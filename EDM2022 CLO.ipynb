{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68eaf770",
   "metadata": {},
   "source": [
    "Required packages:\\\n",
    "pandas==1.4.0\\\n",
    "numpy==1.21.5\\\n",
    "scikit-learn==1.0.2\\\n",
    "tensorflow==2.7.0\\\n",
    "torch==1.10.2\\\n",
    "transformers==4.17.0.dev0\\\n",
    "datasets==1.18.3\\\n",
    "textstat==0.7.2 (if running the ML part)\\\n",
    "xgboost==1.5.2 (if running the ML part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9476647",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c045eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_DL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "071ca393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e136f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/sample_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6636997",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna({'Remember': 0, 'Understand': 0, 'Apply': 0, 'Analyze': 0, 'Evaluate': 0, 'Create':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f82825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learning_outcome     object\n",
       "Remember            float64\n",
       "Understand          float64\n",
       "Apply               float64\n",
       "Analyze             float64\n",
       "Evaluate            float64\n",
       "Create              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc442796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Remember', 'Understand', 'Apply', 'Analyze', 'Evaluate', 'Create']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns[1:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc8ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['one_hot_encoded'] = list(data[data.columns[1:]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0c1c6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning_outcome</th>\n",
       "      <th>Remember</th>\n",
       "      <th>Understand</th>\n",
       "      <th>Apply</th>\n",
       "      <th>Analyze</th>\n",
       "      <th>Evaluate</th>\n",
       "      <th>Create</th>\n",
       "      <th>one_hot_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyze the health economic implications of e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apply research skills to operate effectively ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assess and synthesise diverse information abo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe the general characteristics of the m...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evaluate the different models of perioperativ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Learning_outcome  Remember  Understand  \\\n",
       "0   Analyze the health economic implications of e...       0.0         0.0   \n",
       "1   Apply research skills to operate effectively ...       0.0         0.0   \n",
       "2   Assess and synthesise diverse information abo...       0.0         0.0   \n",
       "3   Describe the general characteristics of the m...       0.0         1.0   \n",
       "4   Evaluate the different models of perioperativ...       0.0         0.0   \n",
       "\n",
       "   Apply  Analyze  Evaluate  Create                 one_hot_encoded  \n",
       "0    0.0      1.0       0.0     0.0  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "1    1.0      0.0       0.0     0.0  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "2    0.0      0.0       1.0     1.0  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0]  \n",
       "3    0.0      0.0       0.0     0.0  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "4    0.0      0.0       1.0     0.0  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2a66887",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Learning_outcome'] = data['Learning_outcome'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ae693d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "textual_data = data['Learning_outcome'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d93cda",
   "metadata": {},
   "source": [
    "### Some Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b80c62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2b64a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for text in textual_data:\n",
    "    lengths.append(len(word_tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "450ac0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 266, 17.808372310570626, 54.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(lengths), max(lengths), np.mean(lengths), np.percentile(lengths, 99.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cca923c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([20195,  1185]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['Remember'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96deeb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([15555,  5825]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['Understand'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c195c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([15299,  6081]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['Apply'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71b2a254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([17921,  3459]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['Analyze'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e1cf6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([17546,  3834]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['Evaluate'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b9de6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([17493,  3887]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['Create'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2467a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC_data = pd.read_csv(\"data/LIWC2015 Results (Learning_outcome.csv).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d391fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join(LIWC_data).drop(['A'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e00c7436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning_outcome</th>\n",
       "      <th>Remember</th>\n",
       "      <th>Understand</th>\n",
       "      <th>Apply</th>\n",
       "      <th>Analyze</th>\n",
       "      <th>Evaluate</th>\n",
       "      <th>Create</th>\n",
       "      <th>one_hot_encoded</th>\n",
       "      <th>WC</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>...</th>\n",
       "      <th>Comma</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>analyze the health economic implications of e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>99.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apply research skills to operate effectively ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>14</td>\n",
       "      <td>99.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assess and synthesise diverse information abo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0]</td>\n",
       "      <td>26</td>\n",
       "      <td>43.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>describe the general characteristics of the m...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>23</td>\n",
       "      <td>99.00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evaluate the different models of perioperativ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>10</td>\n",
       "      <td>98.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Learning_outcome  Remember  Understand  \\\n",
       "0   analyze the health economic implications of e...       0.0         0.0   \n",
       "1   apply research skills to operate effectively ...       0.0         0.0   \n",
       "2   assess and synthesise diverse information abo...       0.0         0.0   \n",
       "3   describe the general characteristics of the m...       0.0         1.0   \n",
       "4   evaluate the different models of perioperativ...       0.0         0.0   \n",
       "\n",
       "   Apply  Analyze  Evaluate  Create                 one_hot_encoded  WC  \\\n",
       "0    0.0      1.0       0.0     0.0  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   9   \n",
       "1    1.0      0.0       0.0     0.0  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  14   \n",
       "2    0.0      0.0       1.0     1.0  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0]  26   \n",
       "3    0.0      0.0       0.0     0.0  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  23   \n",
       "4    0.0      0.0       1.0     0.0  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  10   \n",
       "\n",
       "   Analytic  ...  Comma  Colon  SemiC  QMark  Exclam  Dash  Quote  Apostro  \\\n",
       "0     99.00  ...    0.0    0.0    0.0    0.0     0.0  0.00    0.0      0.0   \n",
       "1     99.00  ...    0.0    0.0    0.0    0.0     0.0  0.00    0.0      0.0   \n",
       "2     43.96  ...    0.0    0.0    0.0    0.0     0.0  0.00    0.0      0.0   \n",
       "3     99.00  ...    8.7    0.0    0.0    0.0     0.0  4.35    0.0      0.0   \n",
       "4     98.58  ...    0.0    0.0    0.0    0.0     0.0  0.00    0.0      0.0   \n",
       "\n",
       "   Parenth  OtherP  \n",
       "0      0.0     0.0  \n",
       "1      0.0     0.0  \n",
       "2      0.0     0.0  \n",
       "3      0.0     0.0  \n",
       "4      0.0     0.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3100cb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WC', 'Analytic', 'Clout', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'Dic',\n",
       "       'function', 'pronoun', 'ppron', 'i', 'we', 'you', 'shehe', 'they',\n",
       "       'ipron', 'article', 'prep', 'auxverb', 'adverb', 'conj', 'negate',\n",
       "       'verb', 'adj', 'compare', 'interrog', 'number', 'quant', 'affect',\n",
       "       'posemo', 'negemo', 'anx', 'anger', 'sad', 'social', 'family', 'friend',\n",
       "       'female', 'male', 'cogproc', 'insight', 'cause', 'discrep', 'tentat',\n",
       "       'certain', 'differ', 'percept', 'see', 'hear', 'feel', 'bio', 'body',\n",
       "       'health', 'sexual', 'ingest', 'drives', 'affiliation', 'achieve',\n",
       "       'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture',\n",
       "       'relativ', 'motion', 'space', 'time', 'work', 'leisure', 'home',\n",
       "       'money', 'relig', 'death', 'informal', 'swear', 'netspeak', 'assent',\n",
       "       'nonflu', 'filler', 'AllPunc', 'Period', 'Comma', 'Colon', 'SemiC',\n",
       "       'QMark', 'Exclam', 'Dash', 'Quote', 'Apostro', 'Parenth', 'OtherP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[8:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15abd28d",
   "metadata": {},
   "source": [
    "## Undersample - not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "883e406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18a376e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rus(X, Y):\n",
    "    Y = np.where(Y==1.0, 1, 0)\n",
    "    r = RandomUnderSampler(random_state=0)\n",
    "    X = X.to_numpy()\n",
    "    #X = np.reshape(X, (-1, 1))\n",
    "    X_resampled, y_resampled = r.fit_resample(X, Y)\n",
    "    #X_resampled = X_resampled.flatten()\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b333a9",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "defe8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, cohen_kappa_score, f1_score\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, AutoModel, TrainingArguments, Trainer, AutoModelForSequenceClassification, EarlyStoppingCallback\n",
    "from datasets import load_metric, list_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34c19d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metric: F1 Score\n",
    "metric = load_metric(\"f1\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b5aedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "\n",
    "def createBERT(dir_name, X, Y, test_X, test_Y, batch_size=64, nepochs=3, patience=10):\n",
    "    # function to fine-tune BERT with given data and print out performance on the testing set\n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', use_cache=False)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2, use_cache=False)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=dir_name,          # output directory\n",
    "        num_train_epochs=nepochs,              # total number of training epochs\n",
    "        per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "        per_device_eval_batch_size=batch_size,   # batch size for evaluation\n",
    "        warmup_steps=5,                # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.05,               # strength of weight decay\n",
    "        logging_dir='./logs',            # directory for storing logs\n",
    "        logging_steps=10,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=10,\n",
    "        load_best_model_at_end=True,\n",
    "        save_total_limit=3\n",
    "    )\n",
    "    train_x, val_x, train_y, val_y = train_test_split(X, Y, test_size=0.2, random_state=666, stratify=Y)\n",
    "\n",
    "    train_encoded = tokenizer(train_x, truncation=True, padding=True, max_length=55)\n",
    "    val_encoded = tokenizer(val_x, truncation=True, padding=True, max_length=55)\n",
    "    test_encoded = tokenizer(test_X, truncation=True, padding=True, max_length=55)\n",
    "\n",
    "    train_set = EncodeDataset(train_encoded, train_y)\n",
    "    val_set = EncodeDataset(val_encoded, val_y)\n",
    "    test_set = EncodeDataset(test_encoded, test_Y)\n",
    "    trainer = Trainer(model=model, args=training_args, train_dataset=train_set, eval_dataset=val_set, compute_metrics=compute_metrics, callbacks=[EarlyStoppingCallback(early_stopping_patience=patience)])\n",
    "    print(\"Started training model for column\", dir_name)\n",
    "    trainer.train()\n",
    "    trainer.save_model()\n",
    "    print(\"Training Completed. Started testing...\")\n",
    "    predicted = trainer.predict(test_set)\n",
    "    predicted_result = np.argmax(predicted.predictions, axis=-1)\n",
    "    print(\"Accuracy Score -> \", accuracy_score(test_Y, predicted_result))\n",
    "    print(\"Kappa Score -> \", cohen_kappa_score(test_Y, predicted_result))\n",
    "    print(\"ROC AUC Score -> \", roc_auc_score(test_Y, predicted_result))\n",
    "    print(\"F1 Score -> \", f1_score(test_Y, predicted_result))\n",
    "    print(\"Classification report -> \\n\", classification_report(test_Y, predicted_result))\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa33c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remember_bert = None\n",
    "understand_bert = None\n",
    "apply_bert = None\n",
    "analyze_bert = None\n",
    "evaluate_bert = None\n",
    "create_bert = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15cc8f5",
   "metadata": {},
   "source": [
    "## ML Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "909e00f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca7cea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import textstat\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e51969db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1355502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28a8a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateX(data_x, test_x, textual_column_index, start_index_LIWC, end_index_LIWC):\n",
    "    # generating ML features based on previous literature\n",
    "    column_names = []\n",
    "    print(\"Getting Unigram...\")\n",
    "    uni_cv = CountVectorizer(stop_words='english', ngram_range=(1, 1), max_features=1000)\n",
    "    unigram = uni_cv.fit_transform(data_x[:, textual_column_index])\n",
    "    unigram = unigram.toarray()\n",
    "    unigram_test = uni_cv.transform(test_x[:,textual_column_index]).toarray()\n",
    "    temp = uni_cv.get_feature_names_out().tolist()\n",
    "    column_names += [\"uni_\"+name for name in temp]\n",
    "    print(\"Getting Bigram...\")\n",
    "    bi_cv = CountVectorizer(stop_words='english', ngram_range=(2, 2), max_features=1000)\n",
    "    bigram = bi_cv.fit_transform(data_x[:, textual_column_index])\n",
    "    bigram = bigram.toarray()\n",
    "    bigram_test = bi_cv.transform(test_x[:, textual_column_index]).toarray()\n",
    "    temp = bi_cv.get_feature_names_out().tolist()\n",
    "    column_names += [\"bi_\"+name for name in temp]\n",
    "    print(\"Getting Tfidf...\")\n",
    "    tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1, 1), max_features=1000)\n",
    "    t = tfidf.fit_transform(data_x[:, textual_column_index])\n",
    "    t = t.toarray()\n",
    "    t_test = tfidf.transform(test_x[:, textual_column_index]).toarray()\n",
    "    temp = tfidf.get_feature_names_out().tolist()\n",
    "    column_names += [\"tfidf_\"+name for name in temp]\n",
    "    print(\"Getting ARI...\")\n",
    "    ari = [textstat.automated_readability_index(text) for text in data_x[:, textual_column_index]]\n",
    "    ari_test = [textstat.automated_readability_index(text) for text in test_x[:, textual_column_index]]\n",
    "    column_names.append(\"ari\")\n",
    "    combined_data_x = []\n",
    "    combined_test_x = []\n",
    "    print(\"Combining...\")\n",
    "    for i in range(len(data_x)):\n",
    "        combined_data_x.append(unigram[i].tolist()\n",
    "                              + bigram[i].tolist()\n",
    "                              + t[i].tolist()\n",
    "                              + [ari[i]]\n",
    "                              + data_x[i, start_index_LIWC:end_index_LIWC].tolist())\n",
    "    for i in range(len(test_x)):\n",
    "        combined_test_x.append(unigram_test[i].tolist()\n",
    "                              + bigram_test[i].tolist()\n",
    "                              + t_test[i].tolist()\n",
    "                              + [ari_test[i]]\n",
    "                              + test_x[i, start_index_LIWC:end_index_LIWC].tolist())\n",
    "    print(\"Generated feature shape is\", np.array(combined_data_x).shape)\n",
    "    print(\"Generated test feature is\", np.array(combined_test_x).shape)\n",
    "    return combined_data_x, column_names, combined_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51b0294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performancePrinter(test_y, pred_y):\n",
    "    # performance printer\n",
    "    print(\"Accuracy Score -> \", accuracy_score(test_y, pred_y))\n",
    "    print(\"Kappa Score -> \", cohen_kappa_score(test_y, pred_y))\n",
    "    print(\"ROC AUC Score -> \", roc_auc_score(test_y, pred_y))\n",
    "    print(\"F1 Score -> \", f1_score(test_y, pred_y))\n",
    "    print(\"Classification report -> \\n\", classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f911b",
   "metadata": {},
   "source": [
    "#### Grid Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a611e127",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_nb = {'var_smoothing': [1e-8, 1e-9, 1e-10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "436ddc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_svm = {'C': [0.1, 1, 10, 100],\n",
    "              'gamma': ['scale', 'auto'],\n",
    "              'kernel': ['linear', 'poly', 'rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cecc099",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lr = {'penalty': ['l1', 'l2', 'none'],\n",
    "             'C': [0.1, 1, 10],\n",
    "             'solver': ['saga'],\n",
    "             'tol': [0.01, 0.001, 0.0001],\n",
    "             'max_iter': [200, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6faf861",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf = {'n_estimators': [50, 100, 250],\n",
    "             'max_depth': [None, 5, 10],\n",
    "             'max_features':['auto', 'sqrt'],\n",
    "             'min_samples_split': [2, 5, 10],\n",
    "             'min_samples_leaf': [1, 2, 4],\n",
    "             'bootstrap': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e76d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {'gamma':[0.1, 0.5],\n",
    "              'learning_rate': [0.1, 0.5],\n",
    "              'max_depth': [5, 7, 10],\n",
    "              'n_estimators': [50, 100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4563f24",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e403b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_x, split_test_x, split_train_y, split_test_y = train_test_split(data.drop(columns=list(data.columns[1:8])), data[data.columns[1:7]], test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc95c9",
   "metadata": {},
   "source": [
    "### Remember"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f6ce7e",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffb12e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "remember_x, remember_y = split_train_x.to_numpy(), split_train_y['Remember'].astype('long').to_numpy()#rus(split_train_x, split_train_y['Remember'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1aadafae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17104, 94), (17104,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remember_x.shape, remember_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff35a5c8",
   "metadata": {},
   "source": [
    "#### BERT Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6c5f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "remember_x_bert = remember_x[:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3178440a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 13683\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training model for column remember\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='642' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/642 41:06 < 39:06, 0.13 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.429400</td>\n",
       "      <td>0.220046</td>\n",
       "      <td>0.485719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.150900</td>\n",
       "      <td>0.202605</td>\n",
       "      <td>0.485719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>0.111501</td>\n",
       "      <td>0.822688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.108962</td>\n",
       "      <td>0.823905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.117200</td>\n",
       "      <td>0.084652</td>\n",
       "      <td>0.845506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.077134</td>\n",
       "      <td>0.858652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.074709</td>\n",
       "      <td>0.884382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.092848</td>\n",
       "      <td>0.861487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.088100</td>\n",
       "      <td>0.070787</td>\n",
       "      <td>0.872400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.066905</td>\n",
       "      <td>0.900992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.083940</td>\n",
       "      <td>0.884900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.078017</td>\n",
       "      <td>0.886819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.070066</td>\n",
       "      <td>0.878469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.073780</td>\n",
       "      <td>0.889201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.057345</td>\n",
       "      <td>0.907397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.061340</td>\n",
       "      <td>0.895977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>0.054828</td>\n",
       "      <td>0.911270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>0.914624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.050182</td>\n",
       "      <td>0.907397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.047231</td>\n",
       "      <td>0.913076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>0.059961</td>\n",
       "      <td>0.921684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.049499</td>\n",
       "      <td>0.925816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.049251</td>\n",
       "      <td>0.930550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.038600</td>\n",
       "      <td>0.046195</td>\n",
       "      <td>0.930361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.046354</td>\n",
       "      <td>0.922022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.909033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.049854</td>\n",
       "      <td>0.923124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.065291</td>\n",
       "      <td>0.894852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>0.046569</td>\n",
       "      <td>0.929290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.044116</td>\n",
       "      <td>0.927081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.043530</td>\n",
       "      <td>0.929094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>0.039751</td>\n",
       "      <td>0.927555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.046553</td>\n",
       "      <td>0.928353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-10\n",
      "Configuration saved in remember/checkpoint-10/config.json\n",
      "Model weights saved in remember/checkpoint-10/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-20\n",
      "Configuration saved in remember/checkpoint-20/config.json\n",
      "Model weights saved in remember/checkpoint-20/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-30\n",
      "Configuration saved in remember/checkpoint-30/config.json\n",
      "Model weights saved in remember/checkpoint-30/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-40\n",
      "Configuration saved in remember/checkpoint-40/config.json\n",
      "Model weights saved in remember/checkpoint-40/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-50\n",
      "Configuration saved in remember/checkpoint-50/config.json\n",
      "Model weights saved in remember/checkpoint-50/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-60\n",
      "Configuration saved in remember/checkpoint-60/config.json\n",
      "Model weights saved in remember/checkpoint-60/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-70\n",
      "Configuration saved in remember/checkpoint-70/config.json\n",
      "Model weights saved in remember/checkpoint-70/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-80\n",
      "Configuration saved in remember/checkpoint-80/config.json\n",
      "Model weights saved in remember/checkpoint-80/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-90\n",
      "Configuration saved in remember/checkpoint-90/config.json\n",
      "Model weights saved in remember/checkpoint-90/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-100\n",
      "Configuration saved in remember/checkpoint-100/config.json\n",
      "Model weights saved in remember/checkpoint-100/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-110\n",
      "Configuration saved in remember/checkpoint-110/config.json\n",
      "Model weights saved in remember/checkpoint-110/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-120\n",
      "Configuration saved in remember/checkpoint-120/config.json\n",
      "Model weights saved in remember/checkpoint-120/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-130\n",
      "Configuration saved in remember/checkpoint-130/config.json\n",
      "Model weights saved in remember/checkpoint-130/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-140\n",
      "Configuration saved in remember/checkpoint-140/config.json\n",
      "Model weights saved in remember/checkpoint-140/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-150\n",
      "Configuration saved in remember/checkpoint-150/config.json\n",
      "Model weights saved in remember/checkpoint-150/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-160\n",
      "Configuration saved in remember/checkpoint-160/config.json\n",
      "Model weights saved in remember/checkpoint-160/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-170\n",
      "Configuration saved in remember/checkpoint-170/config.json\n",
      "Model weights saved in remember/checkpoint-170/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-180\n",
      "Configuration saved in remember/checkpoint-180/config.json\n",
      "Model weights saved in remember/checkpoint-180/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-190\n",
      "Configuration saved in remember/checkpoint-190/config.json\n",
      "Model weights saved in remember/checkpoint-190/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-200\n",
      "Configuration saved in remember/checkpoint-200/config.json\n",
      "Model weights saved in remember/checkpoint-200/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-210\n",
      "Configuration saved in remember/checkpoint-210/config.json\n",
      "Model weights saved in remember/checkpoint-210/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-220\n",
      "Configuration saved in remember/checkpoint-220/config.json\n",
      "Model weights saved in remember/checkpoint-220/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-230\n",
      "Configuration saved in remember/checkpoint-230/config.json\n",
      "Model weights saved in remember/checkpoint-230/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-240\n",
      "Configuration saved in remember/checkpoint-240/config.json\n",
      "Model weights saved in remember/checkpoint-240/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-250\n",
      "Configuration saved in remember/checkpoint-250/config.json\n",
      "Model weights saved in remember/checkpoint-250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-260\n",
      "Configuration saved in remember/checkpoint-260/config.json\n",
      "Model weights saved in remember/checkpoint-260/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-270\n",
      "Configuration saved in remember/checkpoint-270/config.json\n",
      "Model weights saved in remember/checkpoint-270/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-280\n",
      "Configuration saved in remember/checkpoint-280/config.json\n",
      "Model weights saved in remember/checkpoint-280/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-290\n",
      "Configuration saved in remember/checkpoint-290/config.json\n",
      "Model weights saved in remember/checkpoint-290/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-300\n",
      "Configuration saved in remember/checkpoint-300/config.json\n",
      "Model weights saved in remember/checkpoint-300/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-310\n",
      "Configuration saved in remember/checkpoint-310/config.json\n",
      "Model weights saved in remember/checkpoint-310/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-320\n",
      "Configuration saved in remember/checkpoint-320/config.json\n",
      "Model weights saved in remember/checkpoint-320/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to remember/checkpoint-330\n",
      "Configuration saved in remember/checkpoint-330/config.json\n",
      "Model weights saved in remember/checkpoint-330/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from remember/checkpoint-230 (score: 0.9305499223590747).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to remember\n",
      "Configuration saved in remember/config.json\n",
      "Model weights saved in remember/pytorch_model.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 4276\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed. Started testing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9871375116931712\n",
      "Kappa Score ->  0.8712781329363342\n",
      "ROC AUC Score ->  0.9157408306981614\n",
      "F1 Score ->  0.8780487804878049\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4039\n",
      "           1       0.93      0.84      0.88       237\n",
      "\n",
      "    accuracy                           0.99      4276\n",
      "   macro avg       0.96      0.92      0.94      4276\n",
      "weighted avg       0.99      0.99      0.99      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if RUN_DL:\n",
    "    remember_bert = createBERT('remember', remember_x_bert, remember_y, split_test_x['Learning_outcome'].tolist(), split_test_y['Remember'].astype('long').to_numpy(), 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3cf108",
   "metadata": {},
   "source": [
    "#### Traditional ML Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e82952f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Unigram...\n",
      "Getting Bigram...\n",
      "Getting Tfidf...\n",
      "Getting ARI...\n",
      "Combining...\n",
      "Generated feature shape is (17104, 3094)\n",
      "Generated test feature is (4276, 3094)\n"
     ]
    }
   ],
   "source": [
    "combined_remember_x, column_names_remember, test_remember_x = generateX(remember_x, split_test_x.to_numpy(), 0, 1, 94)\n",
    "train_remember_x = combined_remember_x\n",
    "train_remember_y = remember_y\n",
    "test_remember_y = split_test_y['Remember'].astype('long').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b1dc82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_remember += data.columns[8:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b657a1f5",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac9cd9bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "gnb_remember = GaussianNB()\n",
    "gnb_remember_gs = GridSearchCV(gnb_remember, params_nb, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "gnb_remember_gs.fit(train_remember_x, train_remember_y)\n",
    "pred_remember_y_gnb = gnb_remember_gs.predict(test_remember_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "737fc3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 1e-08}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_remember_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "886ca354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.6396164639850327\n",
      "Kappa Score ->  0.11147063503407495\n",
      "ROC AUC Score ->  0.7158971128543117\n",
      "F1 Score ->  0.1978136387298282\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.63      0.77      4039\n",
      "           1       0.11      0.80      0.20       237\n",
      "\n",
      "    accuracy                           0.64      4276\n",
      "   macro avg       0.55      0.72      0.48      4276\n",
      "weighted avg       0.93      0.64      0.74      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_remember_y, pred_remember_y_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad2258",
   "metadata": {},
   "source": [
    "##### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0bc25cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    }
   ],
   "source": [
    "svm_remember = SVC()\n",
    "svm_remember_gs = GridSearchCV(svm_remember, params_svm, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "svm_remember_gs.fit(train_remember_x, train_remember_y)\n",
    "pred_remember_y_svm = svm_remember_gs.predict(test_remember_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c0b176b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_remember_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "498593d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9815247895229187\n",
      "Kappa Score ->  0.8273257585206419\n",
      "ROC AUC Score ->  0.9226993563807726\n",
      "F1 Score ->  0.8371134020618556\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4039\n",
      "           1       0.82      0.86      0.84       237\n",
      "\n",
      "    accuracy                           0.98      4276\n",
      "   macro avg       0.91      0.92      0.91      4276\n",
      "weighted avg       0.98      0.98      0.98      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_remember_y, pred_remember_y_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416f5d3",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b157144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr_remember = LogisticRegression()\n",
    "lr_remember_gs = GridSearchCV(lr_remember, params_lr, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "lr_remember_gs.fit(train_remember_x, train_remember_y)\n",
    "pred_remember_y_lr = lr_remember_gs.predict(test_remember_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "65687665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_remember_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa4f80a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9597754911131899\n",
      "Kappa Score ->  0.4849022642751588\n",
      "ROC AUC Score ->  0.6808208573998452\n",
      "F1 Score ->  0.5028901734104045\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      4039\n",
      "           1       0.80      0.37      0.50       237\n",
      "\n",
      "    accuracy                           0.96      4276\n",
      "   macro avg       0.88      0.68      0.74      4276\n",
      "weighted avg       0.95      0.96      0.95      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_remember_y, pred_remember_y_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87123057",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7ad2b71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    }
   ],
   "source": [
    "rf_remember = RandomForestClassifier()\n",
    "rf_remember_gs = GridSearchCV(rf_remember, params_rf, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "rf_remember_gs.fit(train_remember_x, train_remember_y)\n",
    "pred_remember_y_rf = rf_remember_gs.predict(test_remember_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d4d2f721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 250}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_remember_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "05f57ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9831618334892422\n",
      "Kappa Score ->  0.8297196396077499\n",
      "ROC AUC Score ->  0.8917913215348663\n",
      "F1 Score ->  0.8385650224215246\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4039\n",
      "           1       0.89      0.79      0.84       237\n",
      "\n",
      "    accuracy                           0.98      4276\n",
      "   macro avg       0.94      0.89      0.91      4276\n",
      "weighted avg       0.98      0.98      0.98      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_remember_y, pred_remember_y_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a7922b",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5b4e81bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:21:12] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END ..C=0.1, gamma=auto, kernel=linear;, score=0.799 total time= 1.3min\n",
      "[CV 1/3] END ...C=1, gamma=scale, kernel=linear;, score=0.734 total time= 1.6min\n",
      "[CV 2/3] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time= 1.5min\n",
      "[CV 3/3] END .......C=1, gamma=auto, kernel=rbf;, score=0.000 total time= 2.3min\n",
      "[CV 2/3] END .....C=10, gamma=auto, kernel=poly;, score=0.643 total time= 1.5min\n",
      "[CV 2/3] END ...C=100, gamma=scale, kernel=poly;, score=0.418 total time= 1.4min\n",
      "[CV 3/3] END ..C=100, gamma=auto, kernel=linear;, score=0.720 total time= 1.7min\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.066 total time=  49.6s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.099 total time=  37.3s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.281 total time= 2.0min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.303 total time= 1.5min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.099 total time= 1.3min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.078 total time=  36.3s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.308 total time= 3.1min\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.345 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.019 total time=  18.0s\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.078 total time=  37.0s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.019 total time=  30.1s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.322 total time= 2.7min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.712 total time=   6.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.672 total time=  10.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.758 total time=  42.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.712 total time=  37.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.676 total time=  38.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.616 total time=  16.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.604 total time=  14.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.687 total time=  17.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.748 total time=  41.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.638 total time=  15.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.659 total time=   8.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.699 total time=  39.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.537 total time=  34.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.481 total time=  30.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.013 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.019 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.000 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.019 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.019 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.006 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.019 total time=   3.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.025 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.025 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.025 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.025 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.019 total time=   9.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.019 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.019 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.019 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.019 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.025 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.778 total time=  23.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.760 total time=  26.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.762 total time=  26.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.701 total time=  13.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.711 total time= 1.0min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.734 total time=  58.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.656 total time=  24.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.623 total time=  23.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.780 total time=  15.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.753 total time=  14.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.773 total time=  26.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.756 total time=  14.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.788 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.746 total time= 1.0min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.672 total time=  55.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.600 total time=  47.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.019 total time=   3.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.013 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.019 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.019 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.019 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.019 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.019 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.019 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.013 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.019 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.019 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.025 total time=   6.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.019 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.019 total time=  13.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.019 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.025 total time=  13.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.019 total time=   6.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.019 total time=   6.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.019 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.019 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.019 total time=  13.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.019 total time=   6.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.019 total time=   6.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.025 total time=   6.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.019 total time=  13.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.019 total time=   6.6s\n",
      "[04:00:54] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:02:31] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:06:05] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:08:03] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:10:17] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:13:12] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:15:28] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_remember = XGBClassifier()\n",
    "xgb_remember_gs = GridSearchCV(xgb_remember, params_xgb, scoring=\"f1\", n_jobs=-1, cv=3)\n",
    "xgb_remember_gs.fit(train_remember_x, train_remember_y)\n",
    "pred_remember_y_xgb = xgb_remember_gs.predict(test_remember_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "535c40c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_remember_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e8d67a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9808231992516371\n",
      "Kappa Score ->  0.8197173945011111\n",
      "ROC AUC Score ->  0.9163702424567219\n",
      "F1 Score ->  0.8298755186721992\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4039\n",
      "           1       0.82      0.84      0.83       237\n",
      "\n",
      "    accuracy                           0.98      4276\n",
      "   macro avg       0.90      0.92      0.91      4276\n",
      "weighted avg       0.98      0.98      0.98      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_remember_y, pred_remember_y_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb02b1ef",
   "metadata": {},
   "source": [
    "### Understand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32843c2",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "324fc08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "understand_x, understand_y = split_train_x.to_numpy(), split_train_y['Understand'].astype('long').to_numpy() #rus(split_train_x, split_train_y['Understand'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c9ea2682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17104, 94)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "understand_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dfae7e",
   "metadata": {},
   "source": [
    "#### BERT Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a316d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "understand_x_bert = understand_x[:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c19bbdad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /Users/ylii0447/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /Users/ylii0447/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /Users/ylii0447/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "using `logging_steps` to initialize `eval_steps` to 10\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 13683\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training model for column understand\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='642' max='642' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [642/642 1:20:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.601600</td>\n",
       "      <td>0.486269</td>\n",
       "      <td>0.421835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.402600</td>\n",
       "      <td>0.257279</td>\n",
       "      <td>0.885416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.198980</td>\n",
       "      <td>0.913151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.220500</td>\n",
       "      <td>0.200793</td>\n",
       "      <td>0.919804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.178525</td>\n",
       "      <td>0.917128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.230800</td>\n",
       "      <td>0.168040</td>\n",
       "      <td>0.921720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.204700</td>\n",
       "      <td>0.158797</td>\n",
       "      <td>0.928188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.134900</td>\n",
       "      <td>0.171044</td>\n",
       "      <td>0.932743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.166900</td>\n",
       "      <td>0.185779</td>\n",
       "      <td>0.914503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.171141</td>\n",
       "      <td>0.923408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.168500</td>\n",
       "      <td>0.163571</td>\n",
       "      <td>0.926485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.198900</td>\n",
       "      <td>0.151065</td>\n",
       "      <td>0.926445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.154400</td>\n",
       "      <td>0.139789</td>\n",
       "      <td>0.937293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.156968</td>\n",
       "      <td>0.928540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.154985</td>\n",
       "      <td>0.935891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.139096</td>\n",
       "      <td>0.939323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.147351</td>\n",
       "      <td>0.928405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.141439</td>\n",
       "      <td>0.936726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.111100</td>\n",
       "      <td>0.128699</td>\n",
       "      <td>0.943855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.156400</td>\n",
       "      <td>0.126047</td>\n",
       "      <td>0.935839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.152600</td>\n",
       "      <td>0.125333</td>\n",
       "      <td>0.937959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.109800</td>\n",
       "      <td>0.124675</td>\n",
       "      <td>0.941511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.114000</td>\n",
       "      <td>0.128646</td>\n",
       "      <td>0.946694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>0.123223</td>\n",
       "      <td>0.948203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>0.127896</td>\n",
       "      <td>0.944057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.135214</td>\n",
       "      <td>0.951054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.118116</td>\n",
       "      <td>0.951136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.130107</td>\n",
       "      <td>0.946529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.117313</td>\n",
       "      <td>0.951869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.126100</td>\n",
       "      <td>0.129831</td>\n",
       "      <td>0.942497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.110530</td>\n",
       "      <td>0.948129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.093100</td>\n",
       "      <td>0.105501</td>\n",
       "      <td>0.948845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.109821</td>\n",
       "      <td>0.951785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.105955</td>\n",
       "      <td>0.954947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.115179</td>\n",
       "      <td>0.954734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.118028</td>\n",
       "      <td>0.954632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.111100</td>\n",
       "      <td>0.117643</td>\n",
       "      <td>0.953099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.109693</td>\n",
       "      <td>0.952939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.108825</td>\n",
       "      <td>0.953519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>0.104696</td>\n",
       "      <td>0.953004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.113329</td>\n",
       "      <td>0.954098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.126321</td>\n",
       "      <td>0.951647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.957962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.115734</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.113646</td>\n",
       "      <td>0.957962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.050400</td>\n",
       "      <td>0.117881</td>\n",
       "      <td>0.956406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.119238</td>\n",
       "      <td>0.953878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>0.128067</td>\n",
       "      <td>0.953389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.122065</td>\n",
       "      <td>0.954838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.119633</td>\n",
       "      <td>0.955040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.126580</td>\n",
       "      <td>0.952649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.053200</td>\n",
       "      <td>0.124022</td>\n",
       "      <td>0.955630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.115938</td>\n",
       "      <td>0.958800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>0.112863</td>\n",
       "      <td>0.958712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.112452</td>\n",
       "      <td>0.958625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>0.111104</td>\n",
       "      <td>0.959605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.115580</td>\n",
       "      <td>0.958952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.111548</td>\n",
       "      <td>0.959526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.110822</td>\n",
       "      <td>0.958868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.111948</td>\n",
       "      <td>0.957559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.110051</td>\n",
       "      <td>0.959253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.108020</td>\n",
       "      <td>0.958756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.107948</td>\n",
       "      <td>0.958756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>0.107995</td>\n",
       "      <td>0.959113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .C=0.1, gamma=scale, kernel=linear;, score=0.777 total time= 1.3min\n",
      "[CV 1/3] END ....C=0.1, gamma=auto, kernel=poly;, score=0.453 total time= 1.5min\n",
      "[CV 2/3] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time= 1.3min\n",
      "[CV 2/3] END ......C=1, gamma=auto, kernel=poly;, score=0.650 total time= 1.5min\n",
      "[CV 3/3] END ....C=10, gamma=scale, kernel=poly;, score=0.000 total time= 1.3min\n",
      "[CV 3/3] END .....C=10, gamma=auto, kernel=poly;, score=0.661 total time= 1.5min\n",
      "[CV 3/3] END ...C=100, gamma=scale, kernel=poly;, score=0.457 total time= 1.4min\n",
      "[CV 2/3] END ....C=100, gamma=auto, kernel=poly;, score=0.636 total time= 1.5min\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.030 total time=  17.7s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.084 total time=  37.4s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.099 total time=  38.1s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.281 total time= 2.0min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.342 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.030 total time=  17.4s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.095 total time=  36.7s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.019 total time=  17.7s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.099 total time=  37.0s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.030 total time=  17.6s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.322 total time= 1.4min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.335 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.078 total time= 1.1min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.078 total time=  37.1s\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.078 total time=  36.9s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.322 total time= 2.7min\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.350 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.691 total time=   9.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.729 total time=  40.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.684 total time=  15.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.648 total time=   8.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.622 total time=  36.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.506 total time=  15.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.425 total time=  14.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.480 total time=   7.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.507 total time=  32.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.758 total time=   8.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.756 total time=  41.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.703 total time=  36.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.664 total time=  15.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.544 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.495 total time=  34.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.534 total time=  15.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.000 total time=   3.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.000 total time=   5.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.000 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.019 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.019 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.019 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.025 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.025 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.025 total time=   9.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.019 total time=   9.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.019 total time=   3.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.019 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.025 total time=   9.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.025 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.019 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.025 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.025 total time=   9.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.740 total time=  23.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.773 total time=  27.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.759 total time=  26.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.730 total time=  13.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.744 total time=  14.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.737 total time=  23.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.717 total time=  12.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.759 total time= 1.0min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.677 total time=  56.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.751 total time= 1.1min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.753 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.742 total time=  26.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.752 total time=  25.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.623 total time=  22.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.630 total time=  13.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.598 total time=  13.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.632 total time=  21.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.000 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.006 total time=   5.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.019 total time=   8.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.019 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.019 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.000 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.019 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.000 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.000 total time=   3.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.019 total time=   3.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.025 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.019 total time=   6.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.025 total time=   6.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.019 total time=  13.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.019 total time=  13.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.019 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.019 total time=  13.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.019 total time=  13.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.019 total time=  13.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.019 total time=   6.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.031 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.019 total time=  13.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.025 total time=  11.2s\n",
      "[04:00:58] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:03:54] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:08:37] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:09:57] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:11:31] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:15:01] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:16:29] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to understand/checkpoint-10\n",
      "Configuration saved in understand/checkpoint-10/config.json\n",
      "Model weights saved in understand/checkpoint-10/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ...............var_smoothing=1e-08;, score=0.181 total time=   3.0s\n",
      "[CV 1/3] END .C=0.1, gamma=scale, kernel=linear;, score=0.799 total time= 1.3min\n",
      "[CV 2/3] END ....C=0.1, gamma=auto, kernel=poly;, score=0.418 total time= 1.5min\n",
      "[CV 3/3] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time= 1.2min\n",
      "[CV 3/3] END ......C=1, gamma=auto, kernel=poly;, score=0.699 total time= 1.6min\n",
      "[CV 1/3] END .....C=10, gamma=scale, kernel=rbf;, score=0.000 total time= 1.4min\n",
      "[CV 2/3] END ......C=10, gamma=auto, kernel=rbf;, score=0.204 total time= 2.4min\n",
      "[CV 3/3] END ....C=100, gamma=scale, kernel=rbf;, score=0.306 total time= 1.7min\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.030 total time=  23.0s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.019 total time=  17.6s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.099 total time=  38.4s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.030 total time=  25.0s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.257 total time= 2.0min\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.345 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.019 total time=  17.7s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.099 total time=  36.6s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.048 total time=  17.9s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.019 total time=  38.0s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.048 total time=  17.8s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.345 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.019 total time=  17.4s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.345 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.095 total time= 1.1min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.048 total time=  18.0s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.030 total time=  31.0s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.334 total time= 2.7min\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.703 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.775 total time=  10.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.722 total time=  10.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.665 total time=  18.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.668 total time=   8.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.636 total time=  10.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.656 total time=  15.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.692 total time=   8.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.465 total time=   9.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.508 total time=  33.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.558 total time=  14.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.688 total time=  17.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.719 total time=  16.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.726 total time=   8.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.737 total time=  40.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.632 total time=  37.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.512 total time=  15.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.540 total time=  14.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.591 total time=   8.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.507 total time=  29.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.000 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.019 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.000 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.000 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.000 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.025 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.025 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.019 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.019 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.025 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.025 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.019 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.019 total time=   9.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.019 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.019 total time=   9.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.019 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.025 total time=   9.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.789 total time= 1.1min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.739 total time=  14.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.719 total time=  25.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.762 total time=  13.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.754 total time=  59.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.623 total time=  56.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.642 total time=  54.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.777 total time=  27.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.740 total time=  27.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.757 total time=  14.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.730 total time=  14.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.736 total time=  25.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.756 total time=  14.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.617 total time=  12.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.700 total time=  13.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.588 total time=  13.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.623 total time=  23.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.657 total time=  13.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.019 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.019 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.019 total time=   5.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.000 total time=   8.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.019 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.019 total time=   3.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.000 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.013 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.019 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.000 total time=   7.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.019 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.019 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.006 total time=   7.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.019 total time=  14.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.025 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.025 total time=  13.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.019 total time=   6.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.019 total time=   6.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.019 total time=   6.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.019 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.019 total time=   6.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.025 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.019 total time=   6.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.025 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.025 total time=  13.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.031 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.019 total time=  14.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.019 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.025 total time=  13.5s\n",
      "[04:01:07] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:03:09] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:05:33] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:08:22] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:12:54] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:15:10] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:18:05] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ...............var_smoothing=1e-09;, score=0.193 total time=   3.2s\n",
      "[CV 1/3] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.000 total time= 1.4min\n",
      "[CV 2/3] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.000 total time= 2.3min\n",
      "[CV 2/3] END ....C=1, gamma=auto, kernel=linear;, score=0.745 total time= 1.5min\n",
      "[CV 3/3] END ..C=10, gamma=scale, kernel=linear;, score=0.720 total time= 1.7min\n",
      "[CV 1/3] END ......C=10, gamma=auto, kernel=rbf;, score=0.151 total time= 2.4min\n",
      "[CV 2/3] END ....C=100, gamma=scale, kernel=rbf;, score=0.240 total time= 1.6min\n",
      "[CV 3/3] END .....C=100, gamma=auto, kernel=rbf;, score=0.343 total time= 1.7min\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.054 total time=  49.7s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.019 total time=  18.4s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.095 total time=  38.0s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.019 total time=  17.7s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.303 total time= 1.5min\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.350 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.072 total time= 1.3min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.078 total time=  37.1s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.308 total time= 3.1min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.342 total time= 1.5min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.099 total time=  37.5s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.099 total time=  37.6s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.048 total time=  18.2s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.345 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.019 total time=  17.8s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.322 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.741 total time=  38.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.751 total time=  17.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.667 total time=  16.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.720 total time=   8.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.700 total time=   9.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.614 total time=  16.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.468 total time=   8.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.478 total time=  35.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.521 total time=  32.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.699 total time=  17.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.701 total time=   9.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.649 total time=  10.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.644 total time=  16.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.701 total time=   8.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.660 total time=   9.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.621 total time=  37.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.565 total time=  15.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.483 total time=  15.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.019 total time=   6.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.019 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.000 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.000 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.019 total time=   2.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.019 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.006 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.019 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.000 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.006 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.019 total time=   3.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.025 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.025 total time=   9.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.019 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.019 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.025 total time=   9.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.019 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.019 total time=   3.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.019 total time=   8.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.019 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.025 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.019 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.782 total time=  12.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.761 total time=  25.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.747 total time=  14.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.775 total time=  28.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.712 total time=  25.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.706 total time=  13.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.692 total time=  58.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.633 total time=  55.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.685 total time=  23.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.756 total time=  26.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.726 total time=  13.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.777 total time= 1.1min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.729 total time=  59.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.746 total time=  57.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.660 total time=  24.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.618 total time=  24.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.013 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.019 total time=   8.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.019 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.006 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.019 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.000 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.019 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.019 total time=   2.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.019 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.013 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.019 total time=   2.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.006 total time=   7.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.025 total time=  14.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.025 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.025 total time=  13.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.025 total time=   6.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.025 total time=   6.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.019 total time=  13.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.019 total time=  13.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.025 total time=   6.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.019 total time=   6.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.025 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.019 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.019 total time=  13.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.019 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.019 total time=  11.1s\n",
      "[04:01:03] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:03:06] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:05:25] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:08:18] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:12:47] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:16:08] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:18:09] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ...............var_smoothing=1e-09;, score=0.180 total time=   2.8s\n",
      "[CV 3/3] END .C=0.1, gamma=scale, kernel=linear;, score=0.796 total time= 1.3min\n",
      "[CV 1/3] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.000 total time= 2.4min\n",
      "[CV 1/3] END ....C=1, gamma=auto, kernel=linear;, score=0.734 total time= 1.5min\n",
      "[CV 2/3] END ..C=10, gamma=scale, kernel=linear;, score=0.717 total time= 1.6min\n",
      "[CV 1/3] END .....C=10, gamma=auto, kernel=poly;, score=0.634 total time= 1.5min\n",
      "[CV 2/3] END .C=100, gamma=scale, kernel=linear;, score=0.717 total time= 1.6min\n",
      "[CV 1/3] END ....C=100, gamma=auto, kernel=poly;, score=0.634 total time= 1.5min\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.054 total time=  49.6s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.084 total time=  38.1s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.036 total time=  24.9s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.048 total time=  17.7s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.317 total time= 1.5min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.322 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.090 total time= 1.3min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.095 total time=  36.5s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.323 total time= 3.1min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.048 total time=  30.3s\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.078 total time= 1.1min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.019 total time=  17.9s\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.078 total time=  36.8s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.019 total time=  17.7s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.342 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.030 total time=  17.6s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.350 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.730 total time=  14.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.730 total time=  16.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.735 total time=  10.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.737 total time=  40.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.688 total time=  36.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.487 total time=  33.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.410 total time=  14.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.692 total time=   8.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.758 total time=  39.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.698 total time=  38.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.708 total time=  35.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.403 total time=  14.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.469 total time=   8.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.520 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.019 total time=   3.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.000 total time=   6.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.019 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.019 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.000 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.000 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.000 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.019 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.019 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.000 total time=   5.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.019 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.025 total time=   9.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.019 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.019 total time=   9.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.019 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.025 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.019 total time=   8.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.025 total time=   9.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.025 total time=   9.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.025 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.019 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.764 total time=  59.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.768 total time= 1.0min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.760 total time=  25.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.689 total time=  24.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.631 total time=  13.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.667 total time=  57.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.698 total time=  56.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.769 total time= 1.1min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.738 total time=  58.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.719 total time=  25.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.615 total time=  22.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.688 total time=  13.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.669 total time=  54.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.013 total time=   3.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.019 total time=   8.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.019 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.019 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.019 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.019 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.019 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.019 total time=   7.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.019 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.019 total time=   7.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.025 total time=   7.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.019 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.000 total time=   7.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.013 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.019 total time=   6.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.031 total time=   6.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.019 total time=   6.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.025 total time=   6.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.019 total time=   6.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.031 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.019 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.025 total time=   6.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.025 total time=   6.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.025 total time=   6.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.031 total time=   6.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.025 total time=   6.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.019 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.019 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.019 total time=  13.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.019 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.019 total time=   6.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.019 total time=  11.7s\n",
      "[04:01:10] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:03:11] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:07:59] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:11:28] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:13:23] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:18:10] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...C=0.1, gamma=scale, kernel=poly;, score=0.000 total time= 1.3min\n",
      "[CV 2/3] END ..C=0.1, gamma=auto, kernel=linear;, score=0.777 total time= 1.4min\n",
      "[CV 3/3] END ...C=1, gamma=scale, kernel=linear;, score=0.759 total time= 1.5min\n",
      "[CV 1/3] END .......C=1, gamma=auto, kernel=rbf;, score=0.006 total time= 2.4min\n",
      "[CV 3/3] END .....C=10, gamma=scale, kernel=rbf;, score=0.000 total time= 1.5min\n",
      "[CV 1/3] END .C=100, gamma=scale, kernel=linear;, score=0.698 total time= 1.6min\n",
      "[CV 1/3] END ..C=100, gamma=auto, kernel=linear;, score=0.698 total time= 1.6min\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.036 total time=  23.4s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.072 total time=  37.1s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.095 total time=  38.3s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.258 total time= 2.0min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.048 total time=  18.4s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.019 total time=  36.0s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.072 total time= 1.3min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.095 total time=  36.6s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.048 total time=  38.8s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.345 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.322 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.019 total time=  30.2s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.099 total time= 1.1min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.030 total time=  18.2s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.099 total time=  37.3s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.345 total time= 2.7min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.342 total time= 1.2min\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.716 total time=  15.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.752 total time=  18.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.721 total time=  17.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.585 total time=   8.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.650 total time=  37.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.694 total time=  16.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.543 total time=  14.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.476 total time=   8.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.464 total time=   8.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.493 total time=  32.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.685 total time=   8.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.734 total time=  10.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.674 total time=  16.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.738 total time=   8.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.710 total time=  37.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.692 total time=  35.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.515 total time=  13.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.523 total time=   8.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.507 total time=  29.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.006 total time=   2.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.019 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.000 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.019 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.006 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.019 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.019 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.000 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.031 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.025 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.025 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.019 total time=   9.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.019 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.025 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.025 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.025 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.025 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.025 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.792 total time=  25.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.780 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.755 total time= 1.0min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.701 total time= 1.0min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.652 total time=  55.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.790 total time=  27.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.764 total time=  27.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.760 total time=  15.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.735 total time=  14.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.735 total time=  25.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.705 total time=  13.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.726 total time= 1.0min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.657 total time=  54.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.658 total time=  24.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.019 total time=   9.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.019 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.006 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.019 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.025 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.000 total time=   3.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.019 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.019 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.025 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.019 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.019 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.019 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.019 total time=   7.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.019 total time=  13.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.019 total time=  13.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.019 total time=  13.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.025 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.025 total time=  13.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.025 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.025 total time=  13.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.019 total time=  13.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.025 total time=   6.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.025 total time=  14.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.025 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.025 total time=   4.3s\n",
      "[04:00:55] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:02:35] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:04:56] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:06:30] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:09:53] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:11:25] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:13:19] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:18:00] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...............var_smoothing=1e-09;, score=0.194 total time=   2.7s\n",
      "[CV 2/3] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.000 total time= 1.4min\n",
      "[CV 3/3] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.000 total time= 2.3min\n",
      "[CV 3/3] END ....C=1, gamma=auto, kernel=linear;, score=0.759 total time= 1.6min\n",
      "[CV 1/3] END ....C=10, gamma=scale, kernel=poly;, score=0.000 total time= 1.3min\n",
      "[CV 1/3] END ...C=10, gamma=auto, kernel=linear;, score=0.698 total time= 1.6min\n",
      "[CV 1/3] END ...C=100, gamma=scale, kernel=poly;, score=0.464 total time= 1.4min\n",
      "[CV 2/3] END ..C=100, gamma=auto, kernel=linear;, score=0.717 total time= 1.6min\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.066 total time=  50.4s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.048 total time=  18.6s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.099 total time=  38.0s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.317 total time= 1.4min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.306 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.090 total time= 1.3min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.030 total time=  17.7s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.099 total time=  36.5s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.345 total time= 3.1min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.030 total time=  30.1s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.095 total time= 1.1min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.099 total time=  37.1s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.345 total time= 2.7min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.048 total time=  17.8s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.342 total time= 1.3min\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.769 total time=  16.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.687 total time=  39.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.693 total time=  37.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.701 total time=  15.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.534 total time=   8.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.436 total time=   8.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.561 total time=  14.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.585 total time=   7.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.714 total time=   9.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.701 total time=  38.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.721 total time=  39.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.702 total time=  16.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.575 total time=   8.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.703 total time=  37.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.490 total time=  32.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.006 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.013 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.019 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.019 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.000 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.019 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.000 total time=   5.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.019 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.000 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.019 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.019 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.019 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.025 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.019 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.019 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.025 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.019 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.019 total time=   9.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.793 total time=  14.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.750 total time=  14.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.785 total time=  14.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.732 total time= 1.0min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.735 total time=  58.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.662 total time=  22.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.639 total time=  22.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.598 total time=  13.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.631 total time=  54.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.774 total time= 1.0min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.764 total time=  27.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.745 total time=  24.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.681 total time=  13.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.724 total time=  58.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.672 total time=  52.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.013 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.019 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.019 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.000 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.025 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.019 total time=   7.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.013 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.000 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.000 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.025 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.013 total time=   3.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.025 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.000 total time=   3.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.000 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.019 total time=   8.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.019 total time=   7.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.019 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.019 total time=  13.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.025 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.025 total time=  14.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.019 total time=  13.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.019 total time=  13.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.019 total time=   6.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.025 total time=  13.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.019 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.025 total time=  13.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.025 total time=   6.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.025 total time=   6.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.019 total time=   6.7s\n",
      "[04:00:57] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:03:50] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:08:32] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:12:40] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:16:03] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:18:03] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to understand/checkpoint-20\n",
      "Configuration saved in understand/checkpoint-20/config.json\n",
      "Model weights saved in understand/checkpoint-20/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...............var_smoothing=1e-08;, score=0.195 total time=   2.9s\n",
      "[CV 1/3] END ...............var_smoothing=1e-10;, score=0.193 total time=   2.7s\n",
      "[CV 3/3] END ...C=0.1, gamma=scale, kernel=poly;, score=0.000 total time= 1.3min\n",
      "[CV 3/3] END ....C=0.1, gamma=auto, kernel=poly;, score=0.450 total time= 1.6min\n",
      "[CV 1/3] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time= 1.5min\n",
      "[CV 2/3] END .......C=1, gamma=auto, kernel=rbf;, score=0.000 total time= 2.3min\n",
      "[CV 2/3] END ...C=10, gamma=auto, kernel=linear;, score=0.717 total time= 1.6min\n",
      "[CV 3/3] END .C=100, gamma=scale, kernel=linear;, score=0.720 total time= 1.7min\n",
      "[CV 3/3] END ....C=100, gamma=auto, kernel=poly;, score=0.661 total time= 1.4min\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.019 total time=  23.1s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.048 total time=  17.7s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.072 total time=  37.3s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.019 total time=  24.2s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.258 total time= 2.0min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.326 total time= 1.5min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.048 total time=  18.0s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.078 total time=  36.7s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.095 total time=  36.2s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.323 total time= 3.1min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.326 total time= 1.5min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.048 total time=  18.2s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.095 total time=  37.3s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.048 total time=  30.5s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.345 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.322 total time= 1.4min\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.696 total time=  40.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.688 total time=  38.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.706 total time=  16.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.671 total time=  38.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.558 total time=  33.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.729 total time=  37.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.749 total time=  16.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.607 total time=   9.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.682 total time=  37.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.689 total time=  17.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.431 total time=  32.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.478 total time=  13.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.000 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.019 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.019 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.013 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.019 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.019 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.025 total time=   9.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.031 total time=   3.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.025 total time=   9.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.006 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.025 total time=   3.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.019 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.025 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.019 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.019 total time=   9.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.019 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.019 total time=   8.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.025 total time=   9.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.025 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.761 total time=  11.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.732 total time=  14.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.762 total time= 1.1min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.729 total time=  59.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.738 total time=  25.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.584 total time=  23.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.685 total time=  13.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.571 total time=  13.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.681 total time=  22.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.715 total time=  13.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.793 total time= 1.1min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.738 total time= 1.0min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.727 total time=  59.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.643 total time=  23.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.682 total time=  22.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.587 total time=  13.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.676 total time=  48.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.019 total time=   3.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.019 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.000 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.019 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.019 total time=   7.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.019 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.006 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.019 total time=   6.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.019 total time=  13.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.019 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.019 total time=  13.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.019 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.019 total time=  13.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.019 total time=  13.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.025 total time=  14.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.025 total time=   6.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.019 total time=   6.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.019 total time=   6.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.019 total time=   6.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.019 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[04:01:14] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:04:53] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:06:22] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:08:15] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:10:33] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:13:28] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:14:50] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:16:17] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:18:12] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ...............var_smoothing=1e-10;, score=0.180 total time=   2.6s\n",
      "[CV 3/3] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.000 total time= 1.4min\n",
      "[CV 2/3] END ...C=1, gamma=scale, kernel=linear;, score=0.745 total time= 1.5min\n",
      "[CV 3/3] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time= 1.6min\n",
      "[CV 1/3] END ..C=10, gamma=scale, kernel=linear;, score=0.698 total time= 1.6min\n",
      "[CV 2/3] END .....C=10, gamma=scale, kernel=rbf;, score=0.000 total time= 1.5min\n",
      "[CV 3/3] END ......C=10, gamma=auto, kernel=rbf;, score=0.187 total time= 2.4min\n",
      "[CV 2/3] END .....C=100, gamma=auto, kernel=rbf;, score=0.291 total time= 1.9min\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.093 total time=  50.2s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.078 total time=  37.5s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.257 total time= 2.0min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.019 total time=  18.0s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.030 total time=  36.8s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.048 total time=  37.5s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.099 total time= 1.3min\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.030 total time=  38.5s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.019 total time=  17.7s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.335 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.030 total time=  17.5s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.048 total time=  17.7s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.322 total time= 1.5min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.099 total time= 1.1min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.095 total time=  36.9s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.030 total time=  17.4s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.322 total time= 1.4min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.342 total time= 1.4min\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.722 total time=   8.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.731 total time=  17.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.677 total time=  10.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.720 total time=  38.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.682 total time=  15.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.635 total time=   7.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.633 total time=  37.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.570 total time=  31.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.706 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.728 total time=   9.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.744 total time=  18.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.725 total time=  19.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.672 total time=  17.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.640 total time=  16.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.715 total time=   8.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.582 total time=   8.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.498 total time=  14.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.511 total time=   7.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.535 total time=  33.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.000 total time=   6.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.019 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.019 total time=   2.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.000 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.000 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.000 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.019 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.019 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.019 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.019 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.019 total time=   9.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.025 total time=   9.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.019 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.025 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.019 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.019 total time=   3.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.739 total time=  11.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.749 total time=  14.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.773 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.764 total time=  26.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.710 total time=  25.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.710 total time=  13.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.604 total time=  13.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.657 total time=  12.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.643 total time=  13.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.542 total time=  22.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.617 total time=  12.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.743 total time=  15.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.740 total time=  27.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.790 total time=  13.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.740 total time=  14.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.759 total time=  27.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.670 total time=  14.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.767 total time= 1.0min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.749 total time= 1.0min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.609 total time=  55.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.000 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.000 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.006 total time=   7.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.019 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.019 total time=   3.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.013 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.019 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.000 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.019 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.000 total time=   7.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.019 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.025 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.025 total time=  14.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.019 total time=   6.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.019 total time=  13.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.019 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.019 total time=  13.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.025 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.025 total time=  13.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.025 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.019 total time=  13.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.019 total time=  13.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.019 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.019 total time=  13.6s\n",
      "[04:00:53] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:02:28] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:06:01] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:07:56] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:11:19] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:13:15] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:15:32] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:18:17] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ...............var_smoothing=1e-08;, score=0.194 total time=   3.2s\n",
      "[CV 2/3] END ...............var_smoothing=1e-10;, score=0.191 total time=   2.6s\n",
      "[CV 2/3] END ...C=0.1, gamma=scale, kernel=poly;, score=0.000 total time= 1.2min\n",
      "[CV 3/3] END ..C=0.1, gamma=auto, kernel=linear;, score=0.796 total time= 1.4min\n",
      "[CV 1/3] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time= 1.3min\n",
      "[CV 1/3] END ......C=1, gamma=auto, kernel=poly;, score=0.649 total time= 1.5min\n",
      "[CV 2/3] END ....C=10, gamma=scale, kernel=poly;, score=0.006 total time= 1.2min\n",
      "[CV 3/3] END ...C=10, gamma=auto, kernel=linear;, score=0.720 total time= 1.7min\n",
      "[CV 1/3] END ....C=100, gamma=scale, kernel=rbf;, score=0.284 total time= 1.6min\n",
      "[CV 1/3] END .....C=100, gamma=auto, kernel=rbf;, score=0.289 total time= 2.0min\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.093 total time=  50.1s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.030 total time=  18.3s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.078 total time=  37.9s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.030 total time=  17.5s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.285 total time= 1.4min\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.030 total time=  17.8s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.342 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.078 total time=  36.2s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.099 total time=  36.4s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.345 total time= 3.2min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.342 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.030 total time=  17.8s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.095 total time=  37.6s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.095 total time=  37.0s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.334 total time= 2.7min\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.326 total time= 1.3min\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.738 total time=  42.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.686 total time=   9.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.711 total time=  17.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.695 total time=  36.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.552 total time=  14.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.428 total time=   8.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.485 total time=  34.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.745 total time=  18.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.644 total time=  40.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.664 total time=  10.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.699 total time=  17.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.681 total time=  15.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.522 total time=   7.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.464 total time=   8.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.475 total time=  32.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.019 total time=   3.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.019 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.025 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.019 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.019 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.013 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.019 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.000 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.019 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.019 total time=   9.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.019 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.019 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.025 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.019 total time=   9.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.025 total time=   3.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.025 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.025 total time=   9.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.025 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.019 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.019 total time=   9.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.756 total time= 1.0min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.781 total time= 1.1min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.713 total time=  13.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.712 total time=  24.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.637 total time=  22.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.579 total time=  12.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.596 total time=  54.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.753 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.776 total time=  27.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.730 total time=  25.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.764 total time=  13.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.716 total time=  14.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.742 total time=  24.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.582 total time=  13.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.634 total time=  54.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.655 total time=  47.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.013 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.000 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.019 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.000 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.000 total time=   3.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.013 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.019 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.019 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.019 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.019 total time=   7.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.019 total time=  13.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.019 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.019 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.019 total time=   6.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.019 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.019 total time=   6.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.025 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.025 total time=  13.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.031 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.019 total time=   6.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.019 total time=  14.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.019 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.019 total time=  13.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.019 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.025 total time=  13.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.025 total time=   6.1s\n",
      "[04:01:01] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:03:56] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:05:19] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:08:09] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:10:28] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:13:26] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[04:18:14] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-30\n",
      "Configuration saved in understand/checkpoint-30/config.json\n",
      "Model weights saved in understand/checkpoint-30/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-40\n",
      "Configuration saved in understand/checkpoint-40/config.json\n",
      "Model weights saved in understand/checkpoint-40/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-50\n",
      "Configuration saved in understand/checkpoint-50/config.json\n",
      "Model weights saved in understand/checkpoint-50/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-60\n",
      "Configuration saved in understand/checkpoint-60/config.json\n",
      "Model weights saved in understand/checkpoint-60/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-70\n",
      "Configuration saved in understand/checkpoint-70/config.json\n",
      "Model weights saved in understand/checkpoint-70/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-80\n",
      "Configuration saved in understand/checkpoint-80/config.json\n",
      "Model weights saved in understand/checkpoint-80/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-90\n",
      "Configuration saved in understand/checkpoint-90/config.json\n",
      "Model weights saved in understand/checkpoint-90/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-100\n",
      "Configuration saved in understand/checkpoint-100/config.json\n",
      "Model weights saved in understand/checkpoint-100/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-110\n",
      "Configuration saved in understand/checkpoint-110/config.json\n",
      "Model weights saved in understand/checkpoint-110/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-120\n",
      "Configuration saved in understand/checkpoint-120/config.json\n",
      "Model weights saved in understand/checkpoint-120/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-130\n",
      "Configuration saved in understand/checkpoint-130/config.json\n",
      "Model weights saved in understand/checkpoint-130/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-140\n",
      "Configuration saved in understand/checkpoint-140/config.json\n",
      "Model weights saved in understand/checkpoint-140/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-150\n",
      "Configuration saved in understand/checkpoint-150/config.json\n",
      "Model weights saved in understand/checkpoint-150/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-160\n",
      "Configuration saved in understand/checkpoint-160/config.json\n",
      "Model weights saved in understand/checkpoint-160/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-170\n",
      "Configuration saved in understand/checkpoint-170/config.json\n",
      "Model weights saved in understand/checkpoint-170/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-180\n",
      "Configuration saved in understand/checkpoint-180/config.json\n",
      "Model weights saved in understand/checkpoint-180/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-190\n",
      "Configuration saved in understand/checkpoint-190/config.json\n",
      "Model weights saved in understand/checkpoint-190/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-200\n",
      "Configuration saved in understand/checkpoint-200/config.json\n",
      "Model weights saved in understand/checkpoint-200/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-210\n",
      "Configuration saved in understand/checkpoint-210/config.json\n",
      "Model weights saved in understand/checkpoint-210/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-220\n",
      "Configuration saved in understand/checkpoint-220/config.json\n",
      "Model weights saved in understand/checkpoint-220/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-230\n",
      "Configuration saved in understand/checkpoint-230/config.json\n",
      "Model weights saved in understand/checkpoint-230/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-240\n",
      "Configuration saved in understand/checkpoint-240/config.json\n",
      "Model weights saved in understand/checkpoint-240/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-250\n",
      "Configuration saved in understand/checkpoint-250/config.json\n",
      "Model weights saved in understand/checkpoint-250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-260\n",
      "Configuration saved in understand/checkpoint-260/config.json\n",
      "Model weights saved in understand/checkpoint-260/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-270\n",
      "Configuration saved in understand/checkpoint-270/config.json\n",
      "Model weights saved in understand/checkpoint-270/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-280\n",
      "Configuration saved in understand/checkpoint-280/config.json\n",
      "Model weights saved in understand/checkpoint-280/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-290\n",
      "Configuration saved in understand/checkpoint-290/config.json\n",
      "Model weights saved in understand/checkpoint-290/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-300\n",
      "Configuration saved in understand/checkpoint-300/config.json\n",
      "Model weights saved in understand/checkpoint-300/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-310\n",
      "Configuration saved in understand/checkpoint-310/config.json\n",
      "Model weights saved in understand/checkpoint-310/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-320\n",
      "Configuration saved in understand/checkpoint-320/config.json\n",
      "Model weights saved in understand/checkpoint-320/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-330\n",
      "Configuration saved in understand/checkpoint-330/config.json\n",
      "Model weights saved in understand/checkpoint-330/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-340\n",
      "Configuration saved in understand/checkpoint-340/config.json\n",
      "Model weights saved in understand/checkpoint-340/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-350\n",
      "Configuration saved in understand/checkpoint-350/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in understand/checkpoint-350/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-360\n",
      "Configuration saved in understand/checkpoint-360/config.json\n",
      "Model weights saved in understand/checkpoint-360/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-370\n",
      "Configuration saved in understand/checkpoint-370/config.json\n",
      "Model weights saved in understand/checkpoint-370/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-380\n",
      "Configuration saved in understand/checkpoint-380/config.json\n",
      "Model weights saved in understand/checkpoint-380/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-390\n",
      "Configuration saved in understand/checkpoint-390/config.json\n",
      "Model weights saved in understand/checkpoint-390/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-400\n",
      "Configuration saved in understand/checkpoint-400/config.json\n",
      "Model weights saved in understand/checkpoint-400/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-410\n",
      "Configuration saved in understand/checkpoint-410/config.json\n",
      "Model weights saved in understand/checkpoint-410/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-420\n",
      "Configuration saved in understand/checkpoint-420/config.json\n",
      "Model weights saved in understand/checkpoint-420/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-430\n",
      "Configuration saved in understand/checkpoint-430/config.json\n",
      "Model weights saved in understand/checkpoint-430/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-440\n",
      "Configuration saved in understand/checkpoint-440/config.json\n",
      "Model weights saved in understand/checkpoint-440/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-450\n",
      "Configuration saved in understand/checkpoint-450/config.json\n",
      "Model weights saved in understand/checkpoint-450/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-460\n",
      "Configuration saved in understand/checkpoint-460/config.json\n",
      "Model weights saved in understand/checkpoint-460/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-470\n",
      "Configuration saved in understand/checkpoint-470/config.json\n",
      "Model weights saved in understand/checkpoint-470/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-480\n",
      "Configuration saved in understand/checkpoint-480/config.json\n",
      "Model weights saved in understand/checkpoint-480/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-490\n",
      "Configuration saved in understand/checkpoint-490/config.json\n",
      "Model weights saved in understand/checkpoint-490/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-500\n",
      "Configuration saved in understand/checkpoint-500/config.json\n",
      "Model weights saved in understand/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-510\n",
      "Configuration saved in understand/checkpoint-510/config.json\n",
      "Model weights saved in understand/checkpoint-510/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-520\n",
      "Configuration saved in understand/checkpoint-520/config.json\n",
      "Model weights saved in understand/checkpoint-520/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-530\n",
      "Configuration saved in understand/checkpoint-530/config.json\n",
      "Model weights saved in understand/checkpoint-530/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-540\n",
      "Configuration saved in understand/checkpoint-540/config.json\n",
      "Model weights saved in understand/checkpoint-540/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-550\n",
      "Configuration saved in understand/checkpoint-550/config.json\n",
      "Model weights saved in understand/checkpoint-550/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-560\n",
      "Configuration saved in understand/checkpoint-560/config.json\n",
      "Model weights saved in understand/checkpoint-560/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-570\n",
      "Configuration saved in understand/checkpoint-570/config.json\n",
      "Model weights saved in understand/checkpoint-570/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-580\n",
      "Configuration saved in understand/checkpoint-580/config.json\n",
      "Model weights saved in understand/checkpoint-580/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-590\n",
      "Configuration saved in understand/checkpoint-590/config.json\n",
      "Model weights saved in understand/checkpoint-590/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-600\n",
      "Configuration saved in understand/checkpoint-600/config.json\n",
      "Model weights saved in understand/checkpoint-600/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-610\n",
      "Configuration saved in understand/checkpoint-610/config.json\n",
      "Model weights saved in understand/checkpoint-610/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-620\n",
      "Configuration saved in understand/checkpoint-620/config.json\n",
      "Model weights saved in understand/checkpoint-620/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-630\n",
      "Configuration saved in understand/checkpoint-630/config.json\n",
      "Model weights saved in understand/checkpoint-630/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to understand/checkpoint-640\n",
      "Configuration saved in understand/checkpoint-640/config.json\n",
      "Model weights saved in understand/checkpoint-640/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from understand/checkpoint-560 (score: 0.9596052671859214).\n",
      "Saving model checkpoint to understand\n",
      "Configuration saved in understand/config.json\n",
      "Model weights saved in understand/pytorch_model.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 4276\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed. Started testing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.970533208606174\n",
      "Kappa Score ->  0.9264205240709017\n",
      "ROC AUC Score ->  0.9594435413957519\n",
      "F1 Score ->  0.9467905405405406\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      3076\n",
      "           1       0.96      0.93      0.95      1200\n",
      "\n",
      "    accuracy                           0.97      4276\n",
      "   macro avg       0.97      0.96      0.96      4276\n",
      "weighted avg       0.97      0.97      0.97      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if RUN_DL:\n",
    "    understand_bert = createBERT('understand', understand_x_bert, understand_y, split_test_x['Learning_outcome'].tolist(), split_test_y['Understand'].astype('long').to_numpy(), 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82734e5d",
   "metadata": {},
   "source": [
    "#### Traditional ML Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d588d0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Unigram...\n",
      "Getting Bigram...\n",
      "Getting Tfidf...\n",
      "Getting ARI...\n",
      "Combining...\n",
      "Generated feature shape is (17104, 3094)\n",
      "Generated test feature is (4276, 3094)\n"
     ]
    }
   ],
   "source": [
    "combined_understand_x, column_names_understand, test_understand_x = generateX(understand_x, split_test_x.to_numpy(), 0, 1, 94)\n",
    "train_understand_x = combined_understand_x\n",
    "train_understand_y = understand_y\n",
    "test_understand_y = split_test_y['Understand'].astype('long').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "25639c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_understand += data.columns[8:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18727e9d",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "93869378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "gnb_understand = GaussianNB()\n",
    "gnb_understand_gs = GridSearchCV(gnb_understand, params_nb, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "gnb_understand_gs.fit(train_understand_x, train_understand_y)\n",
    "pred_understand_y_gnb = gnb_understand_gs.predict(test_understand_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "408b0310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 1e-08}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_understand_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5c306209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.641955098222638\n",
      "Kappa Score ->  0.3273875303759528\n",
      "ROC AUC Score ->  0.7158154529692242\n",
      "F1 Score ->  0.5808924171913495\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.55      0.69      3076\n",
      "           1       0.43      0.88      0.58      1200\n",
      "\n",
      "    accuracy                           0.64      4276\n",
      "   macro avg       0.68      0.72      0.63      4276\n",
      "weighted avg       0.79      0.64      0.66      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_understand_y, pred_understand_y_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80641010",
   "metadata": {},
   "source": [
    "##### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d8c7b3be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV 1/3] END ...............var_smoothing=1e-09;, score=0.551 total time=   3.1s\n",
      "[CV 3/3] END .C=0.1, gamma=scale, kernel=linear;, score=0.854 total time= 4.5min\n",
      "[CV 2/3] END ....C=0.1, gamma=auto, kernel=poly;, score=0.800 total time= 4.4min\n",
      "[CV 1/3] END ......C=1, gamma=scale, kernel=rbf;, score=0.407 total time= 4.5min\n",
      "[CV 1/3] END .......C=1, gamma=auto, kernel=rbf;, score=0.523 total time= 4.8min\n",
      "[CV 2/3] END ....C=10, gamma=scale, kernel=poly;, score=0.603 total time= 3.8min\n",
      "[CV 3/3] END ...C=10, gamma=auto, kernel=linear;, score=0.801 total time=19.5min\n",
      "[CV 3/3] END ....C=100, gamma=scale, kernel=rbf;, score=0.775 total time= 4.1min\n",
      "[CV 3/3] END ....C=100, gamma=auto, kernel=poly;, score=0.776 total time= 4.6min\n",
      "[CV 3/3] END ...............var_smoothing=1e-10;, score=0.546 total time=   2.5s\n",
      "[CV 2/3] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.000 total time= 4.9min\n",
      "[CV 1/3] END ...C=1, gamma=scale, kernel=linear;, score=0.830 total time= 8.2min\n",
      "[CV 2/3] END ......C=1, gamma=auto, kernel=poly;, score=0.823 total time= 5.1min\n",
      "[CV 1/3] END ....C=10, gamma=scale, kernel=poly;, score=0.619 total time= 3.8min\n",
      "[CV 2/3] END ...C=10, gamma=auto, kernel=linear;, score=0.800 total time=24.9min\n",
      "[CV 1/3] END .....C=100, gamma=auto, kernel=rbf;, score=0.661 total time= 8.5min\n",
      "[CV 2/3] END ...............var_smoothing=1e-09;, score=0.557 total time=   3.0s\n",
      "[CV 3/3] END ...C=0.1, gamma=scale, kernel=poly;, score=0.012 total time= 4.2min\n",
      "[CV 1/3] END ....C=0.1, gamma=auto, kernel=poly;, score=0.798 total time= 4.4min\n",
      "[CV 3/3] END ...C=1, gamma=scale, kernel=linear;, score=0.841 total time= 7.8min\n",
      "[CV 1/3] END ..C=10, gamma=scale, kernel=linear;, score=0.795 total time=24.0min\n",
      "[CV 1/3] END ....C=100, gamma=scale, kernel=rbf;, score=0.781 total time= 4.1min\n",
      "[CV 1/3] END ....C=100, gamma=auto, kernel=poly;, score=0.782 total time= 4.9min\n",
      "[CV 2/3] END .....C=100, gamma=auto, kernel=rbf;, score=0.663 total time= 8.3min\n",
      "[CV 1/3] END ...............var_smoothing=1e-08;, score=0.563 total time=   3.1s\n",
      "[CV 1/3] END ...............var_smoothing=1e-10;, score=0.539 total time=   2.7s\n",
      "[CV 1/3] END ..C=0.1, gamma=auto, kernel=linear;, score=0.852 total time= 4.6min\n",
      "[CV 2/3] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.098 total time= 5.2min\n",
      "[CV 3/3] END ......C=1, gamma=scale, kernel=rbf;, score=0.413 total time= 4.5min\n",
      "[CV 3/3] END .......C=1, gamma=auto, kernel=rbf;, score=0.505 total time= 4.7min\n",
      "[CV 2/3] END .....C=10, gamma=scale, kernel=rbf;, score=0.577 total time= 4.3min\n",
      "[CV 3/3] END .....C=10, gamma=auto, kernel=poly;, score=0.776 total time= 4.7min\n",
      "[CV 3/3] END ......C=10, gamma=auto, kernel=rbf;, score=0.644 total time= 5.0min\n",
      "[CV 1/3] END ...C=100, gamma=scale, kernel=poly;, score=0.798 total time= 3.6min\n",
      "[CV 2/3] END ...C=100, gamma=scale, kernel=poly;, score=0.801 total time= 3.7min\n",
      "[CV 2/3] END ....C=100, gamma=scale, kernel=rbf;, score=0.791 total time= 4.1min\n",
      "[CV 2/3] END ....C=100, gamma=auto, kernel=poly;, score=0.785 total time= 4.8min\n",
      "[CV 3/3] END .....C=100, gamma=auto, kernel=rbf;, score=0.648 total time= 8.4min\n",
      "[CV 2/3] END ...............var_smoothing=1e-08;, score=0.572 total time=   3.2s\n",
      "[CV 2/3] END .C=0.1, gamma=scale, kernel=linear;, score=0.857 total time= 4.6min\n",
      "[CV 1/3] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.111 total time= 5.2min\n",
      "[CV 2/3] END ......C=1, gamma=scale, kernel=rbf;, score=0.387 total time= 4.5min\n",
      "[CV 2/3] END .......C=1, gamma=auto, kernel=rbf;, score=0.494 total time= 4.8min\n",
      "[CV 1/3] END .....C=10, gamma=scale, kernel=rbf;, score=0.590 total time= 4.4min\n",
      "[CV 2/3] END .....C=10, gamma=auto, kernel=poly;, score=0.789 total time= 4.9min\n",
      "[CV 1/3] END .C=100, gamma=scale, kernel=linear;, score=0.743 total time=68.4min\n",
      "[CV 2/3] END ...............var_smoothing=1e-10;, score=0.541 total time=   2.6s\n",
      "[CV 1/3] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.000 total time= 4.9min\n",
      "[CV 3/3] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.108 total time= 5.1min\n",
      "[CV 1/3] END ....C=1, gamma=auto, kernel=linear;, score=0.830 total time= 7.9min\n",
      "[CV 3/3] END ..C=10, gamma=scale, kernel=linear;, score=0.801 total time=20.6min\n",
      "[CV 3/3] END ...C=100, gamma=scale, kernel=poly;, score=0.785 total time= 3.6min\n",
      "[CV 1/3] END ..C=100, gamma=auto, kernel=linear;, score=0.743 total time=65.0min\n",
      "[CV 3/3] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.000 total time= 4.9min\n",
      "[CV 2/3] END ...C=1, gamma=scale, kernel=linear;, score=0.839 total time= 8.4min\n",
      "[CV 3/3] END ......C=1, gamma=auto, kernel=poly;, score=0.811 total time= 5.0min\n",
      "[CV 3/3] END ....C=10, gamma=scale, kernel=poly;, score=0.608 total time= 3.8min\n",
      "[CV 1/3] END .....C=10, gamma=auto, kernel=poly;, score=0.787 total time= 5.1min\n",
      "[CV 2/3] END ......C=10, gamma=auto, kernel=rbf;, score=0.647 total time= 5.1min\n",
      "[CV 3/3] END .C=100, gamma=scale, kernel=linear;, score=0.775 total time=92.8min\n",
      "[CV 3/3] END ...............var_smoothing=1e-09;, score=0.558 total time=   3.1s\n",
      "[CV 1/3] END ...C=0.1, gamma=scale, kernel=poly;, score=0.006 total time= 4.2min\n",
      "[CV 2/3] END ..C=0.1, gamma=auto, kernel=linear;, score=0.857 total time= 4.6min\n",
      "[CV 2/3] END .....C=1, gamma=scale, kernel=poly;, score=0.415 total time= 3.8min\n",
      "[CV 3/3] END ....C=1, gamma=auto, kernel=linear;, score=0.841 total time= 7.7min\n",
      "[CV 3/3] END .....C=10, gamma=scale, kernel=rbf;, score=0.579 total time= 4.3min\n",
      "[CV 1/3] END ......C=10, gamma=auto, kernel=rbf;, score=0.657 total time= 5.2min\n",
      "[CV 2/3] END .C=100, gamma=scale, kernel=linear;, score=0.772 total time=98.3min\n",
      "[CV 3/3] END ...............var_smoothing=1e-08;, score=0.573 total time=   3.1s\n",
      "[CV 2/3] END ...C=0.1, gamma=scale, kernel=poly;, score=0.008 total time= 4.2min\n",
      "[CV 3/3] END ..C=0.1, gamma=auto, kernel=linear;, score=0.854 total time= 4.6min\n",
      "[CV 1/3] END .....C=1, gamma=scale, kernel=poly;, score=0.424 total time= 3.8min\n",
      "[CV 2/3] END ....C=1, gamma=auto, kernel=linear;, score=0.839 total time= 8.1min\n",
      "[CV 1/3] END ...C=10, gamma=auto, kernel=linear;, score=0.795 total time=23.0min\n",
      "[CV 3/3] END ..C=100, gamma=auto, kernel=linear;, score=0.775 total time=89.5min\n",
      "[CV 1/3] END .C=0.1, gamma=scale, kernel=linear;, score=0.852 total time= 4.6min\n",
      "[CV 3/3] END ....C=0.1, gamma=auto, kernel=poly;, score=0.785 total time= 4.4min\n",
      "[CV 3/3] END .....C=1, gamma=scale, kernel=poly;, score=0.424 total time= 3.8min\n",
      "[CV 1/3] END ......C=1, gamma=auto, kernel=poly;, score=0.813 total time= 5.2min\n",
      "[CV 2/3] END ..C=10, gamma=scale, kernel=linear;, score=0.800 total time=25.4min\n",
      "[CV 2/3] END ..C=100, gamma=auto, kernel=linear;, score=0.772 total time=94.1min\n"
     ]
    }
   ],
   "source": [
    "svm_understand = SVC()\n",
    "svm_understand_gs = GridSearchCV(svm_understand, params_svm, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "svm_understand_gs.fit(train_understand_x, train_understand_y)\n",
    "pred_understand_y_svm = svm_understand_gs.predict(test_understand_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "49bf27f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_understand_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0d9baeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9216557530402245\n",
      "Kappa Score ->  0.8012661606685524\n",
      "ROC AUC Score ->  0.8911649328131773\n",
      "F1 Score ->  0.8547897702644125\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      3076\n",
      "           1       0.89      0.82      0.85      1200\n",
      "\n",
      "    accuracy                           0.92      4276\n",
      "   macro avg       0.91      0.89      0.90      4276\n",
      "weighted avg       0.92      0.92      0.92      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_understand_y, pred_understand_y_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f518ebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_understand = SVC(C=0.1, gamma='scale', kernel='linear')\n",
    "svm_understand.fit(train_understand_x, train_understand_y)\n",
    "pred_understand_y = svm_understand.predict(test_understand_x)\n",
    "performancePrinter(test_understand_y, pred_understand_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d5db21",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7ac26c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr_understand = LogisticRegression()\n",
    "lr_understand_gs = GridSearchCV(lr_understand, params_lr, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "lr_understand_gs.fit(train_understand_x, train_understand_y)\n",
    "pred_understand_y_lr = lr_understand_gs.predict(test_understand_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e26a2a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_understand_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8885bd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.8905519176800748\n",
      "Kappa Score ->  0.7141064411940176\n",
      "ROC AUC Score ->  0.8385435630689206\n",
      "F1 Score ->  0.7868852459016394\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93      3076\n",
      "           1       0.87      0.72      0.79      1200\n",
      "\n",
      "    accuracy                           0.89      4276\n",
      "   macro avg       0.88      0.84      0.86      4276\n",
      "weighted avg       0.89      0.89      0.89      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_understand_y, pred_understand_y_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a67d80f",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "85b184c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    }
   ],
   "source": [
    "rf_understand = RandomForestClassifier()\n",
    "rf_understand_gs = GridSearchCV(rf_understand, params_rf, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "rf_understand_gs.fit(train_understand_x, train_understand_y)\n",
    "pred_understand_y_rf = rf_understand_gs.predict(test_understand_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6fd0b01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 250}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_understand_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0c1bba54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9197848456501403\n",
      "Kappa Score ->  0.7926343798689639\n",
      "ROC AUC Score ->  0.8796998266146511\n",
      "F1 Score ->  0.8465324384787473\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95      3076\n",
      "           1       0.91      0.79      0.85      1200\n",
      "\n",
      "    accuracy                           0.92      4276\n",
      "   macro avg       0.92      0.88      0.90      4276\n",
      "weighted avg       0.92      0.92      0.92      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_understand_y, pred_understand_y_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48ad15f",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "88d1469c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:23:13] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.673 total time=  54.6s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.589 total time=  16.6s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.679 total time=  37.6s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.587 total time=  16.3s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.763 total time= 1.4min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.759 total time= 1.5min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.692 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.693 total time=  36.3s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.762 total time= 3.6min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.588 total time=  27.1s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.695 total time= 1.0min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.589 total time=  16.9s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.694 total time=  37.8s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.764 total time= 2.6min\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.768 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.825 total time=  11.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.817 total time=   7.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.818 total time=  26.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.804 total time=  23.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.794 total time=  20.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.787 total time=   5.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.814 total time=   6.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.826 total time=  26.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.815 total time=  11.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.803 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.803 total time=   6.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.813 total time=  24.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.798 total time=   5.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.795 total time=   5.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.790 total time=  19.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.012 total time=   2.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.001 total time=   3.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.001 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.018 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.005 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.017 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.004 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.004 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.010 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.003 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.008 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.454 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.442 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.397 total time=   4.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.332 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.394 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.389 total time=   8.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.335 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.402 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.408 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.363 total time=   9.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.420 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.341 total time=   3.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.449 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.372 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.340 total time=   8.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.325 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.290 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.828 total time=  10.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.840 total time=  45.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.821 total time=  16.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.821 total time=  10.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.820 total time=  10.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.826 total time=  40.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.813 total time=  15.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.804 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.806 total time=  36.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.834 total time=  19.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.833 total time=  10.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.835 total time=  44.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.824 total time=  40.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.802 total time=  15.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.804 total time=  15.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.807 total time=   7.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.809 total time=  32.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.012 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.000 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.009 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.001 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.021 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.009 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.019 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.005 total time=   7.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.001 total time=   7.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.004 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.009 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.003 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.009 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.004 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.022 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.004 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.376 total time=  13.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.426 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.394 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.455 total time=  13.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.431 total time=   6.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.314 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.471 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.498 total time=   6.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.399 total time=   6.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.404 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.451 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.384 total time=  13.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.395 total time=  13.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.415 total time=  13.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.321 total time=   4.4s\n",
      "[09:03:23] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:05:02] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:08:25] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:10:20] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:12:33] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:15:22] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:17:27] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.575 total time=  23.7s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.608 total time=  16.0s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.694 total time=  37.1s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.695 total time=  37.8s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.617 total time=  16.7s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.749 total time= 1.5min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.620 total time=  17.1s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.609 total time=  33.7s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.677 total time= 1.4min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.693 total time=  37.3s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.609 total time=  35.0s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.620 total time=  16.7s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.751 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.610 total time=  16.2s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.751 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.693 total time= 1.0min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.693 total time=  38.1s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.695 total time=  37.1s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.751 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.768 total time= 1.4min\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.821 total time=  10.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.828 total time=  26.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.807 total time=  11.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.805 total time=  10.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.784 total time=   5.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.780 total time=   9.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.793 total time=   9.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.785 total time=   5.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.793 total time=  21.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.816 total time=  11.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.813 total time=   6.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.817 total time=  25.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.811 total time=  11.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.802 total time=  10.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.791 total time=  19.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.787 total time=   5.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.785 total time=  19.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.000 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.006 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.003 total time=   2.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.010 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.003 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.004 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.005 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.005 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.005 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.001 total time=   5.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.001 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.004 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.010 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.005 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.001 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.006 total time=   5.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.437 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.399 total time=   8.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.421 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.400 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.379 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.341 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.407 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.270 total time=   4.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.516 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.421 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.424 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.359 total time=   9.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.427 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.360 total time=   8.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.826 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.829 total time=  10.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.837 total time=  45.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.826 total time=  42.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.825 total time=  18.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.804 total time=   7.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.798 total time=   9.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.810 total time=  16.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.810 total time=  15.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.835 total time=  20.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.834 total time=  45.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.820 total time=  18.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.830 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.826 total time=  10.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.830 total time=  18.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.808 total time=  15.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.810 total time=   8.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.812 total time=  36.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.005 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.004 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.000 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.009 total time=   7.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.010 total time=   7.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.006 total time=   7.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.001 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.006 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.013 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.008 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.003 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.010 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.000 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.003 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.018 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.008 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.014 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.410 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.401 total time=  13.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.436 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.402 total time=  13.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.389 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.398 total time=  13.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.393 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.362 total time=  13.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.451 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.388 total time=  13.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.444 total time=  13.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.389 total time=   6.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.394 total time=   7.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.359 total time=  13.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.386 total time=  13.6s\n",
      "[09:03:33] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:05:36] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:07:55] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:10:42] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:15:20] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:18:28] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.662 total time=  54.8s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.609 total time=  16.7s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.694 total time=  37.6s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.608 total time=  16.3s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.759 total time= 1.5min\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.589 total time=  17.2s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.765 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.679 total time=  36.4s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.695 total time=  36.4s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.616 total time=  36.9s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.751 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.768 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.751 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.609 total time=  16.4s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.693 total time=  38.0s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.620 total time=  27.1s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.589 total time=  16.2s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.768 total time= 1.5min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.765 total time= 1.4min\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.818 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.819 total time=   7.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.824 total time=  27.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.809 total time=  25.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.806 total time=  11.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.786 total time=   5.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.787 total time=  22.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.789 total time=   9.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.817 total time=   6.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.829 total time=   6.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.820 total time=  26.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.815 total time=  11.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.805 total time=  11.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.806 total time=  10.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.791 total time=  20.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.792 total time=  10.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.000 total time=   6.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.001 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.008 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.004 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.003 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.018 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.000 total time=   5.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.018 total time=   2.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.013 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.004 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.013 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.009 total time=   5.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.017 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.022 total time=   2.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.001 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.006 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.470 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.398 total time=   8.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.422 total time=   3.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.351 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.431 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.354 total time=   8.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.504 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.482 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.413 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.361 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.390 total time=   8.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.455 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.488 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.469 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.351 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.841 total time=  46.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.837 total time=  46.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.827 total time=  42.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.807 total time=  37.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.810 total time=  38.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.832 total time=  10.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.831 total time=  12.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.832 total time=  20.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.824 total time=  17.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.819 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.827 total time=  42.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.803 total time=  36.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.808 total time=  33.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.001 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.018 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.006 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.003 total time=   7.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.005 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.003 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.005 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.015 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.009 total time=   7.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.003 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.003 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.006 total time=   7.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.006 total time=   8.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.004 total time=   8.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.004 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.484 total time=   6.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.351 total time=   6.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.437 total time=   6.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.324 total time=   6.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.382 total time=  14.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.408 total time=   6.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.329 total time=  13.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.412 total time=   6.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.365 total time=  14.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.400 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.374 total time=  13.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.375 total time=   6.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.410 total time=   6.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.342 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.477 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.393 total time=  10.8s\n",
      "[09:03:27] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:06:21] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:10:49] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:12:12] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:13:41] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:15:36] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:19:59] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.588 total time=  16.4s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.690 total time=  37.1s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.696 total time=  37.0s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.738 total time= 2.2min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.765 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.589 total time=  16.4s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.692 total time=  36.4s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.609 total time=  16.8s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.680 total time=  36.6s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.765 total time= 3.5min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.620 total time=  27.7s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.695 total time= 1.0min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.679 total time=  37.4s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.768 total time= 2.5min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.765 total time= 1.3min\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.822 total time=  26.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.813 total time=  12.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.809 total time=  11.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.800 total time=   5.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.802 total time=   5.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.810 total time=  23.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.789 total time=   5.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.787 total time=  20.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.826 total time=  12.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.824 total time=  12.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.816 total time=  11.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.810 total time=  10.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.803 total time=   6.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.813 total time=  24.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.785 total time=   8.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.789 total time=   5.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.788 total time=  20.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.012 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.015 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.006 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.013 total time=   2.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.004 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.012 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.004 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.004 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.005 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.006 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.010 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.003 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.019 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.001 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.360 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.400 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.235 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.247 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.348 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.414 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.329 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.309 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.332 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.395 total time=   8.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.389 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.403 total time=   8.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.380 total time=   8.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.439 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.838 total time=   8.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.839 total time=  11.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.839 total time=  46.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.825 total time=  17.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.822 total time=  17.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.817 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.826 total time=  40.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.806 total time=  35.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.830 total time=  19.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.836 total time=   9.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.837 total time=  44.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.825 total time=  41.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.822 total time=  17.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.807 total time=   8.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.810 total time=  36.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.806 total time=  15.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.014 total time=   3.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.000 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.001 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.051 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.005 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.009 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.001 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.010 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.006 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.019 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.001 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.009 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.012 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.003 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.000 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.004 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.420 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.435 total time=  13.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.434 total time=  13.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.383 total time=   6.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.425 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.476 total time=  13.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.287 total time=   7.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.444 total time=   6.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.434 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.351 total time=  13.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.396 total time=   6.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.321 total time=   6.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.339 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.448 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.379 total time=  13.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.406 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.404 total time=  13.6s\n",
      "[09:03:44] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:07:14] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:08:40] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:10:36] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:12:57] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:15:39] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:16:54] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:18:18] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:20:07] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.593 total time=  24.8s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.678 total time=  36.7s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.693 total time=  37.1s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.744 total time= 2.2min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.768 total time= 1.5min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.692 total time= 1.4min\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.749 total time= 3.5min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.765 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.590 total time=  16.4s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.695 total time=  37.6s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.589 total time=  27.2s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.751 total time= 2.6min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.765 total time= 1.3min\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.820 total time=  10.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.823 total time=  12.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.822 total time=  11.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.799 total time=   6.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.812 total time=  24.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.809 total time=  10.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.790 total time=   9.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.783 total time=   9.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.789 total time=  21.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.820 total time=   6.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.820 total time=   6.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.823 total time=  11.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.808 total time=  23.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.798 total time=   5.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.788 total time=   6.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.787 total time=   9.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.788 total time=   9.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.787 total time=   9.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.033 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.006 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.018 total time=   5.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.001 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.004 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.000 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.009 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.027 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.005 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.010 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.017 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.003 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.012 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.000 total time=   2.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.013 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.013 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.026 total time=   2.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.009 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.003 total time=   5.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.355 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.435 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.314 total time=   8.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.416 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.481 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.390 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.283 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.411 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.432 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.384 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.346 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.457 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.457 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.368 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.381 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.831 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.836 total time=  19.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.825 total time=  11.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.830 total time=  19.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.828 total time=  17.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.833 total time=  10.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.826 total time=  41.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.807 total time=  36.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.829 total time=  10.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.833 total time=  20.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.837 total time=  20.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.833 total time=  19.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.817 total time=   8.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.825 total time=  41.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.822 total time=  40.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.810 total time=  16.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.798 total time=   7.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.003 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.004 total time=   3.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.000 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.005 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.012 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.001 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.001 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.021 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.006 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.000 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.010 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.009 total time=   3.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.003 total time=   7.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.001 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.008 total time=   7.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.001 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.000 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.507 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.309 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.412 total time=   6.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.419 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.467 total time=  13.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.353 total time=   6.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.428 total time=   6.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.426 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.379 total time=  13.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.366 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.393 total time=   6.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.477 total time=   6.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.402 total time=  13.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.465 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.454 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.285 total time=  13.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.421 total time=   6.7s\n",
      "[09:03:25] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:05:06] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:07:24] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:08:51] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:12:17] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:13:44] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:16:58] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:18:22] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:20:11] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_understand = XGBClassifier()\n",
    "xgb_understand_gs = GridSearchCV(xgb_understand, params_xgb, scoring=\"f1\", n_jobs=-1, cv=3)\n",
    "xgb_understand_gs.fit(train_understand_x, train_understand_y)\n",
    "pred_understand_y_xgb = xgb_understand_gs.predict(test_understand_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ca14df5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.1, 'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 100}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_understand_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8566c676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9282039289055192\n",
      "Kappa Score ->  0.8182551703323023\n",
      "ROC AUC Score ->  0.9002904204594712\n",
      "F1 Score ->  0.8673866090712743\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3076\n",
      "           1       0.90      0.84      0.87      1200\n",
      "\n",
      "    accuracy                           0.93      4276\n",
      "   macro avg       0.92      0.90      0.91      4276\n",
      "weighted avg       0.93      0.93      0.93      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_understand_y, pred_understand_y_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9b90c5",
   "metadata": {},
   "source": [
    "### Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4f6b46",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "165f4af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_x, apply_y = split_train_x.to_numpy(), split_train_y['Apply'].astype('long').to_numpy()#rus(split_train_x, split_train_y['Apply'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "65581878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17104, 94)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0274db",
   "metadata": {},
   "source": [
    "#### BERT Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cf8bece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_x_bert = apply_x[:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "63ae4661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.662 total time=  54.0s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.690 total time=  37.0s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.594 total time=  25.6s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.748 total time= 1.4min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.764 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.688 total time= 1.4min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.589 total time=  16.6s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.695 total time=  36.6s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.749 total time= 3.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.609 total time=  26.9s\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.680 total time= 1.0min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.609 total time=  16.5s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.696 total time=  37.7s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.768 total time= 2.5min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.822 total time=   5.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.819 total time=  26.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.818 total time=  26.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.810 total time=  10.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.801 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.810 total time=  23.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.789 total time=   9.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.786 total time=   9.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.819 total time=  26.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.808 total time=   6.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.807 total time=  24.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.807 total time=  10.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.791 total time=   5.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.789 total time=  20.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.788 total time=  18.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.003 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.001 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.003 total time=   5.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.001 total time=   5.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.029 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.006 total time=   5.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.001 total time=   5.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.012 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.004 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.001 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.005 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.021 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.010 total time=   2.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.006 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.001 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.492 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.411 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.463 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.436 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.349 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.422 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.336 total time=   8.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.550 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.465 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.370 total time=   8.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.338 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.314 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.418 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.394 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.405 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.460 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.348 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.836 total time=  17.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.836 total time=  19.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.835 total time=  19.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.817 total time=   8.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.825 total time=  41.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.825 total time=  40.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.807 total time=  36.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.836 total time=  45.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.829 total time=  19.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.834 total time=  18.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.826 total time=  17.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.817 total time=   8.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.828 total time=  41.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.805 total time=   9.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.803 total time=  16.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.019 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.003 total time=   3.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.001 total time=   7.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.009 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.012 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.003 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.003 total time=   7.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.036 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.000 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.015 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.000 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.013 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.024 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.013 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.029 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.392 total time=   6.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.413 total time=   6.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.357 total time=   6.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.322 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.379 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.428 total time=  13.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.370 total time=  13.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.544 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.451 total time=   6.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.421 total time=   6.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.360 total time=  13.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.361 total time=   6.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.378 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.391 total time=  13.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.386 total time=   6.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.491 total time=   6.6s\n",
      "[09:03:24] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:04:58] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:08:22] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:10:16] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:13:36] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:15:30] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:19:49] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.598 total time=  23.5s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.617 total time=  16.5s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.679 total time=  37.0s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.599 total time=  24.6s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.744 total time= 2.2min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.768 total time= 1.5min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.620 total time=  16.8s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.679 total time=  37.0s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.679 total time=  36.3s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.765 total time= 3.5min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.768 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.679 total time=  37.9s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.694 total time=  37.0s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.608 total time=  16.3s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.765 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.588 total time=  16.6s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.751 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.819 total time=  10.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.820 total time=  12.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.818 total time=   6.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.825 total time=  26.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.809 total time=  23.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.780 total time=  20.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.788 total time=   9.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.821 total time=  12.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.820 total time=  11.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.817 total time=   6.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.818 total time=  25.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.799 total time=   6.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.808 total time=  23.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.788 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.784 total time=   5.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.000 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.005 total time=   6.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.012 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.005 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.014 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.003 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.001 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.001 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.013 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.012 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.018 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.012 total time=   2.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.004 total time=   5.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.008 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.004 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.000 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.008 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.001 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.004 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.437 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.303 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.400 total time=   8.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.340 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.337 total time=   8.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.465 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.422 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.464 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.360 total time=   8.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.273 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.540 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.352 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.411 total time=   8.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.353 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.434 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.403 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.365 total time=   9.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.839 total time=  44.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.831 total time=  44.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.826 total time=  41.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.806 total time=  16.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.806 total time=  16.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.809 total time=   7.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.813 total time=  37.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.837 total time=  45.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.822 total time=  41.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.817 total time=  17.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.807 total time=   8.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.812 total time=   9.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.801 total time=  16.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.805 total time=  33.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.004 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.003 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.000 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.008 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.004 total time=   7.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.004 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.000 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.000 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.000 total time=   3.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.019 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.003 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.006 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.358 total time=  13.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.384 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.343 total time=  13.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.399 total time=   6.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.431 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.339 total time=  13.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.301 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.470 total time=  13.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.400 total time=   6.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.440 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.345 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.407 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.388 total time=  13.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.499 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.283 total time=  13.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.448 total time=  11.2s\n",
      "[09:03:31] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:06:23] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:07:44] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:10:33] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:12:52] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:15:34] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:19:54] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /Users/ylii0447/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /Users/ylii0447/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /Users/ylii0447/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "using `logging_steps` to initialize `eval_steps` to 10\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 13683\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training model for column apply\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='642' max='642' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [642/642 1:19:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.579700</td>\n",
       "      <td>0.477144</td>\n",
       "      <td>0.644891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.403300</td>\n",
       "      <td>0.365935</td>\n",
       "      <td>0.819933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.311400</td>\n",
       "      <td>0.268655</td>\n",
       "      <td>0.887379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.288300</td>\n",
       "      <td>0.272360</td>\n",
       "      <td>0.882373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>0.227896</td>\n",
       "      <td>0.904492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.287900</td>\n",
       "      <td>0.211766</td>\n",
       "      <td>0.913097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.181607</td>\n",
       "      <td>0.924221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.180069</td>\n",
       "      <td>0.921146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.178776</td>\n",
       "      <td>0.923498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.185473</td>\n",
       "      <td>0.912232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.203400</td>\n",
       "      <td>0.210281</td>\n",
       "      <td>0.908197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.201513</td>\n",
       "      <td>0.917210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.166438</td>\n",
       "      <td>0.928663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.162300</td>\n",
       "      <td>0.163216</td>\n",
       "      <td>0.929134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>0.151391</td>\n",
       "      <td>0.938871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.154400</td>\n",
       "      <td>0.156330</td>\n",
       "      <td>0.933942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.143708</td>\n",
       "      <td>0.934291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>0.138235</td>\n",
       "      <td>0.936622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>0.159568</td>\n",
       "      <td>0.934378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.144201</td>\n",
       "      <td>0.933178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>0.145370</td>\n",
       "      <td>0.929950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.148600</td>\n",
       "      <td>0.129463</td>\n",
       "      <td>0.938911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.140563</td>\n",
       "      <td>0.940129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.105700</td>\n",
       "      <td>0.143649</td>\n",
       "      <td>0.938646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.133616</td>\n",
       "      <td>0.936815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.115300</td>\n",
       "      <td>0.141892</td>\n",
       "      <td>0.939137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.139100</td>\n",
       "      <td>0.131803</td>\n",
       "      <td>0.943908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>0.135227</td>\n",
       "      <td>0.941360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.133272</td>\n",
       "      <td>0.939716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>0.122320</td>\n",
       "      <td>0.946681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.127500</td>\n",
       "      <td>0.121788</td>\n",
       "      <td>0.943947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.143900</td>\n",
       "      <td>0.112838</td>\n",
       "      <td>0.950422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.117500</td>\n",
       "      <td>0.135309</td>\n",
       "      <td>0.942134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.110704</td>\n",
       "      <td>0.947332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.119631</td>\n",
       "      <td>0.949440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.115110</td>\n",
       "      <td>0.952230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.099800</td>\n",
       "      <td>0.116717</td>\n",
       "      <td>0.951094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>0.113641</td>\n",
       "      <td>0.952367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.109025</td>\n",
       "      <td>0.953594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.104200</td>\n",
       "      <td>0.104454</td>\n",
       "      <td>0.954271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.102621</td>\n",
       "      <td>0.954526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.100600</td>\n",
       "      <td>0.114016</td>\n",
       "      <td>0.955253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.115502</td>\n",
       "      <td>0.949807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.141088</td>\n",
       "      <td>0.948275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.113415</td>\n",
       "      <td>0.954702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.058800</td>\n",
       "      <td>0.113652</td>\n",
       "      <td>0.954678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.115592</td>\n",
       "      <td>0.956184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.115772</td>\n",
       "      <td>0.958245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.118308</td>\n",
       "      <td>0.955695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.124546</td>\n",
       "      <td>0.956044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.121808</td>\n",
       "      <td>0.955431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.119458</td>\n",
       "      <td>0.953317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.118809</td>\n",
       "      <td>0.954128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.111697</td>\n",
       "      <td>0.958939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.106876</td>\n",
       "      <td>0.960405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>0.107786</td>\n",
       "      <td>0.959558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.091500</td>\n",
       "      <td>0.110098</td>\n",
       "      <td>0.958547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.106340</td>\n",
       "      <td>0.959507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.107085</td>\n",
       "      <td>0.960306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.106887</td>\n",
       "      <td>0.959312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.106201</td>\n",
       "      <td>0.959016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.108651</td>\n",
       "      <td>0.959430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.109444</td>\n",
       "      <td>0.959055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.108789</td>\n",
       "      <td>0.959430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.671 total time=  54.2s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.620 total time=  17.3s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.575 total time=  25.1s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.748 total time= 2.2min\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.751 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.609 total time=  16.3s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.695 total time=  36.4s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.620 total time=  16.6s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.695 total time=  37.2s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.590 total time=  16.1s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.767 total time= 1.5min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.764 total time= 1.5min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.765 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.679 total time=  37.9s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.609 total time=  27.1s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.764 total time= 2.6min\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.819 total time=   6.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.815 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.804 total time=   6.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.808 total time=  24.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.802 total time=   5.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.814 total time=  23.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.787 total time=  20.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.820 total time=  12.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.823 total time=  26.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.808 total time=   5.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.814 total time=  24.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.813 total time=  23.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.784 total time=   9.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.785 total time=   9.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.000 total time=   3.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.003 total time=   2.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.004 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.012 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.005 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.003 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.013 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.005 total time=   2.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.003 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.004 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.008 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.006 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.000 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.386 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.464 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.285 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.448 total time=   8.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.396 total time=   8.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.362 total time=   8.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.325 total time=   8.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.443 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.352 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.389 total time=   8.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.524 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.409 total time=   8.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.285 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.380 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.356 total time=   8.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.465 total time=   8.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.395 total time=   8.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.831 total time=  17.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.834 total time=  11.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.833 total time=  19.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.826 total time=   9.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.821 total time=  43.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.822 total time=  18.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.814 total time=  14.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.806 total time=   8.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.807 total time=  36.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.837 total time=  45.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.832 total time=  45.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.829 total time=  18.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.824 total time=  40.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.810 total time=  36.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.004 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.000 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.018 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.000 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.022 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.013 total time=   7.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.023 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.000 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.000 total time=   7.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.004 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.023 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.013 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.013 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.001 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.015 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.010 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.013 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.000 total time=   7.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.436 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.418 total time=  13.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.365 total time=   6.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.431 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.422 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.428 total time=  13.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.388 total time=   6.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.428 total time=  13.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.373 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.451 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.314 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.340 total time=  13.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.405 total time=   6.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.434 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.410 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.466 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.319 total time=  11.6s\n",
      "[09:03:42] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:05:39] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:10:13] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:13:30] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:15:25] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:17:32] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:20:14] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.671 total time=  54.6s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.694 total time=  37.2s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.738 total time= 2.2min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.607 total time=  17.2s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.587 total time=  34.5s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.616 total time=  35.6s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.677 total time= 1.4min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.694 total time=  36.2s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.762 total time= 3.6min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.679 total time= 1.0min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.619 total time=  16.6s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.695 total time=  38.4s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.751 total time= 2.6min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.620 total time=  16.6s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.751 total time= 1.3min\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.813 total time=   5.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.823 total time=   6.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.823 total time=  26.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.815 total time=   5.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.813 total time=   6.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.807 total time=  10.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.809 total time=  10.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.780 total time=   5.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.785 total time=   5.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.788 total time=  20.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.811 total time=   6.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.826 total time=  26.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.818 total time=  25.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.814 total time=   5.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.810 total time=  23.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.789 total time=   9.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.781 total time=   5.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.788 total time=  20.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.004 total time=   6.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.001 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.005 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.008 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.008 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.005 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.004 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.017 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.063 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.004 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.009 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.022 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.009 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.014 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.006 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.392 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.461 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.387 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.412 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.469 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.375 total time=   9.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.301 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.347 total time=   8.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.395 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.362 total time=   4.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.380 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.402 total time=   3.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.399 total time=   8.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.366 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.434 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.273 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.431 total time=   8.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.348 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.428 total time=   8.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.838 total time=  43.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.835 total time=  44.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.825 total time=  17.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.817 total time=  17.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.802 total time=   8.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.804 total time=  35.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.814 total time=  15.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.830 total time=   9.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.835 total time=  44.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.834 total time=  44.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.825 total time=  40.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.806 total time=  36.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.808 total time=  16.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.000 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.003 total time=   8.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.005 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.012 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.001 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.004 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.000 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.005 total time=   3.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.001 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.012 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.008 total time=   7.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.014 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.001 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.006 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.026 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.014 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.003 total time=   7.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.009 total time=   8.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.333 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.479 total time=  13.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.418 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.369 total time=  13.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.392 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.380 total time=  13.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.417 total time=   6.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.410 total time=  13.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.459 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.455 total time=  13.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.396 total time=   6.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.461 total time=   6.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.454 total time=   6.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.418 total time=   6.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.491 total time=   6.3s\n",
      "[09:03:39] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:05:33] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:07:51] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:10:39] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:15:17] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:18:25] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:20:17] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.673 total time=  54.9s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.679 total time=  37.4s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.748 total time= 2.2min\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.751 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.689 total time= 1.4min\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.587 total time=  35.5s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.610 total time=  16.3s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.764 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.589 total time=  16.1s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.620 total time=  16.5s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.768 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.693 total time= 1.0min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.620 total time=  17.0s\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.679 total time=  37.6s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.620 total time=  16.7s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.751 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.609 total time=  16.2s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.768 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.822 total time=  26.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.817 total time=  11.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.812 total time=  10.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.800 total time=   6.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.810 total time=  23.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.786 total time=   9.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.777 total time=   5.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.788 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.792 total time=  20.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.814 total time=   6.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.824 total time=  26.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.807 total time=  10.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.811 total time=  10.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.806 total time=   5.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.812 total time=  23.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.784 total time=   5.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.789 total time=  19.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.006 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.024 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.015 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.065 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.004 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.001 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.000 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.008 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.006 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.013 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.012 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.000 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.001 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.399 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.396 total time=   8.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.325 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.375 total time=   3.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.395 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.435 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.306 total time=   8.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.442 total time=   8.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.381 total time=   8.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.325 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.441 total time=   4.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.417 total time=   4.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.300 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.395 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.297 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.290 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.447 total time=   8.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.825 total time=  16.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.839 total time=  19.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.832 total time=  10.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.819 total time=  10.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.823 total time=  11.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.820 total time=  18.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.822 total time=   9.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.807 total time=  10.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.808 total time=  15.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.805 total time=   7.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.811 total time=   9.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.803 total time=  15.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.830 total time=   9.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.837 total time=  11.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.833 total time=  19.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.834 total time=  10.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.824 total time=  10.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.820 total time=   9.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.828 total time=  10.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.828 total time=  18.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.822 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.803 total time=   9.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.804 total time=  15.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.809 total time=   8.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.808 total time=  35.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.000 total time=   9.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.001 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.003 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.008 total time=   7.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.000 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.008 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.003 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.003 total time=   7.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.001 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.014 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.005 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.000 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.012 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.000 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.009 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.022 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.005 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.486 total time=   6.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.419 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.473 total time=  13.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.322 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.359 total time=   6.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.411 total time=   6.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.413 total time=   6.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.341 total time=   6.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.312 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.368 total time=  13.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.412 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.461 total time=  13.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.474 total time=   6.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.395 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.296 total time=  13.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.312 total time=   6.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.465 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.326 total time=  13.6s\n",
      "[09:03:28] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:06:18] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:10:47] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:15:28] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:17:36] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:20:15] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to apply/checkpoint-10\n",
      "Configuration saved in apply/checkpoint-10/config.json\n",
      "Model weights saved in apply/checkpoint-10/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-20\n",
      "Configuration saved in apply/checkpoint-20/config.json\n",
      "Model weights saved in apply/checkpoint-20/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-30\n",
      "Configuration saved in apply/checkpoint-30/config.json\n",
      "Model weights saved in apply/checkpoint-30/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-40\n",
      "Configuration saved in apply/checkpoint-40/config.json\n",
      "Model weights saved in apply/checkpoint-40/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-50\n",
      "Configuration saved in apply/checkpoint-50/config.json\n",
      "Model weights saved in apply/checkpoint-50/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-60\n",
      "Configuration saved in apply/checkpoint-60/config.json\n",
      "Model weights saved in apply/checkpoint-60/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-70\n",
      "Configuration saved in apply/checkpoint-70/config.json\n",
      "Model weights saved in apply/checkpoint-70/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-80\n",
      "Configuration saved in apply/checkpoint-80/config.json\n",
      "Model weights saved in apply/checkpoint-80/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-90\n",
      "Configuration saved in apply/checkpoint-90/config.json\n",
      "Model weights saved in apply/checkpoint-90/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-100\n",
      "Configuration saved in apply/checkpoint-100/config.json\n",
      "Model weights saved in apply/checkpoint-100/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-110\n",
      "Configuration saved in apply/checkpoint-110/config.json\n",
      "Model weights saved in apply/checkpoint-110/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-120\n",
      "Configuration saved in apply/checkpoint-120/config.json\n",
      "Model weights saved in apply/checkpoint-120/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-130\n",
      "Configuration saved in apply/checkpoint-130/config.json\n",
      "Model weights saved in apply/checkpoint-130/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-140\n",
      "Configuration saved in apply/checkpoint-140/config.json\n",
      "Model weights saved in apply/checkpoint-140/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-150\n",
      "Configuration saved in apply/checkpoint-150/config.json\n",
      "Model weights saved in apply/checkpoint-150/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-160\n",
      "Configuration saved in apply/checkpoint-160/config.json\n",
      "Model weights saved in apply/checkpoint-160/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-170\n",
      "Configuration saved in apply/checkpoint-170/config.json\n",
      "Model weights saved in apply/checkpoint-170/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-180\n",
      "Configuration saved in apply/checkpoint-180/config.json\n",
      "Model weights saved in apply/checkpoint-180/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-190\n",
      "Configuration saved in apply/checkpoint-190/config.json\n",
      "Model weights saved in apply/checkpoint-190/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-200\n",
      "Configuration saved in apply/checkpoint-200/config.json\n",
      "Model weights saved in apply/checkpoint-200/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-210\n",
      "Configuration saved in apply/checkpoint-210/config.json\n",
      "Model weights saved in apply/checkpoint-210/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-220\n",
      "Configuration saved in apply/checkpoint-220/config.json\n",
      "Model weights saved in apply/checkpoint-220/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-230\n",
      "Configuration saved in apply/checkpoint-230/config.json\n",
      "Model weights saved in apply/checkpoint-230/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-240\n",
      "Configuration saved in apply/checkpoint-240/config.json\n",
      "Model weights saved in apply/checkpoint-240/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-250\n",
      "Configuration saved in apply/checkpoint-250/config.json\n",
      "Model weights saved in apply/checkpoint-250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-260\n",
      "Configuration saved in apply/checkpoint-260/config.json\n",
      "Model weights saved in apply/checkpoint-260/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-270\n",
      "Configuration saved in apply/checkpoint-270/config.json\n",
      "Model weights saved in apply/checkpoint-270/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-280\n",
      "Configuration saved in apply/checkpoint-280/config.json\n",
      "Model weights saved in apply/checkpoint-280/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-290\n",
      "Configuration saved in apply/checkpoint-290/config.json\n",
      "Model weights saved in apply/checkpoint-290/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-300\n",
      "Configuration saved in apply/checkpoint-300/config.json\n",
      "Model weights saved in apply/checkpoint-300/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-310\n",
      "Configuration saved in apply/checkpoint-310/config.json\n",
      "Model weights saved in apply/checkpoint-310/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-320\n",
      "Configuration saved in apply/checkpoint-320/config.json\n",
      "Model weights saved in apply/checkpoint-320/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-330\n",
      "Configuration saved in apply/checkpoint-330/config.json\n",
      "Model weights saved in apply/checkpoint-330/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-340\n",
      "Configuration saved in apply/checkpoint-340/config.json\n",
      "Model weights saved in apply/checkpoint-340/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-350\n",
      "Configuration saved in apply/checkpoint-350/config.json\n",
      "Model weights saved in apply/checkpoint-350/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-360\n",
      "Configuration saved in apply/checkpoint-360/config.json\n",
      "Model weights saved in apply/checkpoint-360/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-370\n",
      "Configuration saved in apply/checkpoint-370/config.json\n",
      "Model weights saved in apply/checkpoint-370/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-380\n",
      "Configuration saved in apply/checkpoint-380/config.json\n",
      "Model weights saved in apply/checkpoint-380/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-390\n",
      "Configuration saved in apply/checkpoint-390/config.json\n",
      "Model weights saved in apply/checkpoint-390/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-400\n",
      "Configuration saved in apply/checkpoint-400/config.json\n",
      "Model weights saved in apply/checkpoint-400/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-410\n",
      "Configuration saved in apply/checkpoint-410/config.json\n",
      "Model weights saved in apply/checkpoint-410/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-420\n",
      "Configuration saved in apply/checkpoint-420/config.json\n",
      "Model weights saved in apply/checkpoint-420/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-430\n",
      "Configuration saved in apply/checkpoint-430/config.json\n",
      "Model weights saved in apply/checkpoint-430/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-440\n",
      "Configuration saved in apply/checkpoint-440/config.json\n",
      "Model weights saved in apply/checkpoint-440/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-450\n",
      "Configuration saved in apply/checkpoint-450/config.json\n",
      "Model weights saved in apply/checkpoint-450/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-460\n",
      "Configuration saved in apply/checkpoint-460/config.json\n",
      "Model weights saved in apply/checkpoint-460/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-470\n",
      "Configuration saved in apply/checkpoint-470/config.json\n",
      "Model weights saved in apply/checkpoint-470/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-480\n",
      "Configuration saved in apply/checkpoint-480/config.json\n",
      "Model weights saved in apply/checkpoint-480/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-490\n",
      "Configuration saved in apply/checkpoint-490/config.json\n",
      "Model weights saved in apply/checkpoint-490/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-500\n",
      "Configuration saved in apply/checkpoint-500/config.json\n",
      "Model weights saved in apply/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-510\n",
      "Configuration saved in apply/checkpoint-510/config.json\n",
      "Model weights saved in apply/checkpoint-510/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-520\n",
      "Configuration saved in apply/checkpoint-520/config.json\n",
      "Model weights saved in apply/checkpoint-520/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-530\n",
      "Configuration saved in apply/checkpoint-530/config.json\n",
      "Model weights saved in apply/checkpoint-530/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-540\n",
      "Configuration saved in apply/checkpoint-540/config.json\n",
      "Model weights saved in apply/checkpoint-540/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-550\n",
      "Configuration saved in apply/checkpoint-550/config.json\n",
      "Model weights saved in apply/checkpoint-550/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-560\n",
      "Configuration saved in apply/checkpoint-560/config.json\n",
      "Model weights saved in apply/checkpoint-560/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-570\n",
      "Configuration saved in apply/checkpoint-570/config.json\n",
      "Model weights saved in apply/checkpoint-570/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-580\n",
      "Configuration saved in apply/checkpoint-580/config.json\n",
      "Model weights saved in apply/checkpoint-580/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-590\n",
      "Configuration saved in apply/checkpoint-590/config.json\n",
      "Model weights saved in apply/checkpoint-590/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-600\n",
      "Configuration saved in apply/checkpoint-600/config.json\n",
      "Model weights saved in apply/checkpoint-600/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-610\n",
      "Configuration saved in apply/checkpoint-610/config.json\n",
      "Model weights saved in apply/checkpoint-610/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-620\n",
      "Configuration saved in apply/checkpoint-620/config.json\n",
      "Model weights saved in apply/checkpoint-620/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-630\n",
      "Configuration saved in apply/checkpoint-630/config.json\n",
      "Model weights saved in apply/checkpoint-630/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to apply/checkpoint-640\n",
      "Configuration saved in apply/checkpoint-640/config.json\n",
      "Model weights saved in apply/checkpoint-640/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from apply/checkpoint-550 (score: 0.9604048926173028).\n",
      "Saving model checkpoint to apply\n",
      "Configuration saved in apply/config.json\n",
      "Model weights saved in apply/pytorch_model.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 4276\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed. Started testing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9609448082319925\n",
      "Kappa Score ->  0.9039256259501931\n",
      "ROC AUC Score ->  0.9514028637770897\n",
      "F1 Score ->  0.9311907704985579\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3060\n",
      "           1       0.93      0.93      0.93      1216\n",
      "\n",
      "    accuracy                           0.96      4276\n",
      "   macro avg       0.95      0.95      0.95      4276\n",
      "weighted avg       0.96      0.96      0.96      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if RUN_DL:    \n",
    "    apply_bert = createBERT('apply', apply_x_bert, apply_y, split_test_x['Learning_outcome'].tolist(), split_test_y['Apply'].astype('long').to_numpy(), 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f411638",
   "metadata": {},
   "source": [
    "#### Traditional ML Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "85b9015a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Unigram...\n",
      "Getting Bigram...\n",
      "Getting Tfidf...\n",
      "Getting ARI...\n",
      "Combining...\n",
      "Generated feature shape is (17104, 3094)\n",
      "Generated test feature is (4276, 3094)\n"
     ]
    }
   ],
   "source": [
    "combined_apply_x, column_names_apply, test_apply_x = generateX(apply_x, split_test_x.to_numpy(), 0, 1, 94)\n",
    "train_apply_x = combined_apply_x\n",
    "train_apply_y = apply_y\n",
    "test_apply_y = split_test_y['Apply'].astype('long').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fe7fa2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_apply += data.columns[8:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002a2de8",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c05a947a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "gnb_apply = GaussianNB()\n",
    "gnb_apply_gs = GridSearchCV(gnb_apply, params_nb, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "gnb_apply_gs.fit(train_apply_x, train_apply_y)\n",
    "pred_apply_y_gnb = gnb_apply_gs.predict(test_apply_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4eeffe99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 1e-08}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_apply_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "64ca54e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.7778297474275023\n",
      "Kappa Score ->  0.5071471070401455\n",
      "ROC AUC Score ->  0.780842578259374\n",
      "F1 Score ->  0.6685275645498953\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.77      0.83      3060\n",
      "           1       0.58      0.79      0.67      1216\n",
      "\n",
      "    accuracy                           0.78      4276\n",
      "   macro avg       0.74      0.78      0.75      4276\n",
      "weighted avg       0.81      0.78      0.79      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_apply_y, pred_apply_y_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697f9f51",
   "metadata": {},
   "source": [
    "##### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "048516ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV 3/3] END ...C=0.1, gamma=scale, kernel=poly;, score=0.000 total time= 4.7min\n",
      "[CV 3/3] END ....C=0.1, gamma=auto, kernel=poly;, score=0.784 total time= 4.6min\n",
      "[CV 2/3] END .....C=1, gamma=scale, kernel=poly;, score=0.009 total time= 4.4min\n",
      "[CV 1/3] END ......C=1, gamma=auto, kernel=poly;, score=0.832 total time= 5.4min\n",
      "[CV 3/3] END ..C=10, gamma=scale, kernel=linear;, score=0.807 total time=23.7min\n",
      "[CV 2/3] END ....C=100, gamma=scale, kernel=rbf;, score=0.800 total time= 4.6min\n",
      "[CV 3/3] END ....C=100, gamma=auto, kernel=poly;, score=0.797 total time= 5.0min\n",
      "[CV 1/3] END ...............var_smoothing=1e-08;, score=0.643 total time=   3.2s\n",
      "[CV 2/3] END ...............var_smoothing=1e-10;, score=0.609 total time=   2.7s\n",
      "[CV 1/3] END ...C=0.1, gamma=scale, kernel=poly;, score=0.000 total time= 4.6min\n",
      "[CV 3/3] END ..C=0.1, gamma=auto, kernel=linear;, score=0.850 total time= 4.6min\n",
      "[CV 3/3] END ...C=1, gamma=scale, kernel=linear;, score=0.842 total time= 8.3min\n",
      "[CV 1/3] END ..C=10, gamma=scale, kernel=linear;, score=0.823 total time=21.7min\n",
      "[CV 1/3] END ...C=100, gamma=scale, kernel=poly;, score=0.789 total time= 4.0min\n",
      "[CV 3/3] END ....C=100, gamma=scale, kernel=rbf;, score=0.783 total time= 4.6min\n",
      "[CV 1/3] END .....C=100, gamma=auto, kernel=rbf;, score=0.669 total time=10.9min\n",
      "[CV 3/3] END ...............var_smoothing=1e-10;, score=0.608 total time=   2.7s\n",
      "[CV 2/3] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.000 total time= 5.5min\n",
      "[CV 2/3] END ...C=1, gamma=scale, kernel=linear;, score=0.855 total time= 8.7min\n",
      "[CV 3/3] END ......C=1, gamma=auto, kernel=poly;, score=0.825 total time= 5.5min\n",
      "[CV 2/3] END ....C=10, gamma=scale, kernel=poly;, score=0.482 total time= 4.4min\n",
      "[CV 3/3] END ...C=10, gamma=auto, kernel=linear;, score=0.807 total time=22.9min\n",
      "[CV 1/3] END ....C=100, gamma=auto, kernel=poly;, score=0.796 total time= 5.0min\n",
      "[CV 2/3] END .....C=100, gamma=auto, kernel=rbf;, score=0.654 total time= 9.9min\n",
      "[CV 1/3] END ...............var_smoothing=1e-09;, score=0.623 total time=   3.2s\n",
      "[CV 1/3] END .C=0.1, gamma=scale, kernel=linear;, score=0.860 total time= 4.6min\n",
      "[CV 2/3] END ..C=0.1, gamma=auto, kernel=linear;, score=0.858 total time= 4.7min\n",
      "[CV 1/3] END .....C=1, gamma=scale, kernel=poly;, score=0.012 total time= 4.3min\n",
      "[CV 2/3] END ....C=1, gamma=auto, kernel=linear;, score=0.855 total time= 8.4min\n",
      "[CV 1/3] END ...C=10, gamma=auto, kernel=linear;, score=0.823 total time=20.6min\n",
      "[CV 1/3] END ....C=100, gamma=scale, kernel=rbf;, score=0.784 total time= 4.6min\n",
      "[CV 2/3] END ....C=100, gamma=auto, kernel=poly;, score=0.800 total time= 5.1min\n",
      "[CV 3/3] END .....C=100, gamma=auto, kernel=rbf;, score=0.678 total time= 9.9min\n",
      "[CV 3/3] END ...............var_smoothing=1e-09;, score=0.623 total time=   3.1s\n",
      "[CV 3/3] END .C=0.1, gamma=scale, kernel=linear;, score=0.850 total time= 4.7min\n",
      "[CV 1/3] END ....C=0.1, gamma=auto, kernel=poly;, score=0.788 total time= 4.7min\n",
      "[CV 1/3] END ......C=1, gamma=scale, kernel=rbf;, score=0.005 total time= 5.1min\n",
      "[CV 1/3] END .......C=1, gamma=auto, kernel=rbf;, score=0.325 total time= 5.6min\n",
      "[CV 3/3] END ....C=10, gamma=scale, kernel=poly;, score=0.489 total time= 4.5min\n",
      "[CV 1/3] END .....C=10, gamma=auto, kernel=poly;, score=0.805 total time= 5.1min\n",
      "[CV 2/3] END ......C=10, gamma=auto, kernel=rbf;, score=0.632 total time= 7.7min\n",
      "[CV 3/3] END .C=100, gamma=scale, kernel=linear;, score=0.761 total time=53.4min\n",
      "[CV 2/3] END ...............var_smoothing=1e-09;, score=0.626 total time=   3.0s\n",
      "[CV 1/3] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.000 total time= 5.4min\n",
      "[CV 3/3] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.002 total time= 5.8min\n",
      "[CV 1/3] END ....C=1, gamma=auto, kernel=linear;, score=0.854 total time= 7.9min\n",
      "[CV 2/3] END ..C=10, gamma=scale, kernel=linear;, score=0.816 total time=23.0min\n",
      "[CV 3/3] END ...C=100, gamma=scale, kernel=poly;, score=0.785 total time= 4.0min\n",
      "[CV 3/3] END ..C=100, gamma=auto, kernel=linear;, score=0.761 total time=50.8min\n",
      "[CV 3/3] END ...............var_smoothing=1e-08;, score=0.638 total time=   3.1s\n",
      "[CV 1/3] END ..C=0.1, gamma=auto, kernel=linear;, score=0.860 total time= 4.7min\n",
      "[CV 2/3] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.000 total time= 5.8min\n",
      "[CV 3/3] END ......C=1, gamma=scale, kernel=rbf;, score=0.001 total time= 5.2min\n",
      "[CV 3/3] END .......C=1, gamma=auto, kernel=rbf;, score=0.313 total time= 5.7min\n",
      "[CV 2/3] END .....C=10, gamma=scale, kernel=rbf;, score=0.438 total time= 4.9min\n",
      "[CV 3/3] END .....C=10, gamma=auto, kernel=poly;, score=0.804 total time= 5.1min\n",
      "[CV 1/3] END .C=100, gamma=scale, kernel=linear;, score=0.799 total time=70.1min\n",
      "[CV 2/3] END ...............var_smoothing=1e-08;, score=0.641 total time=   3.1s\n",
      "[CV 3/3] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.000 total time= 5.5min\n",
      "[CV 1/3] END ...C=1, gamma=scale, kernel=linear;, score=0.854 total time= 8.1min\n",
      "[CV 3/3] END ....C=1, gamma=auto, kernel=linear;, score=0.842 total time= 8.1min\n",
      "[CV 3/3] END .....C=10, gamma=scale, kernel=rbf;, score=0.420 total time= 5.0min\n",
      "[CV 1/3] END ......C=10, gamma=auto, kernel=rbf;, score=0.638 total time= 7.6min\n",
      "[CV 2/3] END .C=100, gamma=scale, kernel=linear;, score=0.787 total time=75.5min\n",
      "[CV 1/3] END ...............var_smoothing=1e-10;, score=0.602 total time=   2.8s\n",
      "[CV 2/3] END .C=0.1, gamma=scale, kernel=linear;, score=0.858 total time= 4.8min\n",
      "[CV 1/3] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.001 total time= 5.7min\n",
      "[CV 2/3] END ......C=1, gamma=scale, kernel=rbf;, score=0.004 total time= 5.2min\n",
      "[CV 2/3] END .......C=1, gamma=auto, kernel=rbf;, score=0.337 total time= 5.6min\n",
      "[CV 1/3] END .....C=10, gamma=scale, kernel=rbf;, score=0.421 total time= 5.0min\n",
      "[CV 2/3] END .....C=10, gamma=auto, kernel=poly;, score=0.804 total time= 5.2min\n",
      "[CV 3/3] END ......C=10, gamma=auto, kernel=rbf;, score=0.653 total time= 7.8min\n",
      "[CV 2/3] END ...C=100, gamma=scale, kernel=poly;, score=0.803 total time= 3.9min\n",
      "[CV 1/3] END ..C=100, gamma=auto, kernel=linear;, score=0.799 total time=66.9min\n",
      "[CV 2/3] END ...C=0.1, gamma=scale, kernel=poly;, score=0.000 total time= 4.7min\n",
      "[CV 2/3] END ....C=0.1, gamma=auto, kernel=poly;, score=0.803 total time= 4.7min\n",
      "[CV 3/3] END .....C=1, gamma=scale, kernel=poly;, score=0.004 total time= 4.4min\n",
      "[CV 2/3] END ......C=1, gamma=auto, kernel=poly;, score=0.832 total time= 5.5min\n",
      "[CV 1/3] END ....C=10, gamma=scale, kernel=poly;, score=0.489 total time= 4.3min\n",
      "[CV 2/3] END ...C=10, gamma=auto, kernel=linear;, score=0.816 total time=22.2min\n",
      "[CV 2/3] END ..C=100, gamma=auto, kernel=linear;, score=0.787 total time=71.5min\n"
     ]
    }
   ],
   "source": [
    "svm_apply = SVC()\n",
    "svm_apply_gs = GridSearchCV(svm_apply, params_svm, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "svm_apply_gs.fit(train_apply_x, train_apply_y)\n",
    "pred_apply_y_svm = svm_apply_gs.predict(test_apply_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c00b9135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_apply_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "13bcccf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9230589335827877\n",
      "Kappa Score ->  0.8050196892409649\n",
      "ROC AUC Score ->  0.8902423030615756\n",
      "F1 Score ->  0.8575140753572976\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      3060\n",
      "           1       0.91      0.81      0.86      1216\n",
      "\n",
      "    accuracy                           0.92      4276\n",
      "   macro avg       0.92      0.89      0.90      4276\n",
      "weighted avg       0.92      0.92      0.92      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_apply_y, pred_apply_y_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89ccfd0",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "15176aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr_apply = LogisticRegression()\n",
    "lr_apply_gs = GridSearchCV(lr_apply, params_lr, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "lr_apply_gs.fit(train_apply_x, train_apply_y)\n",
    "pred_apply_y_lr = lr_apply_gs.predict(test_apply_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "861747b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_apply_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5cb1a459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.8961646398503275\n",
      "Kappa Score ->  0.7255734997883849\n",
      "ROC AUC Score ->  0.8372570519435845\n",
      "F1 Score ->  0.793296089385475\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      3060\n",
      "           1       0.91      0.70      0.79      1216\n",
      "\n",
      "    accuracy                           0.90      4276\n",
      "   macro avg       0.90      0.84      0.86      4276\n",
      "weighted avg       0.90      0.90      0.89      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_apply_y, pred_apply_y_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d449ad",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "202ebcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    }
   ],
   "source": [
    "rf_apply = RandomForestClassifier()\n",
    "rf_apply_gs = GridSearchCV(rf_apply, params_rf, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "rf_apply_gs.fit(train_apply_x, train_apply_y)\n",
    "pred_apply_y_rf = rf_apply_gs.predict(test_apply_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "16c904f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 250}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_apply_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0d622420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9359214218896165\n",
      "Kappa Score ->  0.837073864268455\n",
      "ROC AUC Score ->  0.9044327270381837\n",
      "F1 Score ->  0.8806620209059234\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3060\n",
      "           1       0.94      0.83      0.88      1216\n",
      "\n",
      "    accuracy                           0.94      4276\n",
      "   macro avg       0.94      0.90      0.92      4276\n",
      "weighted avg       0.94      0.94      0.93      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_apply_y, pred_apply_y_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87990563",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5823c58f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:14] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.719 total time=  55.2s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.598 total time=  15.5s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.726 total time=  37.0s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.597 total time=  15.8s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.789 total time= 1.2min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.780 total time= 1.5min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.737 total time= 1.4min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.749 total time=  37.2s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.776 total time= 3.1min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.781 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.748 total time=  36.3s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.748 total time=  37.1s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.616 total time=  15.9s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.780 total time= 1.5min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.616 total time=  15.8s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.801 total time= 1.3min\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.858 total time=   7.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.854 total time=   9.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.857 total time=  39.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.853 total time=  36.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.843 total time=  16.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.818 total time=  12.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.823 total time=   8.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.822 total time=  29.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.856 total time=  17.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.862 total time=  41.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.846 total time=  16.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.836 total time=  15.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.845 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.844 total time=  36.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.826 total time=   8.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.829 total time=  14.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.119 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.224 total time=   2.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.149 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.136 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.133 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.146 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.122 total time=   5.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.132 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.133 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.133 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.177 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.147 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.136 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.114 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.153 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.173 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.144 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.124 total time=   5.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.470 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.565 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.443 total time=   3.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.429 total time=   8.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.422 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.527 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.608 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.642 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.521 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.482 total time=   9.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.626 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.434 total time=   8.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.457 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.512 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.459 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.508 total time=   8.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.424 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.872 total time=  15.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.876 total time=  29.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.868 total time=  29.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.868 total time=  14.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.861 total time= 1.1min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.833 total time=  13.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.837 total time=  12.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.839 total time=  13.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.840 total time=  23.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.841 total time=  12.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.841 total time=  54.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.879 total time= 1.2min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.859 total time= 1.0min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.866 total time=  25.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.841 total time=  22.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.836 total time=  13.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.839 total time=  53.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.115 total time=   9.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.128 total time=   8.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.136 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.114 total time=   7.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.156 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.154 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.200 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.178 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.138 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.162 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.150 total time=   7.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.129 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.132 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.134 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.127 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.149 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.444 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.441 total time=  14.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.535 total time=   7.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.411 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.468 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.487 total time=   6.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.424 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.539 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.542 total time=   7.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.532 total time=  13.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.377 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.486 total time=  14.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.527 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.474 total time=  14.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.393 total time=  13.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.439 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.447 total time=  11.1s\n",
      "[13:49:48] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:52:42] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:57:20] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:01] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:25] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.719 total time=  55.9s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.748 total time=  37.0s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.768 total time= 1.9min\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.773 total time= 1.3min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.725 total time= 1.4min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.738 total time=  37.3s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.779 total time= 3.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.623 total time=  25.3s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.747 total time= 1.0min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.616 total time=  16.2s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.622 total time=  25.1s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.597 total time=  15.7s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.795 total time= 1.3min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.781 total time= 1.4min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.864 total time=  15.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.863 total time=  17.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.856 total time=   9.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.861 total time=  39.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.850 total time=  37.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.828 total time=  14.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.808 total time=  12.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.824 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.854 total time=   9.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.865 total time=  39.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.854 total time=  39.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.847 total time=  16.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.852 total time=   8.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.829 total time=   8.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.818 total time=  31.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.815 total time=  13.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.119 total time=   2.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.126 total time=   6.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.206 total time=   2.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.146 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.130 total time=   5.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.144 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.126 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.133 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.143 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.153 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.127 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.114 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.238 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.127 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.133 total time=   2.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.439 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.423 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.480 total time=   9.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.451 total time=   3.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.395 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.602 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.488 total time=   9.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.485 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.606 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.549 total time=   3.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.452 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.456 total time=   9.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.481 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.515 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.530 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.865 total time=  27.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.871 total time=  28.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.877 total time=  29.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.859 total time=  14.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.851 total time=  14.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.862 total time=  25.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.863 total time=  13.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.856 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.843 total time=  54.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.877 total time= 1.1min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.868 total time= 1.2min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.861 total time=  25.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.859 total time=  25.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.844 total time=  22.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.833 total time=  12.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.844 total time=  53.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.305 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.119 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.156 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.154 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.140 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.150 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.143 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.179 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.146 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.132 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.130 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.131 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.253 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.160 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.116 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.158 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.456 total time=   7.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.409 total time=   6.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.507 total time=   7.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.454 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.477 total time=  13.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.446 total time=  14.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.484 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.526 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.456 total time=  14.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.580 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.646 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.482 total time=  13.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.440 total time=   6.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.466 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.480 total time=  13.9s\n",
      "[13:49:45] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:51:23] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:53:52] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:55:23] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:58:50] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:00:20] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:45] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:19] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.740 total time=  55.3s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.616 total time=  15.5s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.608 total time=  24.5s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.772 total time= 2.2min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.621 total time=  32.3s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.725 total time= 1.4min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.748 total time=  37.8s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.615 total time=  33.6s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.772 total time= 1.3min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.801 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.801 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.726 total time=  37.2s\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.726 total time=  37.2s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.781 total time= 2.5min\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.859 total time=  15.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.856 total time=  17.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.855 total time=  17.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.856 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.831 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.855 total time=  16.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.837 total time=  15.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.826 total time=   8.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.819 total time=  30.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.823 total time=  31.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.862 total time=  17.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.853 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.832 total time=   9.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.849 total time=  15.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.841 total time=   8.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.846 total time=  10.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.839 total time=  16.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.820 total time=  13.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.816 total time=   7.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.829 total time=  30.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.137 total time=   6.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.140 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.183 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.095 total time=   2.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.122 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.274 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.149 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.127 total time=   5.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.194 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.151 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.135 total time=   2.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.145 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.140 total time=   5.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.127 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.109 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.145 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.444 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.497 total time=   8.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.387 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.542 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.566 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.399 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.471 total time=   8.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.601 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.442 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.537 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.433 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.360 total time=   4.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.568 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.487 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.356 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.871 total time=  13.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.869 total time=  16.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.869 total time=  15.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.862 total time=  15.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.877 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.860 total time= 1.0min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.839 total time=  55.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.846 total time=  54.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.865 total time=  27.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.870 total time=  14.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.869 total time= 1.2min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.856 total time=  15.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.855 total time=  24.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.843 total time=  12.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.847 total time=  53.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.837 total time=  48.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.118 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.130 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.128 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.106 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.160 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.125 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.165 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.137 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.154 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.154 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.134 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.131 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.284 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.475 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.618 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.552 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.435 total time=  13.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.529 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.436 total time=  14.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.575 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.503 total time=  14.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.396 total time=  14.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.517 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.466 total time=  13.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.512 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.522 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.424 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.477 total time=  13.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.584 total time=   6.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.388 total time=   7.0s\n",
      "[13:49:47] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:52:48] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:54:13] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:57:03] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:59:22] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:13] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:06:57] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.717 total time=  55.4s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.746 total time=  36.1s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.603 total time=  24.8s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.766 total time= 1.2min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.796 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.748 total time= 1.4min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.622 total time=  16.0s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.748 total time=  37.5s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.597 total time=  15.6s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.794 total time= 1.3min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.781 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.598 total time=  25.5s\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.726 total time= 1.0min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.597 total time=  15.9s\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.726 total time=  37.0s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.794 total time= 2.2min\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.795 total time= 1.1min\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.865 total time=  10.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.851 total time=  10.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.859 total time=  16.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.839 total time=   8.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.844 total time=  36.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.849 total time=  36.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.821 total time=  30.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.859 total time=  17.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.854 total time=   8.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.853 total time=  10.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.862 total time=  17.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.840 total time=   8.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.840 total time=  10.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.848 total time=  16.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.847 total time=  15.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.822 total time=   7.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.821 total time=   8.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.831 total time=  13.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.820 total time=  26.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.132 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.252 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.127 total time=   5.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.120 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.108 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.139 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.205 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.124 total time=   2.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.133 total time=   2.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.138 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.147 total time=   5.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.135 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.140 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.139 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.123 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.122 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.553 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.496 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.474 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.452 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.642 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.441 total time=   4.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.341 total time=   3.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.639 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.473 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.507 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.618 total time=   9.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.600 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.626 total time=   9.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.478 total time=   9.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.399 total time=   3.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.531 total time=   8.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.463 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.866 total time=  13.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.868 total time=  26.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.876 total time=  16.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.871 total time=  30.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.869 total time=  27.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.860 total time=  14.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.866 total time= 1.0min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.836 total time=  55.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.842 total time=  24.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.867 total time=  28.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.874 total time=  13.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.870 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.858 total time= 1.0min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.864 total time= 1.0min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.847 total time=  53.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.180 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.125 total time=   8.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.117 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.164 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.143 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.137 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.120 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.153 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.136 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.117 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.140 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.136 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.113 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.142 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.128 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.574 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.458 total time=  14.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.489 total time=   7.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.432 total time=   7.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.407 total time=   6.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.505 total time=  13.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.562 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.462 total time=  13.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.383 total time=   6.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.460 total time=  13.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.489 total time=  13.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.455 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.410 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.554 total time=  13.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.439 total time=   6.9s\n",
      "[13:50:03] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:53:44] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:55:13] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:57:07] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:59:29] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:15] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:38] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:05] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:07:02] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.602 total time=  23.5s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.725 total time=  36.8s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.726 total time=  36.9s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.782 total time= 1.9min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.614 total time=  16.1s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.801 total time= 1.5min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.616 total time=  15.8s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.726 total time=  36.6s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.726 total time=  37.0s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.794 total time= 3.0min\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.780 total time= 1.5min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.616 total time=  16.2s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.622 total time=  15.4s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.748 total time=  37.1s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.776 total time= 2.2min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.776 total time= 1.1min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.860 total time=  41.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.854 total time=  38.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.848 total time=  16.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.846 total time=  15.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.820 total time=   7.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.829 total time=  31.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.823 total time=  13.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.864 total time=  39.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.857 total time=  18.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.839 total time=  36.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.833 total time=  15.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.820 total time=   7.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.824 total time=  31.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.822 total time=  26.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.206 total time=   2.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.129 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.189 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.139 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.148 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.142 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.120 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.133 total time=   5.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.150 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.124 total time=   5.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.121 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.135 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.120 total time=   5.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.118 total time=   5.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.111 total time=   5.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.427 total time=   4.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.515 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.643 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.442 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.514 total time=   4.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.603 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.480 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.426 total time=   8.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.441 total time=   4.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.630 total time=   4.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.425 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.580 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.395 total time=   4.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.405 total time=   4.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.407 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.500 total time=   8.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.877 total time=  28.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.877 total time= 1.2min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.863 total time= 1.0min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.867 total time=  25.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.841 total time=  24.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.850 total time=  12.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.848 total time=  55.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.873 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.869 total time=  29.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.869 total time=  27.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.856 total time=  14.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.869 total time= 1.0min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.837 total time=  53.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.836 total time=  22.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.221 total time=   4.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.133 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.125 total time=   2.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.164 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.266 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.125 total time=   7.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.118 total time=   7.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.135 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.124 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.129 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.172 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.115 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.126 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.106 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.121 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.658 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.473 total time=  14.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.553 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.520 total time=  14.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.434 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.530 total time=  14.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.566 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.634 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.451 total time=  13.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.382 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.463 total time=  13.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.585 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.633 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.423 total time=  13.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.593 total time=   6.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.452 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.511 total time=   6.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.460 total time=   6.5s\n",
      "[13:49:52] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:51:54] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:54:15] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:57:09] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:01:45] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:08] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:07:04] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.586 total time=  23.5s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.621 total time=  15.5s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.734 total time=  36.3s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.748 total time=  37.5s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.621 total time=  15.7s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.771 total time= 1.2min\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.599 total time=  16.1s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.776 total time= 1.3min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.737 total time= 1.4min\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.597 total time=  33.7s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.780 total time= 3.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.748 total time= 1.0min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.726 total time=  37.4s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.599 total time=  25.8s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.801 total time= 2.5min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.852 total time=   7.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.852 total time=   9.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.856 total time=  41.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.837 total time=  15.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.851 total time=   8.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.833 total time=   9.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.838 total time=  36.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.824 total time=  13.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.819 total time=  12.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.861 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.862 total time=  38.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.862 total time=  39.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.841 total time=  36.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.813 total time=  12.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.810 total time=   8.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.820 total time=  30.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.179 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.123 total time=   5.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.133 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.123 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.124 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.119 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.134 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.115 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.208 total time=   2.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.119 total time=   5.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.128 total time=   5.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.141 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.151 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.175 total time=   5.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.462 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.474 total time=   4.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.485 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.431 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.501 total time=   8.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.440 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.512 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.482 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.479 total time=   4.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.463 total time=   3.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.450 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.434 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.511 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.871 total time= 1.1min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.868 total time= 1.1min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.857 total time= 1.0min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.845 total time=  23.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.847 total time=  23.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.844 total time=  12.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.865 total time=  16.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.875 total time=  28.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.868 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.858 total time=  27.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.869 total time=  26.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.857 total time=  13.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.844 total time=  13.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.834 total time=  12.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.845 total time=  55.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.844 total time=  46.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.161 total time=   3.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.200 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.131 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.140 total time=   7.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.123 total time=   7.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.108 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.145 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.124 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.141 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.150 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.121 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.525 total time=   6.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.462 total time=   6.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.545 total time=   7.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.440 total time=  14.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.433 total time=   6.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.543 total time=   7.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.430 total time=   6.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.469 total time=   6.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.470 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.460 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.517 total time=  13.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.536 total time=   6.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.586 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.552 total time=  13.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.518 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.630 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.480 total time=  11.4s\n",
      "[13:49:50] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:52:45] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:57:21] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:58:46] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:00:16] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:10] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:06:47] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_apply = XGBClassifier()\n",
    "xgb_apply_gs = GridSearchCV(xgb_apply, params_xgb, scoring=\"f1\", n_jobs=-1, cv=3)\n",
    "xgb_apply_gs.fit(train_apply_x, train_apply_y)\n",
    "pred_apply_y_xgb = xgb_apply_gs.predict(test_apply_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4555f8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.5, 'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 100}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_apply_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "53178808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9375584658559402\n",
      "Kappa Score ->  0.8436813525347704\n",
      "ROC AUC Score ->  0.914001225490196\n",
      "F1 Score ->  0.886720407297412\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      3060\n",
      "           1       0.92      0.86      0.89      1216\n",
      "\n",
      "    accuracy                           0.94      4276\n",
      "   macro avg       0.93      0.91      0.92      4276\n",
      "weighted avg       0.94      0.94      0.94      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_apply_y, pred_apply_y_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edc477c",
   "metadata": {},
   "source": [
    "### Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb5fbae",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdf9b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_x, analyze_y = split_train_x.to_numpy(), split_train_y['Analyze'].astype('long').to_numpy()#rus(split_train_x, split_train_y['Analyze'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58414aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17104, 94)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786e7eee",
   "metadata": {},
   "source": [
    "#### BERT Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "654d370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_x_bert = analyze_x[:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d35acd3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /Users/ylii0447/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /Users/ylii0447/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /Users/ylii0447/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "using `logging_steps` to initialize `eval_steps` to 10\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 13683\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training model for column analyze\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='642' max='642' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [642/642 1:21:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.460200</td>\n",
       "      <td>0.417760</td>\n",
       "      <td>0.456121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.346400</td>\n",
       "      <td>0.239997</td>\n",
       "      <td>0.832641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.235700</td>\n",
       "      <td>0.251619</td>\n",
       "      <td>0.855708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>0.177261</td>\n",
       "      <td>0.900010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.146900</td>\n",
       "      <td>0.169113</td>\n",
       "      <td>0.914895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.215400</td>\n",
       "      <td>0.161445</td>\n",
       "      <td>0.904203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.201500</td>\n",
       "      <td>0.153569</td>\n",
       "      <td>0.903113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.118800</td>\n",
       "      <td>0.138027</td>\n",
       "      <td>0.919957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.148672</td>\n",
       "      <td>0.911634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.159262</td>\n",
       "      <td>0.907976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.144400</td>\n",
       "      <td>0.134039</td>\n",
       "      <td>0.925475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.132752</td>\n",
       "      <td>0.910851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>0.134525</td>\n",
       "      <td>0.922171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>0.166512</td>\n",
       "      <td>0.916725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.173200</td>\n",
       "      <td>0.129230</td>\n",
       "      <td>0.923267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.133300</td>\n",
       "      <td>0.123587</td>\n",
       "      <td>0.927975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.103800</td>\n",
       "      <td>0.126739</td>\n",
       "      <td>0.927484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.120200</td>\n",
       "      <td>0.133062</td>\n",
       "      <td>0.923907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.144800</td>\n",
       "      <td>0.122691</td>\n",
       "      <td>0.931147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.126100</td>\n",
       "      <td>0.119853</td>\n",
       "      <td>0.925662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.131386</td>\n",
       "      <td>0.924355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.113960</td>\n",
       "      <td>0.925010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.137300</td>\n",
       "      <td>0.108315</td>\n",
       "      <td>0.932936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.126443</td>\n",
       "      <td>0.934523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>0.116081</td>\n",
       "      <td>0.937889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>0.117897</td>\n",
       "      <td>0.929478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.096100</td>\n",
       "      <td>0.111956</td>\n",
       "      <td>0.938704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.105367</td>\n",
       "      <td>0.939233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.108369</td>\n",
       "      <td>0.939836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>0.103080</td>\n",
       "      <td>0.944518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.086700</td>\n",
       "      <td>0.104072</td>\n",
       "      <td>0.939438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.102739</td>\n",
       "      <td>0.942568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.099844</td>\n",
       "      <td>0.936490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.105500</td>\n",
       "      <td>0.100602</td>\n",
       "      <td>0.933701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.109271</td>\n",
       "      <td>0.932635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.097700</td>\n",
       "      <td>0.106579</td>\n",
       "      <td>0.929993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.098977</td>\n",
       "      <td>0.933424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.069600</td>\n",
       "      <td>0.099085</td>\n",
       "      <td>0.942588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.096222</td>\n",
       "      <td>0.948279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.093362</td>\n",
       "      <td>0.946875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.099709</td>\n",
       "      <td>0.945336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.098581</td>\n",
       "      <td>0.939723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.053400</td>\n",
       "      <td>0.104891</td>\n",
       "      <td>0.943421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.105418</td>\n",
       "      <td>0.942920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.103675</td>\n",
       "      <td>0.945013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>0.108918</td>\n",
       "      <td>0.946715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.101447</td>\n",
       "      <td>0.949368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.102972</td>\n",
       "      <td>0.947304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.100149</td>\n",
       "      <td>0.947112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.098781</td>\n",
       "      <td>0.945838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.109240</td>\n",
       "      <td>0.942305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.109323</td>\n",
       "      <td>0.940086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.104949</td>\n",
       "      <td>0.944417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.102868</td>\n",
       "      <td>0.941940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.102189</td>\n",
       "      <td>0.940790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.100536</td>\n",
       "      <td>0.945617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.099238</td>\n",
       "      <td>0.943757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.095880</td>\n",
       "      <td>0.944254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.095463</td>\n",
       "      <td>0.943338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.095350</td>\n",
       "      <td>0.945175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.097425</td>\n",
       "      <td>0.947225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.097896</td>\n",
       "      <td>0.947112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.040500</td>\n",
       "      <td>0.099035</td>\n",
       "      <td>0.947618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.099014</td>\n",
       "      <td>0.948203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-10\n",
      "Configuration saved in analyze/checkpoint-10/config.json\n",
      "Model weights saved in analyze/checkpoint-10/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-20\n",
      "Configuration saved in analyze/checkpoint-20/config.json\n",
      "Model weights saved in analyze/checkpoint-20/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-30\n",
      "Configuration saved in analyze/checkpoint-30/config.json\n",
      "Model weights saved in analyze/checkpoint-30/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-40\n",
      "Configuration saved in analyze/checkpoint-40/config.json\n",
      "Model weights saved in analyze/checkpoint-40/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-50\n",
      "Configuration saved in analyze/checkpoint-50/config.json\n",
      "Model weights saved in analyze/checkpoint-50/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-60\n",
      "Configuration saved in analyze/checkpoint-60/config.json\n",
      "Model weights saved in analyze/checkpoint-60/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-70\n",
      "Configuration saved in analyze/checkpoint-70/config.json\n",
      "Model weights saved in analyze/checkpoint-70/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-80\n",
      "Configuration saved in analyze/checkpoint-80/config.json\n",
      "Model weights saved in analyze/checkpoint-80/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-90\n",
      "Configuration saved in analyze/checkpoint-90/config.json\n",
      "Model weights saved in analyze/checkpoint-90/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-100\n",
      "Configuration saved in analyze/checkpoint-100/config.json\n",
      "Model weights saved in analyze/checkpoint-100/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-110\n",
      "Configuration saved in analyze/checkpoint-110/config.json\n",
      "Model weights saved in analyze/checkpoint-110/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-120\n",
      "Configuration saved in analyze/checkpoint-120/config.json\n",
      "Model weights saved in analyze/checkpoint-120/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-130\n",
      "Configuration saved in analyze/checkpoint-130/config.json\n",
      "Model weights saved in analyze/checkpoint-130/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-140\n",
      "Configuration saved in analyze/checkpoint-140/config.json\n",
      "Model weights saved in analyze/checkpoint-140/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-150\n",
      "Configuration saved in analyze/checkpoint-150/config.json\n",
      "Model weights saved in analyze/checkpoint-150/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-160\n",
      "Configuration saved in analyze/checkpoint-160/config.json\n",
      "Model weights saved in analyze/checkpoint-160/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-170\n",
      "Configuration saved in analyze/checkpoint-170/config.json\n",
      "Model weights saved in analyze/checkpoint-170/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-180\n",
      "Configuration saved in analyze/checkpoint-180/config.json\n",
      "Model weights saved in analyze/checkpoint-180/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-190\n",
      "Configuration saved in analyze/checkpoint-190/config.json\n",
      "Model weights saved in analyze/checkpoint-190/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-200\n",
      "Configuration saved in analyze/checkpoint-200/config.json\n",
      "Model weights saved in analyze/checkpoint-200/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-210\n",
      "Configuration saved in analyze/checkpoint-210/config.json\n",
      "Model weights saved in analyze/checkpoint-210/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-220\n",
      "Configuration saved in analyze/checkpoint-220/config.json\n",
      "Model weights saved in analyze/checkpoint-220/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-230\n",
      "Configuration saved in analyze/checkpoint-230/config.json\n",
      "Model weights saved in analyze/checkpoint-230/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-240\n",
      "Configuration saved in analyze/checkpoint-240/config.json\n",
      "Model weights saved in analyze/checkpoint-240/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-250\n",
      "Configuration saved in analyze/checkpoint-250/config.json\n",
      "Model weights saved in analyze/checkpoint-250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-260\n",
      "Configuration saved in analyze/checkpoint-260/config.json\n",
      "Model weights saved in analyze/checkpoint-260/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-270\n",
      "Configuration saved in analyze/checkpoint-270/config.json\n",
      "Model weights saved in analyze/checkpoint-270/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-280\n",
      "Configuration saved in analyze/checkpoint-280/config.json\n",
      "Model weights saved in analyze/checkpoint-280/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-290\n",
      "Configuration saved in analyze/checkpoint-290/config.json\n",
      "Model weights saved in analyze/checkpoint-290/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-300\n",
      "Configuration saved in analyze/checkpoint-300/config.json\n",
      "Model weights saved in analyze/checkpoint-300/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-310\n",
      "Configuration saved in analyze/checkpoint-310/config.json\n",
      "Model weights saved in analyze/checkpoint-310/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-320\n",
      "Configuration saved in analyze/checkpoint-320/config.json\n",
      "Model weights saved in analyze/checkpoint-320/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-330\n",
      "Configuration saved in analyze/checkpoint-330/config.json\n",
      "Model weights saved in analyze/checkpoint-330/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-340\n",
      "Configuration saved in analyze/checkpoint-340/config.json\n",
      "Model weights saved in analyze/checkpoint-340/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-350\n",
      "Configuration saved in analyze/checkpoint-350/config.json\n",
      "Model weights saved in analyze/checkpoint-350/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-360\n",
      "Configuration saved in analyze/checkpoint-360/config.json\n",
      "Model weights saved in analyze/checkpoint-360/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-370\n",
      "Configuration saved in analyze/checkpoint-370/config.json\n",
      "Model weights saved in analyze/checkpoint-370/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-380\n",
      "Configuration saved in analyze/checkpoint-380/config.json\n",
      "Model weights saved in analyze/checkpoint-380/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-390\n",
      "Configuration saved in analyze/checkpoint-390/config.json\n",
      "Model weights saved in analyze/checkpoint-390/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-400\n",
      "Configuration saved in analyze/checkpoint-400/config.json\n",
      "Model weights saved in analyze/checkpoint-400/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-410\n",
      "Configuration saved in analyze/checkpoint-410/config.json\n",
      "Model weights saved in analyze/checkpoint-410/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-420\n",
      "Configuration saved in analyze/checkpoint-420/config.json\n",
      "Model weights saved in analyze/checkpoint-420/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-430\n",
      "Configuration saved in analyze/checkpoint-430/config.json\n",
      "Model weights saved in analyze/checkpoint-430/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-440\n",
      "Configuration saved in analyze/checkpoint-440/config.json\n",
      "Model weights saved in analyze/checkpoint-440/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-450\n",
      "Configuration saved in analyze/checkpoint-450/config.json\n",
      "Model weights saved in analyze/checkpoint-450/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-460\n",
      "Configuration saved in analyze/checkpoint-460/config.json\n",
      "Model weights saved in analyze/checkpoint-460/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-470\n",
      "Configuration saved in analyze/checkpoint-470/config.json\n",
      "Model weights saved in analyze/checkpoint-470/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-480\n",
      "Configuration saved in analyze/checkpoint-480/config.json\n",
      "Model weights saved in analyze/checkpoint-480/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-490\n",
      "Configuration saved in analyze/checkpoint-490/config.json\n",
      "Model weights saved in analyze/checkpoint-490/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-500\n",
      "Configuration saved in analyze/checkpoint-500/config.json\n",
      "Model weights saved in analyze/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-510\n",
      "Configuration saved in analyze/checkpoint-510/config.json\n",
      "Model weights saved in analyze/checkpoint-510/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-520\n",
      "Configuration saved in analyze/checkpoint-520/config.json\n",
      "Model weights saved in analyze/checkpoint-520/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-530\n",
      "Configuration saved in analyze/checkpoint-530/config.json\n",
      "Model weights saved in analyze/checkpoint-530/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-540\n",
      "Configuration saved in analyze/checkpoint-540/config.json\n",
      "Model weights saved in analyze/checkpoint-540/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-550\n",
      "Configuration saved in analyze/checkpoint-550/config.json\n",
      "Model weights saved in analyze/checkpoint-550/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-560\n",
      "Configuration saved in analyze/checkpoint-560/config.json\n",
      "Model weights saved in analyze/checkpoint-560/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-570\n",
      "Configuration saved in analyze/checkpoint-570/config.json\n",
      "Model weights saved in analyze/checkpoint-570/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-580\n",
      "Configuration saved in analyze/checkpoint-580/config.json\n",
      "Model weights saved in analyze/checkpoint-580/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-590\n",
      "Configuration saved in analyze/checkpoint-590/config.json\n",
      "Model weights saved in analyze/checkpoint-590/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-600\n",
      "Configuration saved in analyze/checkpoint-600/config.json\n",
      "Model weights saved in analyze/checkpoint-600/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-610\n",
      "Configuration saved in analyze/checkpoint-610/config.json\n",
      "Model weights saved in analyze/checkpoint-610/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-620\n",
      "Configuration saved in analyze/checkpoint-620/config.json\n",
      "Model weights saved in analyze/checkpoint-620/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-630\n",
      "Configuration saved in analyze/checkpoint-630/config.json\n",
      "Model weights saved in analyze/checkpoint-630/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to analyze/checkpoint-640\n",
      "Configuration saved in analyze/checkpoint-640/config.json\n",
      "Model weights saved in analyze/checkpoint-640/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from analyze/checkpoint-470 (score: 0.9493681784349464).\n",
      "Saving model checkpoint to analyze\n",
      "Configuration saved in analyze/config.json\n",
      "Model weights saved in analyze/pytorch_model.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 4276\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed. Started testing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.974508886810103\n",
      "Kappa Score ->  0.9064189075232063\n",
      "ROC AUC Score ->  0.9503508474407191\n",
      "F1 Score ->  0.9216391085549963\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      3575\n",
      "           1       0.93      0.91      0.92       701\n",
      "\n",
      "    accuracy                           0.97      4276\n",
      "   macro avg       0.96      0.95      0.95      4276\n",
      "weighted avg       0.97      0.97      0.97      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if RUN_DL:\n",
    "    analyze_bert = createBERT('analyze', analyze_x_bert, analyze_y, split_test_x['Learning_outcome'].tolist(), split_test_y['Analyze'].astype('long').to_numpy(), 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7ae43f",
   "metadata": {},
   "source": [
    "#### Traditional ML Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22f2f100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Unigram...\n",
      "Getting Bigram...\n",
      "Getting Tfidf...\n",
      "Getting ARI...\n",
      "Combining...\n",
      "Generated feature shape is (17104, 3094)\n",
      "Generated test feature is (4276, 3094)\n"
     ]
    }
   ],
   "source": [
    "combined_analyze_x, column_names_analyze, test_analyze_x = generateX(analyze_x, split_test_x.to_numpy(), 0, 1, 94)\n",
    "train_analyze_x = combined_analyze_x\n",
    "train_analyze_y = analyze_y\n",
    "test_analyze_y = split_test_y['Analyze'].astype('long').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "652e1774",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_analyze += data.columns[8:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3a6123",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4891f523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    }
   ],
   "source": [
    "gnb_analyze = GaussianNB()\n",
    "gnb_analyze_gs = GridSearchCV(gnb_analyze, params_nb, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "gnb_analyze_gs.fit(train_analyze_x, train_analyze_y)\n",
    "pred_analyze_y_gnb = gnb_analyze_gs.predict(test_analyze_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc138c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 1e-08}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_analyze_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a70dfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.5493451824134705\n",
      "Kappa Score ->  0.1829401988743411\n",
      "ROC AUC Score ->  0.6840435741149008\n",
      "F1 Score ->  0.3915377328702242\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.48      0.64      3575\n",
      "           1       0.25      0.88      0.39       701\n",
      "\n",
      "    accuracy                           0.55      4276\n",
      "   macro avg       0.60      0.68      0.52      4276\n",
      "weighted avg       0.84      0.55      0.60      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_analyze_y, pred_analyze_y_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928468c9",
   "metadata": {},
   "source": [
    "##### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4dc6090b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV 3/3] END ...............var_smoothing=1e-09;, score=0.360 total time=   2.7s\n",
      "[CV 3/3] END .C=0.1, gamma=scale, kernel=linear;, score=0.829 total time= 2.6min\n",
      "[CV 2/3] END ..C=0.1, gamma=auto, kernel=linear;, score=0.856 total time= 2.7min\n",
      "[CV 3/3] END ...C=1, gamma=scale, kernel=linear;, score=0.825 total time= 3.8min\n",
      "[CV 2/3] END .......C=1, gamma=auto, kernel=rbf;, score=0.108 total time= 4.0min\n",
      "[CV 3/3] END .....C=10, gamma=scale, kernel=rbf;, score=0.181 total time= 2.9min\n",
      "[CV 1/3] END ......C=10, gamma=auto, kernel=rbf;, score=0.552 total time= 4.5min\n",
      "[CV 3/3] END ...C=100, gamma=scale, kernel=poly;, score=0.760 total time= 2.4min\n",
      "[CV 1/3] END ....C=100, gamma=auto, kernel=poly;, score=0.782 total time= 3.0min\n",
      "[CV 2/3] END ...............var_smoothing=1e-08;, score=0.361 total time=   2.7s\n",
      "[CV 2/3] END ...C=0.1, gamma=scale, kernel=poly;, score=0.000 total time= 2.9min\n",
      "[CV 1/3] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.000 total time= 3.9min\n",
      "[CV 2/3] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time= 3.2min\n",
      "[CV 3/3] END .......C=1, gamma=auto, kernel=rbf;, score=0.123 total time= 3.8min\n",
      "[CV 1/3] END ...C=10, gamma=auto, kernel=linear;, score=0.780 total time= 6.7min\n",
      "[CV 1/3] END ....C=100, gamma=scale, kernel=rbf;, score=0.748 total time= 3.0min\n",
      "[CV 2/3] END ....C=100, gamma=auto, kernel=poly;, score=0.779 total time= 2.9min\n",
      "[CV 3/3] END ...............var_smoothing=1e-08;, score=0.376 total time=   2.7s\n",
      "[CV 3/3] END ...C=0.1, gamma=scale, kernel=poly;, score=0.000 total time= 2.8min\n",
      "[CV 3/3] END ....C=0.1, gamma=auto, kernel=poly;, score=0.758 total time= 2.7min\n",
      "[CV 3/3] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time= 2.6min\n",
      "[CV 3/3] END ......C=1, gamma=auto, kernel=poly;, score=0.784 total time= 3.0min\n",
      "[CV 1/3] END ....C=10, gamma=scale, kernel=poly;, score=0.416 total time= 2.7min\n",
      "[CV 2/3] END ...C=10, gamma=auto, kernel=linear;, score=0.787 total time= 7.0min\n",
      "[CV 2/3] END ....C=100, gamma=scale, kernel=rbf;, score=0.730 total time= 3.0min\n",
      "[CV 3/3] END ....C=100, gamma=auto, kernel=poly;, score=0.753 total time= 2.7min\n",
      "[CV 1/3] END .C=0.1, gamma=scale, kernel=linear;, score=0.844 total time= 2.8min\n",
      "[CV 1/3] END ....C=0.1, gamma=auto, kernel=poly;, score=0.778 total time= 2.8min\n",
      "[CV 2/3] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time= 2.6min\n",
      "[CV 2/3] END ......C=1, gamma=auto, kernel=poly;, score=0.804 total time= 3.4min\n",
      "[CV 1/3] END .....C=10, gamma=scale, kernel=rbf;, score=0.165 total time= 3.2min\n",
      "[CV 2/3] END .....C=10, gamma=auto, kernel=poly;, score=0.780 total time= 3.0min\n",
      "[CV 2/3] END .C=100, gamma=scale, kernel=linear;, score=0.781 total time= 9.3min\n",
      "[CV 3/3] END ...............var_smoothing=1e-10;, score=0.350 total time=   2.6s\n",
      "[CV 3/3] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.000 total time= 3.3min\n",
      "[CV 2/3] END ...C=1, gamma=scale, kernel=linear;, score=0.844 total time= 4.3min\n",
      "[CV 3/3] END ....C=1, gamma=auto, kernel=linear;, score=0.825 total time= 3.7min\n",
      "[CV 2/3] END ....C=10, gamma=scale, kernel=poly;, score=0.416 total time= 2.7min\n",
      "[CV 3/3] END ...C=10, gamma=auto, kernel=linear;, score=0.785 total time= 5.8min\n",
      "[CV 2/3] END ...C=100, gamma=scale, kernel=poly;, score=0.766 total time= 2.6min\n",
      "[CV 3/3] END ..C=100, gamma=auto, kernel=linear;, score=0.772 total time= 5.4min\n",
      "[CV 1/3] END ...............var_smoothing=1e-08;, score=0.372 total time=   2.7s\n",
      "[CV 2/3] END ...............var_smoothing=1e-10;, score=0.341 total time=   2.6s\n",
      "[CV 2/3] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.000 total time= 3.3min\n",
      "[CV 1/3] END ...C=1, gamma=scale, kernel=linear;, score=0.829 total time= 4.1min\n",
      "[CV 2/3] END ....C=1, gamma=auto, kernel=linear;, score=0.844 total time= 4.1min\n",
      "[CV 3/3] END ....C=10, gamma=scale, kernel=poly;, score=0.427 total time= 2.7min\n",
      "[CV 1/3] END .....C=10, gamma=auto, kernel=poly;, score=0.785 total time= 3.0min\n",
      "[CV 3/3] END ......C=10, gamma=auto, kernel=rbf;, score=0.546 total time= 4.4min\n",
      "[CV 1/3] END ..C=100, gamma=auto, kernel=linear;, score=0.762 total time= 7.2min\n",
      "[CV 1/3] END ...............var_smoothing=1e-10;, score=0.348 total time=   2.7s\n",
      "[CV 2/3] END .C=0.1, gamma=scale, kernel=linear;, score=0.856 total time= 2.7min\n",
      "[CV 3/3] END ..C=0.1, gamma=auto, kernel=linear;, score=0.829 total time= 2.6min\n",
      "[CV 1/3] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time= 2.6min\n",
      "[CV 1/3] END ......C=1, gamma=auto, kernel=poly;, score=0.806 total time= 3.3min\n",
      "[CV 3/3] END ..C=10, gamma=scale, kernel=linear;, score=0.785 total time= 6.0min\n",
      "[CV 2/3] END ......C=10, gamma=auto, kernel=rbf;, score=0.580 total time= 4.7min\n",
      "[CV 2/3] END ..C=100, gamma=auto, kernel=linear;, score=0.781 total time= 7.9min\n",
      "[CV 1/3] END ...............var_smoothing=1e-09;, score=0.354 total time=   2.9s\n",
      "[CV 1/3] END ...C=0.1, gamma=scale, kernel=poly;, score=0.000 total time= 2.8min\n",
      "[CV 2/3] END ....C=0.1, gamma=auto, kernel=poly;, score=0.766 total time= 2.8min\n",
      "[CV 1/3] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time= 3.2min\n",
      "[CV 1/3] END .......C=1, gamma=auto, kernel=rbf;, score=0.090 total time= 4.0min\n",
      "[CV 2/3] END .....C=10, gamma=scale, kernel=rbf;, score=0.154 total time= 3.1min\n",
      "[CV 3/3] END .....C=10, gamma=auto, kernel=poly;, score=0.765 total time= 2.8min\n",
      "[CV 1/3] END ...C=100, gamma=scale, kernel=poly;, score=0.780 total time= 2.5min\n",
      "[CV 3/3] END ....C=100, gamma=scale, kernel=rbf;, score=0.715 total time= 2.8min\n",
      "[CV 1/3] END .....C=100, gamma=auto, kernel=rbf;, score=0.586 total time= 5.8min\n",
      "[CV 2/3] END ...............var_smoothing=1e-09;, score=0.349 total time=   2.7s\n",
      "[CV 1/3] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.000 total time= 3.3min\n",
      "[CV 3/3] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.000 total time= 3.9min\n",
      "[CV 1/3] END ....C=1, gamma=auto, kernel=linear;, score=0.829 total time= 3.9min\n",
      "[CV 2/3] END ..C=10, gamma=scale, kernel=linear;, score=0.787 total time= 7.1min\n",
      "[CV 3/3] END .C=100, gamma=scale, kernel=linear;, score=0.772 total time= 6.3min\n",
      "[CV 2/3] END .....C=100, gamma=auto, kernel=rbf;, score=0.620 total time= 5.9min\n",
      "[CV 1/3] END ..C=0.1, gamma=auto, kernel=linear;, score=0.844 total time= 2.8min\n",
      "[CV 2/3] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.000 total time= 4.0min\n",
      "[CV 3/3] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time= 3.2min\n",
      "[CV 1/3] END ..C=10, gamma=scale, kernel=linear;, score=0.780 total time= 7.1min\n",
      "[CV 1/3] END .C=100, gamma=scale, kernel=linear;, score=0.762 total time= 8.5min\n",
      "[CV 3/3] END .....C=100, gamma=auto, kernel=rbf;, score=0.595 total time= 5.1min\n"
     ]
    }
   ],
   "source": [
    "svm_analyze = SVC()\n",
    "svm_analyze_gs = GridSearchCV(svm_analyze, params_svm, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "svm_analyze_gs.fit(train_analyze_x, train_analyze_y)\n",
    "pred_analyze_y_svm = svm_analyze_gs.predict(test_analyze_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "745bc0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_analyze_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0f15c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9560336763330215\n",
      "Kappa Score ->  0.8321028208567374\n",
      "ROC AUC Score ->  0.8974432129924284\n",
      "F1 Score ->  0.8580060422960725\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      3575\n",
      "           1       0.91      0.81      0.86       701\n",
      "\n",
      "    accuracy                           0.96      4276\n",
      "   macro avg       0.94      0.90      0.92      4276\n",
      "weighted avg       0.96      0.96      0.95      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_analyze_y, pred_analyze_y_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a792e",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "64bdce03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr_analyze = LogisticRegression()\n",
    "lr_analyze_gs = GridSearchCV(lr_analyze, params_lr, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "lr_analyze_gs.fit(train_analyze_x, train_analyze_y)\n",
    "pred_analyze_y_lr = lr_analyze_gs.predict(test_analyze_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1be4fbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_analyze_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa24b7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.936155285313377\n",
      "Kappa Score ->  0.7318909215517486\n",
      "ROC AUC Score ->  0.8178931197190826\n",
      "F1 Score ->  0.7672634271099744\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3575\n",
      "           1       0.95      0.64      0.77       701\n",
      "\n",
      "    accuracy                           0.94      4276\n",
      "   macro avg       0.94      0.82      0.87      4276\n",
      "weighted avg       0.94      0.94      0.93      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_analyze_y, pred_analyze_y_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92ea879",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f92e3c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    }
   ],
   "source": [
    "rf_analyze = RandomForestClassifier()\n",
    "rf_analyze_gs = GridSearchCV(rf_analyze, params_rf, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "rf_analyze_gs.fit(train_analyze_x, train_analyze_y)\n",
    "pred_analyze_y_rf = rf_analyze_gs.predict(test_analyze_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "191e3f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_analyze_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36d3a08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9614125350795135\n",
      "Kappa Score ->  0.8511242593561674\n",
      "ROC AUC Score ->  0.9023802160749379\n",
      "F1 Score ->  0.8737566947207346\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      3575\n",
      "           1       0.94      0.81      0.87       701\n",
      "\n",
      "    accuracy                           0.96      4276\n",
      "   macro avg       0.95      0.90      0.93      4276\n",
      "weighted avg       0.96      0.96      0.96      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_analyze_y, pred_analyze_y_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f266568",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90ee39e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:19:43] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.439 total time=  15.7s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.666 total time=  36.4s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.630 total time=  36.7s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.718 total time= 2.1min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.713 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.654 total time=  36.5s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.629 total time=  37.2s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.722 total time= 3.1min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.704 total time= 1.3min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.445 total time=  15.9s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.488 total time=  16.0s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.630 total time=  37.0s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.630 total time=  37.0s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.722 total time= 1.3min\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.742 total time= 1.4min\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.844 total time=  19.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.822 total time=  46.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.833 total time=  42.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.833 total time=  40.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.788 total time=  15.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.820 total time=  33.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.836 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.825 total time=  45.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.833 total time=  42.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.810 total time=  19.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.817 total time=  15.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.801 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.812 total time=   9.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.822 total time=  30.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.055 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.057 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.069 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.055 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.069 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.077 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.055 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.057 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.059 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.065 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.055 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.055 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.067 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.055 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.311 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.319 total time=   9.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.286 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.473 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.334 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.325 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.280 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.280 total time=   9.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.504 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.332 total time=   9.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.336 total time=   4.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.342 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.158 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.399 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.323 total time=   9.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.165 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.328 total time=   9.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.863 total time=  14.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.847 total time=  17.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.861 total time= 1.2min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.825 total time=  29.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.839 total time=  28.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.819 total time=  15.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.822 total time=  13.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.831 total time=  25.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.827 total time=  13.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.828 total time=  56.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.853 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.856 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.846 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.805 total time=  24.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.822 total time=  23.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.807 total time=  13.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.063 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.075 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.055 total time=   5.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.073 total time=   8.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.069 total time=   9.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.067 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.112 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.065 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.065 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.079 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.057 total time=   3.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.065 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.061 total time=   7.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.063 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.061 total time=   3.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.067 total time=   8.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.273 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.566 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.371 total time=  14.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.217 total time=   7.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.324 total time=   7.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.239 total time=   7.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.262 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.347 total time=  14.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.350 total time=   7.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.262 total time=   7.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.282 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.345 total time=   7.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.251 total time=   7.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.305 total time=   6.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.327 total time=   7.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.361 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.299 total time=   6.8s\n",
      "[01:05:09] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:06:53] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:10:16] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:13:37] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_analyze = XGBClassifier()\n",
    "xgb_analyze_gs = GridSearchCV(xgb_analyze, params_xgb, scoring=\"f1\", n_jobs=-1, cv=3)\n",
    "xgb_analyze_gs.fit(train_analyze_x, train_analyze_y)\n",
    "pred_analyze_y_xgb = xgb_analyze_gs.predict(test_analyze_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "28fbe0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.5, 'learning_rate': 0.5, 'max_depth': 7, 'n_estimators': 100}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_analyze_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c8f8a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9590739008419084\n",
      "Kappa Score ->  0.843618863874223\n",
      "ROC AUC Score ->  0.9027018345420628\n",
      "F1 Score ->  0.8677248677248677\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3575\n",
      "           1       0.92      0.82      0.87       701\n",
      "\n",
      "    accuracy                           0.96      4276\n",
      "   macro avg       0.94      0.90      0.92      4276\n",
      "weighted avg       0.96      0.96      0.96      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_analyze_y, pred_analyze_y_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384fea72",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd14e34",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "21c48dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_x, evaluate_y = split_train_x.to_numpy(), split_train_y['Evaluate'].astype('long').to_numpy()#rus(split_train_x, split_train_y['Evaluate'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e55be36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17104, 94)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee4dc6",
   "metadata": {},
   "source": [
    "#### BERT Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8741ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_x_bert = evaluate_x[:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bfbf7885",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /Users/ylii0447/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /Users/ylii0447/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /Users/ylii0447/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "using `logging_steps` to initialize `eval_steps` to 10\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 13683\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training model for column evaluate\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='642' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/642 1:14:44 < 05:14, 0.13 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.477300</td>\n",
       "      <td>0.387792</td>\n",
       "      <td>0.506840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.316400</td>\n",
       "      <td>0.248049</td>\n",
       "      <td>0.852237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.197300</td>\n",
       "      <td>0.195532</td>\n",
       "      <td>0.898498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.149800</td>\n",
       "      <td>0.196426</td>\n",
       "      <td>0.903085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.174626</td>\n",
       "      <td>0.898409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.166154</td>\n",
       "      <td>0.903785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.133700</td>\n",
       "      <td>0.176839</td>\n",
       "      <td>0.898078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>0.147803</td>\n",
       "      <td>0.915990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>0.132252</td>\n",
       "      <td>0.925607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.102700</td>\n",
       "      <td>0.143567</td>\n",
       "      <td>0.929352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.124600</td>\n",
       "      <td>0.130292</td>\n",
       "      <td>0.930417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>0.125780</td>\n",
       "      <td>0.924007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>0.139563</td>\n",
       "      <td>0.922611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.105700</td>\n",
       "      <td>0.129482</td>\n",
       "      <td>0.930829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.142184</td>\n",
       "      <td>0.929902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.175100</td>\n",
       "      <td>0.126740</td>\n",
       "      <td>0.917437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.111798</td>\n",
       "      <td>0.935912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.091500</td>\n",
       "      <td>0.134427</td>\n",
       "      <td>0.932252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>0.126345</td>\n",
       "      <td>0.937019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>0.129892</td>\n",
       "      <td>0.928978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.097500</td>\n",
       "      <td>0.117426</td>\n",
       "      <td>0.935102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.102777</td>\n",
       "      <td>0.938468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.088400</td>\n",
       "      <td>0.111452</td>\n",
       "      <td>0.942486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.087800</td>\n",
       "      <td>0.108555</td>\n",
       "      <td>0.942897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.081200</td>\n",
       "      <td>0.113638</td>\n",
       "      <td>0.941312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.109800</td>\n",
       "      <td>0.112260</td>\n",
       "      <td>0.939766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.074100</td>\n",
       "      <td>0.120336</td>\n",
       "      <td>0.936678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.109561</td>\n",
       "      <td>0.939981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>0.114485</td>\n",
       "      <td>0.940997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.118742</td>\n",
       "      <td>0.937817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>0.114330</td>\n",
       "      <td>0.934947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.105616</td>\n",
       "      <td>0.945345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.105900</td>\n",
       "      <td>0.117827</td>\n",
       "      <td>0.933688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.105951</td>\n",
       "      <td>0.939463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>0.115196</td>\n",
       "      <td>0.939297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.162715</td>\n",
       "      <td>0.930725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>0.108731</td>\n",
       "      <td>0.938453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.105692</td>\n",
       "      <td>0.938324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.107761</td>\n",
       "      <td>0.946272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.100251</td>\n",
       "      <td>0.946013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.100281</td>\n",
       "      <td>0.945651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.107700</td>\n",
       "      <td>0.104198</td>\n",
       "      <td>0.938586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.089667</td>\n",
       "      <td>0.948260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.099816</td>\n",
       "      <td>0.949745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.095403</td>\n",
       "      <td>0.952627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.103496</td>\n",
       "      <td>0.948120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.109395</td>\n",
       "      <td>0.950140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.112042</td>\n",
       "      <td>0.948125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.117036</td>\n",
       "      <td>0.947853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>0.120529</td>\n",
       "      <td>0.948250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.122759</td>\n",
       "      <td>0.943696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.135611</td>\n",
       "      <td>0.939064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.123486</td>\n",
       "      <td>0.943600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>0.113633</td>\n",
       "      <td>0.947853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.117027</td>\n",
       "      <td>0.948457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>0.117677</td>\n",
       "      <td>0.949679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.121510</td>\n",
       "      <td>0.945869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.042900</td>\n",
       "      <td>0.117748</td>\n",
       "      <td>0.947032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.115076</td>\n",
       "      <td>0.947646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.114107</td>\n",
       "      <td>0.946700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-10\n",
      "Configuration saved in evaluate/checkpoint-10/config.json\n",
      "Model weights saved in evaluate/checkpoint-10/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-20\n",
      "Configuration saved in evaluate/checkpoint-20/config.json\n",
      "Model weights saved in evaluate/checkpoint-20/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-30\n",
      "Configuration saved in evaluate/checkpoint-30/config.json\n",
      "Model weights saved in evaluate/checkpoint-30/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-40\n",
      "Configuration saved in evaluate/checkpoint-40/config.json\n",
      "Model weights saved in evaluate/checkpoint-40/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-50\n",
      "Configuration saved in evaluate/checkpoint-50/config.json\n",
      "Model weights saved in evaluate/checkpoint-50/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-60\n",
      "Configuration saved in evaluate/checkpoint-60/config.json\n",
      "Model weights saved in evaluate/checkpoint-60/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-70\n",
      "Configuration saved in evaluate/checkpoint-70/config.json\n",
      "Model weights saved in evaluate/checkpoint-70/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-80\n",
      "Configuration saved in evaluate/checkpoint-80/config.json\n",
      "Model weights saved in evaluate/checkpoint-80/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-90\n",
      "Configuration saved in evaluate/checkpoint-90/config.json\n",
      "Model weights saved in evaluate/checkpoint-90/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-100\n",
      "Configuration saved in evaluate/checkpoint-100/config.json\n",
      "Model weights saved in evaluate/checkpoint-100/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-110\n",
      "Configuration saved in evaluate/checkpoint-110/config.json\n",
      "Model weights saved in evaluate/checkpoint-110/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-120\n",
      "Configuration saved in evaluate/checkpoint-120/config.json\n",
      "Model weights saved in evaluate/checkpoint-120/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-130\n",
      "Configuration saved in evaluate/checkpoint-130/config.json\n",
      "Model weights saved in evaluate/checkpoint-130/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-140\n",
      "Configuration saved in evaluate/checkpoint-140/config.json\n",
      "Model weights saved in evaluate/checkpoint-140/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-150\n",
      "Configuration saved in evaluate/checkpoint-150/config.json\n",
      "Model weights saved in evaluate/checkpoint-150/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-160\n",
      "Configuration saved in evaluate/checkpoint-160/config.json\n",
      "Model weights saved in evaluate/checkpoint-160/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-170\n",
      "Configuration saved in evaluate/checkpoint-170/config.json\n",
      "Model weights saved in evaluate/checkpoint-170/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-180\n",
      "Configuration saved in evaluate/checkpoint-180/config.json\n",
      "Model weights saved in evaluate/checkpoint-180/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-190\n",
      "Configuration saved in evaluate/checkpoint-190/config.json\n",
      "Model weights saved in evaluate/checkpoint-190/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-200\n",
      "Configuration saved in evaluate/checkpoint-200/config.json\n",
      "Model weights saved in evaluate/checkpoint-200/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-210\n",
      "Configuration saved in evaluate/checkpoint-210/config.json\n",
      "Model weights saved in evaluate/checkpoint-210/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-220\n",
      "Configuration saved in evaluate/checkpoint-220/config.json\n",
      "Model weights saved in evaluate/checkpoint-220/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-230\n",
      "Configuration saved in evaluate/checkpoint-230/config.json\n",
      "Model weights saved in evaluate/checkpoint-230/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-240\n",
      "Configuration saved in evaluate/checkpoint-240/config.json\n",
      "Model weights saved in evaluate/checkpoint-240/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-250\n",
      "Configuration saved in evaluate/checkpoint-250/config.json\n",
      "Model weights saved in evaluate/checkpoint-250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-260\n",
      "Configuration saved in evaluate/checkpoint-260/config.json\n",
      "Model weights saved in evaluate/checkpoint-260/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-270\n",
      "Configuration saved in evaluate/checkpoint-270/config.json\n",
      "Model weights saved in evaluate/checkpoint-270/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-280\n",
      "Configuration saved in evaluate/checkpoint-280/config.json\n",
      "Model weights saved in evaluate/checkpoint-280/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-290\n",
      "Configuration saved in evaluate/checkpoint-290/config.json\n",
      "Model weights saved in evaluate/checkpoint-290/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-300\n",
      "Configuration saved in evaluate/checkpoint-300/config.json\n",
      "Model weights saved in evaluate/checkpoint-300/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-310\n",
      "Configuration saved in evaluate/checkpoint-310/config.json\n",
      "Model weights saved in evaluate/checkpoint-310/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-320\n",
      "Configuration saved in evaluate/checkpoint-320/config.json\n",
      "Model weights saved in evaluate/checkpoint-320/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-330\n",
      "Configuration saved in evaluate/checkpoint-330/config.json\n",
      "Model weights saved in evaluate/checkpoint-330/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in evaluate/checkpoint-340/config.json\n",
      "Model weights saved in evaluate/checkpoint-340/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-350\n",
      "Configuration saved in evaluate/checkpoint-350/config.json\n",
      "Model weights saved in evaluate/checkpoint-350/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-360\n",
      "Configuration saved in evaluate/checkpoint-360/config.json\n",
      "Model weights saved in evaluate/checkpoint-360/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-370\n",
      "Configuration saved in evaluate/checkpoint-370/config.json\n",
      "Model weights saved in evaluate/checkpoint-370/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-380\n",
      "Configuration saved in evaluate/checkpoint-380/config.json\n",
      "Model weights saved in evaluate/checkpoint-380/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-390\n",
      "Configuration saved in evaluate/checkpoint-390/config.json\n",
      "Model weights saved in evaluate/checkpoint-390/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-400\n",
      "Configuration saved in evaluate/checkpoint-400/config.json\n",
      "Model weights saved in evaluate/checkpoint-400/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-410\n",
      "Configuration saved in evaluate/checkpoint-410/config.json\n",
      "Model weights saved in evaluate/checkpoint-410/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-420\n",
      "Configuration saved in evaluate/checkpoint-420/config.json\n",
      "Model weights saved in evaluate/checkpoint-420/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-430\n",
      "Configuration saved in evaluate/checkpoint-430/config.json\n",
      "Model weights saved in evaluate/checkpoint-430/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-440\n",
      "Configuration saved in evaluate/checkpoint-440/config.json\n",
      "Model weights saved in evaluate/checkpoint-440/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-450\n",
      "Configuration saved in evaluate/checkpoint-450/config.json\n",
      "Model weights saved in evaluate/checkpoint-450/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-460\n",
      "Configuration saved in evaluate/checkpoint-460/config.json\n",
      "Model weights saved in evaluate/checkpoint-460/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-470\n",
      "Configuration saved in evaluate/checkpoint-470/config.json\n",
      "Model weights saved in evaluate/checkpoint-470/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-480\n",
      "Configuration saved in evaluate/checkpoint-480/config.json\n",
      "Model weights saved in evaluate/checkpoint-480/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-490\n",
      "Configuration saved in evaluate/checkpoint-490/config.json\n",
      "Model weights saved in evaluate/checkpoint-490/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-500\n",
      "Configuration saved in evaluate/checkpoint-500/config.json\n",
      "Model weights saved in evaluate/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-510\n",
      "Configuration saved in evaluate/checkpoint-510/config.json\n",
      "Model weights saved in evaluate/checkpoint-510/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-520\n",
      "Configuration saved in evaluate/checkpoint-520/config.json\n",
      "Model weights saved in evaluate/checkpoint-520/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-530\n",
      "Configuration saved in evaluate/checkpoint-530/config.json\n",
      "Model weights saved in evaluate/checkpoint-530/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-540\n",
      "Configuration saved in evaluate/checkpoint-540/config.json\n",
      "Model weights saved in evaluate/checkpoint-540/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-550\n",
      "Configuration saved in evaluate/checkpoint-550/config.json\n",
      "Model weights saved in evaluate/checkpoint-550/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-560\n",
      "Configuration saved in evaluate/checkpoint-560/config.json\n",
      "Model weights saved in evaluate/checkpoint-560/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-570\n",
      "Configuration saved in evaluate/checkpoint-570/config.json\n",
      "Model weights saved in evaluate/checkpoint-570/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-580\n",
      "Configuration saved in evaluate/checkpoint-580/config.json\n",
      "Model weights saved in evaluate/checkpoint-580/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-590\n",
      "Configuration saved in evaluate/checkpoint-590/config.json\n",
      "Model weights saved in evaluate/checkpoint-590/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to evaluate/checkpoint-600\n",
      "Configuration saved in evaluate/checkpoint-600/config.json\n",
      "Model weights saved in evaluate/checkpoint-600/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from evaluate/checkpoint-450 (score: 0.9526271656851526).\n",
      "Saving model checkpoint to evaluate\n",
      "Configuration saved in evaluate/config.json\n",
      "Model weights saved in evaluate/pytorch_model.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 4276\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed. Started testing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:52]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9721702525724977\n",
      "Kappa Score ->  0.9081982284944801\n",
      "ROC AUC Score ->  0.9530047805658713\n",
      "F1 Score ->  0.9252981795354677\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3477\n",
      "           1       0.93      0.92      0.93       799\n",
      "\n",
      "    accuracy                           0.97      4276\n",
      "   macro avg       0.96      0.95      0.95      4276\n",
      "weighted avg       0.97      0.97      0.97      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if RUN_DL:\n",
    "    evaluate_bert = createBERT('evaluate', evaluate_x_bert, evaluate_y, split_test_x['Learning_outcome'].tolist(), split_test_y['Evaluate'].astype('long').to_numpy(), 64, 3, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3df449",
   "metadata": {},
   "source": [
    "#### Traditional ML Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "32254cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Unigram...\n",
      "Getting Bigram...\n",
      "Getting Tfidf...\n",
      "Getting ARI...\n",
      "Combining...\n",
      "Generated feature shape is (17104, 3094)\n",
      "Generated test feature is (4276, 3094)\n"
     ]
    }
   ],
   "source": [
    "combined_evaluate_x, column_names_evaluate, test_evaluate_x = generateX(evaluate_x, split_test_x.to_numpy(), 0, 1, 94)\n",
    "train_evaluate_x = combined_evaluate_x\n",
    "train_evaluate_y = evaluate_y\n",
    "test_evaluate_y = split_test_y['Evaluate'].astype('long').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d264345",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_evaluate += data.columns[8:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14840265",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "787b6d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    }
   ],
   "source": [
    "gnb_evaluate = GaussianNB()\n",
    "gnb_evaluate_gs = GridSearchCV(gnb_evaluate, params_nb, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "gnb_evaluate_gs.fit(train_evaluate_x, train_evaluate_y)\n",
    "pred_evaluate_y_gnb = gnb_evaluate_gs.predict(test_evaluate_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5562b55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 1e-08}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_evaluate_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1582da25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.5956501403180543\n",
      "Kappa Score ->  0.23351157092927388\n",
      "ROC AUC Score ->  0.7026861301677427\n",
      "F1 Score ->  0.44672\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.53      0.68      3477\n",
      "           1       0.30      0.87      0.45       799\n",
      "\n",
      "    accuracy                           0.60      4276\n",
      "   macro avg       0.62      0.70      0.56      4276\n",
      "weighted avg       0.83      0.60      0.64      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_evaluate_y, pred_evaluate_y_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c1f21",
   "metadata": {},
   "source": [
    "##### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aec5b896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.615 total time=  52.0s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.445 total time=  16.5s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.655 total time=  37.1s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.439 total time=  15.9s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.724 total time= 1.2min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.708 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.654 total time= 1.4min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.654 total time=  37.2s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.739 total time= 3.5min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.471 total time=  26.0s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.630 total time= 1.0min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.654 total time=  37.1s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.731 total time= 2.3min\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.736 total time= 1.3min\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.829 total time=  44.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.839 total time=  46.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.839 total time=  41.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.801 total time=  16.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.820 total time=  14.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.811 total time=   8.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.797 total time=  34.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.851 total time=  46.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.831 total time=  18.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.810 total time=   9.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.826 total time=  11.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.827 total time=  18.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.820 total time=  14.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.809 total time=   9.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.798 total time=  34.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.067 total time=   6.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.073 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.059 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.061 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.065 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.081 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.057 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.061 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.071 total time=   5.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.081 total time=   2.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.065 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.069 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.063 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.099 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.063 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.071 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.299 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.411 total time=   4.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.298 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.378 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.270 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.367 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.342 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.353 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.350 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.358 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.353 total time=   9.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.340 total time=   4.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.318 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.331 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.311 total time=   4.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.183 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.284 total time=   9.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.862 total time= 1.3min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.852 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.849 total time=  15.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.849 total time=  28.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.823 total time=  12.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.829 total time=  58.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.802 total time=  24.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.864 total time=  31.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.839 total time=  14.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.860 total time=  17.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.848 total time=  32.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.820 total time=  15.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.822 total time= 1.2min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.831 total time=  13.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.799 total time=  13.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.828 total time=  58.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.827 total time=  52.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.059 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.071 total time=   7.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.057 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.073 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.063 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.069 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.055 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.059 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.055 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.071 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.067 total time=   3.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.091 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.059 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.073 total time=   3.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.366 total time=   6.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.362 total time=   7.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.341 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.329 total time=  14.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.356 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.334 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.369 total time=  14.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.266 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.388 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.346 total time=  14.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.293 total time=   7.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.249 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.344 total time=  14.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.363 total time=   6.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.411 total time=   7.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.457 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.334 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.319 total time=  11.6s\n",
      "[01:05:11] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:06:55] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:07:54] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:09:45] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:11:39] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:13:38] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:14:34] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:15:29] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:16:44] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END ...............var_smoothing=1e-09;, score=0.406 total time=   2.8s\n",
      "[CV 2/3] END .C=0.1, gamma=scale, kernel=linear;, score=0.875 total time= 2.9min\n",
      "[CV 1/3] END ....C=0.1, gamma=auto, kernel=poly;, score=0.717 total time= 3.5min\n",
      "[CV 2/3] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time= 3.1min\n",
      "[CV 2/3] END ......C=1, gamma=auto, kernel=poly;, score=0.834 total time= 3.8min\n",
      "[CV 1/3] END .....C=10, gamma=scale, kernel=rbf;, score=0.083 total time= 3.6min\n",
      "[CV 2/3] END .....C=10, gamma=auto, kernel=poly;, score=0.795 total time= 3.3min\n",
      "[CV 3/3] END .C=100, gamma=scale, kernel=linear;, score=0.774 total time= 8.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.660 total time=  51.6s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.473 total time=  16.0s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.630 total time=  36.9s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.469 total time=  15.9s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.727 total time= 1.5min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.732 total time= 1.3min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.667 total time= 1.4min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.630 total time=  36.9s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.445 total time=  15.9s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.731 total time= 1.3min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.712 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.445 total time=  26.5s\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.655 total time= 1.0min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.488 total time=  15.7s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.630 total time=  37.1s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.736 total time= 2.6min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.713 total time= 1.2min\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.842 total time=  46.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.823 total time=  45.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.832 total time=  42.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.819 total time=  33.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.791 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.846 total time=  11.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.842 total time=  20.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.839 total time=  20.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.846 total time=  20.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.829 total time=   9.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.812 total time=  41.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.830 total time=  42.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.794 total time=  15.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.819 total time=  15.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.057 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.061 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.071 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.071 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.077 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.071 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.065 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.055 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.059 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.081 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.071 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.055 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.263 total time=   9.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.293 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.324 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.308 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.420 total time=   4.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.277 total time=   4.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.296 total time=   4.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.310 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.284 total time=   9.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.314 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.111 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.326 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.291 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.285 total time=  10.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.860 total time=  17.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.848 total time=  31.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.857 total time=  30.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.840 total time=  15.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.828 total time= 1.1min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.847 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.808 total time=  24.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.827 total time=  23.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.833 total time=  15.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.835 total time= 1.2min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.848 total time=  16.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.840 total time=  28.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.818 total time=  15.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.842 total time= 1.2min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.825 total time=  14.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.804 total time=  12.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.823 total time=  13.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.827 total time=  23.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.057 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.057 total time=   9.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.063 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.061 total time=   3.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.071 total time=   7.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.055 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.055 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.075 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.081 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.067 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.055 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.057 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.059 total time=   3.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.065 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.059 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.069 total time=   3.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.063 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.067 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.055 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.071 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.322 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.329 total time=  14.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.290 total time=  14.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.213 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.342 total time=  14.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.411 total time=   7.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.341 total time=   6.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.247 total time=   7.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.292 total time=   7.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.330 total time=  14.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.435 total time=   7.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.163 total time=   7.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.285 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.156 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.386 total time=  14.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.328 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.347 total time=  11.3s\n",
      "[01:05:07] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:06:03] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:08:25] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:09:40] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:12:02] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:13:17] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:14:59] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:16:43] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END ...............var_smoothing=1e-09;, score=0.386 total time=   2.9s\n",
      "[CV 1/3] END ..C=0.1, gamma=auto, kernel=linear;, score=0.883 total time= 2.9min\n",
      "[CV 2/3] END ....C=0.1, gamma=auto, kernel=poly;, score=0.757 total time= 3.6min\n",
      "[CV 3/3] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time= 3.1min\n",
      "[CV 3/3] END ......C=1, gamma=auto, kernel=poly;, score=0.825 total time= 3.6min\n",
      "[CV 3/3] END ....C=10, gamma=scale, kernel=poly;, score=0.346 total time= 3.1min\n",
      "[CV 1/3] END .....C=10, gamma=auto, kernel=poly;, score=0.803 total time= 3.3min\n",
      "[CV 1/3] END .C=100, gamma=scale, kernel=linear;, score=0.788 total time= 9.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.615 total time=  52.1s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.654 total time=  36.7s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.714 total time= 1.8min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.472 total time=  16.0s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.742 total time= 1.5min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.473 total time=  16.1s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.654 total time=  36.7s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.654 total time=  36.7s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.729 total time= 3.0min\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.736 total time= 1.5min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.472 total time=  16.4s\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.445 total time=  16.1s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.670 total time=  37.0s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.703 total time= 2.3min\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.743 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.850 total time=  11.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.821 total time=  18.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.842 total time=  20.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.837 total time=   9.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.815 total time=  42.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.831 total time=  41.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.796 total time=  34.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.848 total time=  45.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.825 total time=  21.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.808 total time=  17.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.832 total time=  18.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.833 total time=   9.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.810 total time=  41.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.819 total time=  35.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.057 total time=   6.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.065 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.073 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.069 total time=   5.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.055 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.055 total time=   5.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.069 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.069 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.065 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.083 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.055 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.063 total time=   2.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.065 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.077 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.075 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.063 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.059 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.057 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.343 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.327 total time=   4.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.310 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.376 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.349 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.301 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.302 total time=   8.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.346 total time=   4.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.154 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.273 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.308 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.258 total time=   9.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.356 total time=   9.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.318 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.351 total time=   9.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.180 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.322 total time=   9.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.851 total time=  32.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.835 total time= 1.2min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.850 total time= 1.1min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.842 total time=  28.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.804 total time=  13.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.823 total time=  14.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.830 total time=  24.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.823 total time=  12.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.826 total time=  59.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.850 total time=  32.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.830 total time=  16.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.835 total time= 1.2min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.852 total time=  15.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.842 total time=  27.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.830 total time=  13.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.827 total time=  56.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.825 total time=  24.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.073 total time=   5.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.067 total time=   8.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.063 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.055 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.057 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.083 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.059 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.061 total time=   3.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.063 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.067 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.063 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.109 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.061 total time=   7.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.067 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.057 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.059 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.077 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.055 total time=   7.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.185 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.372 total time=  15.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.392 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.265 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.349 total time=  14.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.374 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.304 total time=  14.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.337 total time=   7.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.390 total time=  14.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.180 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.366 total time=  14.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.343 total time=   7.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.387 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.285 total time=  14.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.321 total time=   6.5s\n",
      "[01:05:10] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:06:55] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:10:16] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:11:10] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:12:05] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:14:23] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:15:18] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:16:30] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END ...............var_smoothing=1e-09;, score=0.399 total time=   2.9s\n",
      "[CV 2/3] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.000 total time= 3.9min\n",
      "[CV 2/3] END ...C=1, gamma=scale, kernel=linear;, score=0.865 total time= 4.7min\n",
      "[CV 3/3] END ....C=1, gamma=auto, kernel=linear;, score=0.849 total time= 4.1min\n",
      "[CV 1/3] END ....C=10, gamma=scale, kernel=poly;, score=0.341 total time= 3.2min\n",
      "[CV 2/3] END ...C=10, gamma=auto, kernel=linear;, score=0.792 total time= 7.2min\n",
      "[CV 1/3] END ....C=100, gamma=scale, kernel=rbf;, score=0.673 total time= 3.6min\n",
      "[CV 2/3] END ....C=100, gamma=auto, kernel=poly;, score=0.784 total time= 2.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.648 total time=  51.9s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.489 total time=  16.1s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.669 total time=  37.2s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.484 total time=  15.8s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.691 total time= 1.2min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.488 total time=  16.2s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.736 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.488 total time=  15.9s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.629 total time=  37.1s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.474 total time=  16.2s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.446 total time=  36.0s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.488 total time=  16.1s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.703 total time= 1.3min\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.445 total time=  16.0s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.471 total time=  15.7s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.732 total time= 1.3min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.629 total time= 1.0min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.629 total time=  37.2s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.722 total time= 2.3min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.472 total time=  15.9s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.704 total time= 1.2min\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.825 total time=   8.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.825 total time=  11.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.844 total time=  11.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.820 total time=  10.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.829 total time=  10.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.804 total time=  18.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.834 total time=  18.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.825 total time=   9.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.814 total time=  39.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.822 total time=  35.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.840 total time=  46.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.838 total time=  46.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.834 total time=  42.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.793 total time=  15.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.822 total time=  16.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.811 total time=   7.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.795 total time=  29.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.055 total time=   5.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.065 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.055 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.057 total time=   2.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.065 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.063 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.067 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.085 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.075 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.099 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.065 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.067 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.075 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.069 total time=   5.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.519 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.362 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.277 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.287 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.378 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.300 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.290 total time=   9.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.327 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.255 total time=   4.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.324 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.325 total time=   4.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.302 total time=   3.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.337 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.249 total time=   3.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.332 total time=   8.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.383 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.860 total time=  29.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.841 total time=  32.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.846 total time=  31.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.820 total time=  14.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.847 total time=  16.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.820 total time=  15.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.844 total time= 1.1min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.830 total time=  57.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.827 total time=  57.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.847 total time=  16.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.835 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.850 total time=  15.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.844 total time=  28.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.842 total time=  15.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.848 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.800 total time=  23.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.807 total time=  24.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.089 total time=   5.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.085 total time=   3.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.055 total time=   9.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.055 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.063 total time=   7.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.075 total time=   2.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.061 total time=   3.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.059 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.065 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.057 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.061 total time=   7.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.055 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.071 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.053 total time=   2.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.069 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.051 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.073 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.067 total time=   3.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.400 total time=   6.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.307 total time=  15.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.298 total time=   6.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.289 total time=   7.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.339 total time=   6.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.319 total time=  14.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.294 total time=   7.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.298 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.323 total time=  14.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.384 total time=  14.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.296 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.335 total time=  14.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.312 total time=  14.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.266 total time=   7.0s\n",
      "[01:05:08] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:06:05] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:07:48] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:08:44] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:11:02] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:12:00] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:13:13] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:15:35] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END ...............var_smoothing=1e-08;, score=0.426 total time=   3.1s\n",
      "[CV 2/3] END ...C=0.1, gamma=scale, kernel=poly;, score=0.000 total time= 3.2min\n",
      "[CV 3/3] END ....C=0.1, gamma=auto, kernel=poly;, score=0.746 total time= 3.5min\n",
      "[CV 1/3] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time= 3.7min\n",
      "[CV 2/3] END .......C=1, gamma=auto, kernel=rbf;, score=0.070 total time= 4.4min\n",
      "[CV 3/3] END .....C=10, gamma=scale, kernel=rbf;, score=0.069 total time= 3.4min\n",
      "[CV 1/3] END ......C=10, gamma=auto, kernel=rbf;, score=0.487 total time= 5.9min\n",
      "[CV 3/3] END ....C=100, gamma=scale, kernel=rbf;, score=0.708 total time= 3.5min\n",
      "[CV 3/3] END ....C=100, gamma=auto, kernel=poly;, score=0.768 total time= 2.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.469 total time=  21.8s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.468 total time=  16.0s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.650 total time=  37.1s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.476 total time=  22.8s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.698 total time= 2.1min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.487 total time=  35.1s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.654 total time= 1.4min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.669 total time=  36.9s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.469 total time=  35.0s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.721 total time= 1.3min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.742 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.742 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.654 total time=  36.9s\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.654 total time=  37.1s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.712 total time= 2.6min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.846 total time=   7.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.845 total time=  18.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.839 total time=  11.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.822 total time=  19.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.834 total time=  18.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.830 total time=  10.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.813 total time=  40.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.815 total time=   9.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.813 total time=  15.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.817 total time=  14.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.838 total time=  10.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.829 total time=  44.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.849 total time=  44.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.809 total time=  17.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.832 total time=  17.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.808 total time=   8.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.796 total time=  35.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.815 total time=  31.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.069 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.077 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.055 total time=   5.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.061 total time=   5.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.067 total time=   5.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.075 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.055 total time=   5.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.059 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.073 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.055 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.053 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.055 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.059 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.061 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.057 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.057 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.221 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.329 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.326 total time=   9.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.307 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.363 total time=   4.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.311 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.322 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.274 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.308 total time=   8.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.328 total time=   4.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.166 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.342 total time=   9.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.297 total time=   4.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.257 total time=   3.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.327 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.511 total time=   4.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.835 total time=  30.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.848 total time= 1.3min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.843 total time= 1.2min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.841 total time= 1.1min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.831 total time=  56.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.838 total time=  31.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.836 total time=  31.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.855 total time=  31.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.838 total time=  15.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.843 total time= 1.2min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.843 total time= 1.2min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.806 total time=  55.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.055 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.055 total time=   3.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.069 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.055 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.069 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.073 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.057 total time=   7.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.065 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.067 total time=   3.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.065 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.079 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.071 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.162 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.065 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.055 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.063 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.055 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.332 total time=  14.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.491 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.619 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.386 total time=  14.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.370 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.251 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.340 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.286 total time=  14.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.329 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.360 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.351 total time=  14.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.210 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.340 total time=  14.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.350 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.331 total time=  14.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.415 total time=  14.2s\n",
      "[01:05:13] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:06:26] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:08:09] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:09:55] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:13:23] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:16:41] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END ...............var_smoothing=1e-10;, score=0.388 total time=   2.7s\n",
      "[CV 3/3] END ...C=0.1, gamma=scale, kernel=poly;, score=0.000 total time= 3.2min\n",
      "[CV 2/3] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.000 total time= 4.5min\n",
      "[CV 3/3] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time= 3.8min\n",
      "[CV 1/3] END ..C=10, gamma=scale, kernel=linear;, score=0.798 total time= 7.2min\n",
      "[CV 2/3] END ......C=10, gamma=auto, kernel=rbf;, score=0.502 total time= 6.0min\n",
      "[CV 2/3] END ..C=100, gamma=auto, kernel=linear;, score=0.773 total time= 7.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.460 total time=  22.3s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.650 total time=  36.5s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.669 total time=  37.1s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.696 total time= 1.9min\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.722 total time= 1.3min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.626 total time= 1.4min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.669 total time=  36.7s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.702 total time= 3.1min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.713 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.669 total time=  36.8s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.669 total time=  37.0s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.471 total time=  15.8s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.736 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.488 total time=  15.8s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.731 total time= 1.1min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.849 total time=  44.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.848 total time=  46.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.809 total time=  17.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.809 total time=  17.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.814 total time=  15.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.797 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.807 total time=   8.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.803 total time=  16.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.848 total time=  19.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.845 total time=  18.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.841 total time=  10.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.821 total time=  43.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.831 total time=  43.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.817 total time=  36.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.798 total time=  15.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.073 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.085 total time=   2.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.063 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.057 total time=   2.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.057 total time=   5.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.071 total time=   5.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.061 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.061 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.057 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.059 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.051 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.057 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.055 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.085 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.055 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.059 total time=   5.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.055 total time=   5.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.332 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.344 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.305 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.272 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.325 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.311 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.329 total time=   4.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.439 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.354 total time=   4.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.181 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.371 total time=   9.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.362 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.299 total time=   4.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.347 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.293 total time=   9.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.265 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.298 total time=   4.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.837 total time=  15.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.861 total time=  31.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.848 total time=  18.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.834 total time=  30.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.843 total time=  30.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.847 total time=  27.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.842 total time=  15.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.823 total time= 1.1min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.826 total time=  13.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.832 total time=  24.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.849 total time=  16.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.860 total time=  17.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.852 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.847 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.822 total time=  28.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.822 total time=  25.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.824 total time=  24.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.819 total time=  12.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.801 total time=  49.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.083 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.073 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.065 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.073 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.059 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.061 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.073 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.065 total time=   3.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.067 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.065 total time=   7.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.091 total time=   3.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.063 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.055 total time=   7.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.055 total time=   8.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.288 total time=   7.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.358 total time=   7.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.342 total time=   7.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.349 total time=   7.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.213 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.312 total time=  14.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.265 total time=   7.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.248 total time=  14.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.356 total time=   7.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.307 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.307 total time=  14.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.384 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.334 total time=  14.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.380 total time=   6.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.323 total time=   4.1s\n",
      "[01:05:06] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:06:00] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:08:23] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:09:36] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:11:58] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:13:10] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:15:31] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:16:46] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END ...............var_smoothing=1e-08;, score=0.422 total time=   2.9s\n",
      "[CV 1/3] END .C=0.1, gamma=scale, kernel=linear;, score=0.883 total time= 2.8min\n",
      "[CV 2/3] END ..C=0.1, gamma=auto, kernel=linear;, score=0.875 total time= 2.9min\n",
      "[CV 1/3] END .....C=1, gamma=scale, kernel=poly;, score=0.000 total time= 3.1min\n",
      "[CV 1/3] END ......C=1, gamma=auto, kernel=poly;, score=0.838 total time= 3.6min\n",
      "[CV 3/3] END ..C=10, gamma=scale, kernel=linear;, score=0.798 total time= 6.4min\n",
      "[CV 3/3] END ......C=10, gamma=auto, kernel=rbf;, score=0.529 total time= 5.3min\n",
      "[CV 1/3] END ..C=100, gamma=auto, kernel=linear;, score=0.788 total time= 8.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.648 total time=  51.7s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.666 total time=  36.9s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.462 total time=  23.6s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.720 total time= 1.2min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.737 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.668 total time= 1.4min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.488 total time=  16.0s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.669 total time=  36.8s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.709 total time= 3.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.654 total time= 1.0min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.654 total time=  36.8s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.445 total time=  26.6s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.743 total time= 2.6min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.854 total time=  18.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.843 total time=  20.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.837 total time=  21.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.801 total time=   9.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.832 total time=  11.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.835 total time=  19.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.814 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.822 total time=   9.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.819 total time=  13.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.802 total time=   8.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.814 total time=  35.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.824 total time=  19.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.824 total time=  20.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.842 total time=  20.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.815 total time=   9.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.837 total time=  10.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.833 total time=  18.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.807 total time=   9.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.809 total time=   9.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.782 total time=   7.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.811 total time=   9.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.812 total time=  15.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.794 total time=   7.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.063 total time=   3.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.075 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.065 total time=   3.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.059 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.053 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.065 total time=   5.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.063 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.049 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.063 total time=   2.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.061 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.055 total time=   5.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.063 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.061 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.057 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.063 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.055 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.057 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.085 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.059 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.225 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.332 total time=   9.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.256 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.320 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.366 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.283 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.307 total time=   8.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.354 total time=   4.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.339 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.340 total time=   9.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.393 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.381 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.397 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.281 total time=   3.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.321 total time=   8.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.307 total time=   8.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.351 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.231 total time=   9.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.849 total time= 1.3min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.834 total time= 1.2min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.826 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.805 total time=  57.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.803 total time=  57.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.858 total time=  29.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.846 total time=  17.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.847 total time= 1.2min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.826 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.805 total time=  56.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.831 total time=  51.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.067 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.071 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.073 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.065 total time=   3.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.065 total time=   7.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.055 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.055 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.065 total time=   7.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.069 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.055 total time=   7.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.065 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.063 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.384 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.511 total time=   3.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.338 total time=  14.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.282 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.305 total time=  14.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.341 total time=  14.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.357 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.459 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.322 total time=  14.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.328 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.358 total time=  14.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.360 total time=  14.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.310 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.319 total time=  14.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.437 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.382 total time=  13.8s\n",
      "[01:05:17] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:06:32] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:08:14] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:09:59] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:13:19] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:15:02] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:16:50] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END ...............var_smoothing=1e-08;, score=0.407 total time=   3.1s\n",
      "[CV 3/3] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.000 total time= 3.8min\n",
      "[CV 1/3] END ...C=1, gamma=scale, kernel=linear;, score=0.867 total time= 4.4min\n",
      "[CV 2/3] END ....C=1, gamma=auto, kernel=linear;, score=0.865 total time= 4.5min\n",
      "[CV 2/3] END ....C=10, gamma=scale, kernel=poly;, score=0.302 total time= 3.1min\n",
      "[CV 3/3] END ...C=10, gamma=auto, kernel=linear;, score=0.798 total time= 6.1min\n",
      "[CV 2/3] END ...C=100, gamma=scale, kernel=poly;, score=0.759 total time= 3.2min\n",
      "[CV 3/3] END ..C=100, gamma=auto, kernel=linear;, score=0.774 total time= 7.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .C=0.1, gamma=scale, kernel=linear;, score=0.872 total time= 2.8min\n",
      "[CV 3/3] END ..C=0.1, gamma=auto, kernel=linear;, score=0.872 total time= 2.8min\n",
      "[CV 3/3] END ...C=1, gamma=scale, kernel=linear;, score=0.849 total time= 4.2min\n",
      "[CV 1/3] END .......C=1, gamma=auto, kernel=rbf;, score=0.072 total time= 4.5min\n",
      "[CV 2/3] END .....C=10, gamma=scale, kernel=rbf;, score=0.072 total time= 3.4min\n",
      "[CV 3/3] END .....C=10, gamma=auto, kernel=poly;, score=0.771 total time= 3.2min\n",
      "[CV 1/3] END ...C=100, gamma=scale, kernel=poly;, score=0.720 total time= 3.1min\n",
      "[CV 2/3] END ....C=100, gamma=scale, kernel=rbf;, score=0.728 total time= 3.6min\n",
      "[CV 1/3] END .....C=100, gamma=auto, kernel=rbf;, score=0.577 total time= 7.3min\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.659 total time=  51.5s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.624 total time=  37.0s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.711 total time= 1.9min\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.445 total time=  16.3s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.704 total time= 1.3min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.445 total time=  16.1s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.669 total time=  36.6s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.445 total time=  16.2s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.630 total time=  36.9s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.733 total time= 3.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.488 total time=  26.4s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.670 total time= 1.1min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.471 total time=  16.2s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.472 total time=  26.3s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.488 total time=  15.8s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.703 total time= 1.3min\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.445 total time=  16.0s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.722 total time= 1.2min\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.827 total time=  18.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.849 total time=  45.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.836 total time=  19.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.808 total time=   9.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.821 total time=  10.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.821 total time=  18.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.789 total time=   7.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.796 total time=  34.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.817 total time=  35.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.825 total time=   9.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.846 total time=  11.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.817 total time=  11.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.828 total time=  10.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.837 total time=  17.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.825 total time=   9.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.811 total time=  41.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.812 total time=  34.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.814 total time=  14.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.067 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.065 total time=   6.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.055 total time=   5.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.055 total time=   2.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.057 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.095 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.063 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.063 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.109 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.059 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.087 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.071 total time=   5.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.055 total time=   5.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.071 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.069 total time=   5.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.059 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.055 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.349 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.377 total time=   8.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.335 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.346 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.327 total time=   4.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.312 total time=   9.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.325 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.351 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.349 total time=   9.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.363 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.347 total time=   3.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.279 total time=   9.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.498 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.358 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.365 total time=  10.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.835 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.844 total time=  15.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.848 total time=  27.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.844 total time=  15.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.821 total time=  28.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.827 total time=  27.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.822 total time=  24.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.803 total time=  14.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.806 total time=  55.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.862 total time= 1.2min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.829 total time=  30.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.847 total time=  28.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.842 total time=  16.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.825 total time=  28.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.840 total time=  28.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.825 total time=  24.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.829 total time=  12.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.825 total time=  56.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.055 total time=   3.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.071 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.055 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.069 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.057 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.055 total time=   7.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.049 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.071 total time=   7.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.057 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.065 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.077 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.101 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.071 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.069 total time=   7.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.055 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.069 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.063 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.459 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.319 total time=  14.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.397 total time=   7.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.269 total time=   7.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.239 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.279 total time=  14.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.303 total time=   7.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.350 total time=   7.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.255 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.318 total time=  14.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.319 total time=   7.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.320 total time=   6.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.361 total time=   7.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.312 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.323 total time=  14.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.341 total time=   7.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.338 total time=   6.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.350 total time=  12.2s\n",
      "[01:05:19] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:07:38] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:08:34] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:09:49] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:11:31] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:13:15] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:14:56] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:16:38] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END ...............var_smoothing=1e-10;, score=0.390 total time=   2.6s\n",
      "[CV 1/3] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.000 total time= 3.7min\n",
      "[CV 3/3] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.000 total time= 4.5min\n",
      "[CV 1/3] END ....C=1, gamma=auto, kernel=linear;, score=0.867 total time= 4.3min\n",
      "[CV 2/3] END ..C=10, gamma=scale, kernel=linear;, score=0.792 total time= 7.5min\n",
      "[CV 2/3] END .C=100, gamma=scale, kernel=linear;, score=0.773 total time= 8.9min\n",
      "[CV 2/3] END .....C=100, gamma=auto, kernel=rbf;, score=0.567 total time= 7.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.421 total time=  22.1s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.484 total time=  15.7s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.624 total time=  36.9s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.425 total time=  23.1s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.719 total time= 2.1min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.446 total time=  35.1s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.469 total time=  34.9s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.626 total time= 1.4min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.487 total time=  35.6s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.472 total time=  15.8s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.735 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.489 total time=  15.7s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.722 total time= 1.3min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.670 total time= 1.1min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.669 total time=  37.1s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.489 total time=  26.7s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.445 total time=  16.3s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.731 total time= 1.3min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.713 total time= 1.4min\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.845 total time=   8.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.840 total time=  11.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.844 total time=  47.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.837 total time=  41.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.832 total time=  17.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.809 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.815 total time=  34.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.811 total time=  15.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.816 total time=   9.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.847 total time=  10.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.841 total time=  46.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.830 total time=  43.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.833 total time=  41.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.818 total time=  35.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.055 total time=   2.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.055 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.055 total time=   2.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.154 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.067 total time=   2.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.055 total time=   5.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.057 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.059 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.069 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.055 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.069 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.089 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.057 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.057 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.067 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.071 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.071 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.071 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.069 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.282 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.372 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.374 total time=   4.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.318 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.339 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.379 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.272 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.280 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.305 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.293 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.317 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.261 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.380 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.372 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.294 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.850 total time=  16.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.827 total time=  16.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.857 total time=  18.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.836 total time=  16.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.861 total time= 1.2min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.844 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.808 total time=  23.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.824 total time=  24.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.802 total time=  11.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.861 total time=  17.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.847 total time=  32.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.862 total time= 1.3min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.828 total time=  28.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.844 total time=  28.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.826 total time=  14.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.823 total time= 1.1min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.826 total time=  57.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.061 total time=   3.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.059 total time=   3.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.065 total time=   7.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.065 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.057 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.077 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.055 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.055 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.063 total time=   3.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.063 total time=   3.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.071 total time=   7.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.055 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.055 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.077 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.071 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.065 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.328 total time=   6.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.314 total time=   7.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.334 total time=   7.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.339 total time=  14.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.384 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.349 total time=  14.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.364 total time=  14.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.355 total time=   7.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.379 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.367 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.338 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.299 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.365 total time=  14.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.243 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.312 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.367 total time=  14.0s\n",
      "[01:05:15] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:06:33] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:09:53] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:11:35] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:13:21] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:16:48] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END ...............var_smoothing=1e-10;, score=0.376 total time=   2.6s\n",
      "[CV 1/3] END ...C=0.1, gamma=scale, kernel=poly;, score=0.000 total time= 3.2min\n",
      "[CV 1/3] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.000 total time= 4.5min\n",
      "[CV 2/3] END ......C=1, gamma=scale, kernel=rbf;, score=0.000 total time= 3.7min\n",
      "[CV 3/3] END .......C=1, gamma=auto, kernel=rbf;, score=0.056 total time= 4.4min\n",
      "[CV 1/3] END ...C=10, gamma=auto, kernel=linear;, score=0.798 total time= 6.9min\n",
      "[CV 3/3] END ...C=100, gamma=scale, kernel=poly;, score=0.750 total time= 3.1min\n",
      "[CV 1/3] END ....C=100, gamma=auto, kernel=poly;, score=0.795 total time= 3.3min\n",
      "[CV 3/3] END .....C=100, gamma=auto, kernel=rbf;, score=0.583 total time= 6.9min\n"
     ]
    }
   ],
   "source": [
    "svm_evaluate = SVC()\n",
    "svm_evaluate_gs = GridSearchCV(svm_evaluate, params_svm, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "svm_evaluate_gs.fit(train_evaluate_x, train_evaluate_y)\n",
    "pred_evaluate_y_svm = svm_evaluate_gs.predict(test_evaluate_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "21fb1116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_evaluate_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "92f9c75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9586061739943873\n",
      "Kappa Score ->  0.8610375055448982\n",
      "ROC AUC Score ->  0.9220111924490024\n",
      "F1 Score ->  0.8863198458574182\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      3477\n",
      "           1       0.91      0.86      0.89       799\n",
      "\n",
      "    accuracy                           0.96      4276\n",
      "   macro avg       0.94      0.92      0.93      4276\n",
      "weighted avg       0.96      0.96      0.96      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_evaluate_y, pred_evaluate_y_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eef955",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "03f3e19e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr_evaluate = LogisticRegression()\n",
    "lr_evaluate_gs = GridSearchCV(lr_evaluate, params_lr, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "lr_evaluate_gs.fit(train_evaluate_x, train_evaluate_y)\n",
    "pred_evaluate_y_lr = lr_evaluate_gs.predict(test_evaluate_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b31bbc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_evaluate_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b98002b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9197848456501403\n",
      "Kappa Score ->  0.6939989351172623\n",
      "ROC AUC Score ->  0.799334118755721\n",
      "F1 Score ->  0.7387661843107387\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      3477\n",
      "           1       0.94      0.61      0.74       799\n",
      "\n",
      "    accuracy                           0.92      4276\n",
      "   macro avg       0.93      0.80      0.85      4276\n",
      "weighted avg       0.92      0.92      0.91      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_evaluate_y, pred_evaluate_y_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01f205",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5d63fc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    }
   ],
   "source": [
    "rf_evaluate = RandomForestClassifier()\n",
    "rf_evaluate_gs = GridSearchCV(rf_evaluate, params_rf, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "rf_evaluate_gs.fit(train_evaluate_x, train_evaluate_y)\n",
    "pred_evaluate_y_rf = rf_evaluate_gs.predict(test_evaluate_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "070a006c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_evaluate_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a64770ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9665575304022451\n",
      "Kappa Score ->  0.8869526762650686\n",
      "ROC AUC Score ->  0.9317202658053657\n",
      "F1 Score ->  0.9073233959818535\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3477\n",
      "           1       0.94      0.88      0.91       799\n",
      "\n",
      "    accuracy                           0.97      4276\n",
      "   macro avg       0.96      0.93      0.94      4276\n",
      "weighted avg       0.97      0.97      0.97      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_evaluate_y, pred_evaluate_y_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4fdebd",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bc5b198a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:13:49] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.621 total time=  52.3s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.418 total time=  16.2s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.601 total time=  37.1s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.414 total time=  15.8s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.672 total time= 1.5min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.725 total time= 1.3min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.623 total time= 1.4min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.601 total time=  37.1s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.396 total time=  16.1s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.697 total time= 1.3min\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.387 total time=  15.8s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.420 total time=  15.8s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.724 total time= 1.3min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.601 total time= 1.0min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.601 total time=  36.8s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.669 total time= 2.3min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.422 total time=  15.7s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.687 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.890 total time=  12.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.891 total time=  50.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.887 total time=  21.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.886 total time=  20.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.881 total time=  10.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.885 total time=  46.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.868 total time=  38.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.889 total time=  21.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.888 total time=  21.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.888 total time=  22.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.882 total time=  10.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.883 total time=  47.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.885 total time=  46.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.880 total time=  38.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.050 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.061 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.058 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.059 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.052 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.058 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.050 total time=   2.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.050 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.061 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.059 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.058 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.058 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.059 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.060 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.054 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.058 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.063 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.356 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.310 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.333 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.413 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.331 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.314 total time=   4.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.422 total time=   4.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.295 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.337 total time=   9.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.305 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.297 total time=   4.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.301 total time=   4.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.363 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.312 total time=   9.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.391 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.890 total time=  16.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.890 total time=  19.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.892 total time= 1.4min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.889 total time= 1.3min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.890 total time= 1.2min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.884 total time= 1.0min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.898 total time= 1.4min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.890 total time=  34.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.886 total time=  32.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.892 total time=  30.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.889 total time=  16.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.887 total time= 1.2min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.885 total time=  15.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.881 total time=  26.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.054 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.054 total time=   5.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.048 total time=   3.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.056 total time=   8.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.061 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.065 total time=   3.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.050 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.061 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.058 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.058 total time=   3.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.061 total time=   3.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.065 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.054 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.054 total time=   7.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.048 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.061 total time=   3.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.050 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.052 total time=   2.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.333 total time=   6.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.374 total time=  14.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.441 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.393 total time=  14.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.294 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.276 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.330 total time=  14.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.384 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.351 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.360 total time=  15.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.361 total time=   6.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.326 total time=  14.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.260 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.354 total time=  14.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.278 total time=  14.4s\n",
      "[02:58:09] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:59:35] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:01:27] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:03:22] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:07:03] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:08:58] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.621 total time=  52.0s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.597 total time=  37.0s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.640 total time= 1.9min\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.387 total time=  16.3s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.698 total time= 1.3min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.386 total time=  16.0s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.622 total time=  36.4s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.387 total time=  16.1s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.623 total time=  36.6s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.695 total time= 3.1min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.714 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.623 total time=  36.7s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.623 total time=  36.6s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.422 total time=  15.8s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.687 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.399 total time=  16.0s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.724 total time= 1.2min\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.883 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.881 total time=  11.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.889 total time=  49.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.885 total time=  46.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.883 total time=  19.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.870 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.875 total time=  10.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.872 total time=  17.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.871 total time=   8.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.892 total time=  11.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.884 total time=  21.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.892 total time=  50.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.887 total time=  21.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.884 total time=  20.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.880 total time=  10.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.880 total time=  10.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.878 total time=  17.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.872 total time=   9.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.879 total time=  37.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.058 total time=   6.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.058 total time=   5.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.063 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.060 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.058 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.059 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.061 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.063 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.071 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.058 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.067 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.054 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.058 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.052 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.080 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.058 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.315 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.189 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.344 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.296 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.447 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.355 total time=   9.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.299 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.350 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.403 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.380 total time=   4.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.336 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.324 total time=   9.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.235 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.272 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.358 total time=  10.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.892 total time= 1.4min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.886 total time=  17.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.890 total time=  32.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.884 total time=  17.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.886 total time= 1.2min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.883 total time= 1.1min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.882 total time= 1.1min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.890 total time=  34.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.895 total time=  18.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.888 total time=  17.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.889 total time=  16.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.893 total time=  17.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.887 total time=  17.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.893 total time= 1.3min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.878 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.876 total time=  55.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.052 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.056 total time=   3.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.061 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.052 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.065 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.065 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.050 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.048 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.058 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.069 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.060 total time=   7.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.048 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.046 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.107 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.054 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.288 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.397 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.340 total time=  14.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.318 total time=   7.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.325 total time=  14.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.297 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.329 total time=   6.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.268 total time=   7.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.331 total time=  14.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.366 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.374 total time=  14.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.365 total time=  14.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.348 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.311 total time=  11.8s\n",
      "[02:58:15] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:00:50] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:01:51] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:03:10] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:05:03] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:06:55] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:09:28] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.382 total time=  15.8s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.619 total time=  36.8s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.601 total time=  37.2s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.649 total time= 2.1min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.714 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.596 total time=  36.5s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.601 total time=  36.9s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.666 total time= 3.1min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.697 total time= 1.3min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.385 total time=  15.8s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.397 total time=  16.1s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.601 total time=  37.2s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.601 total time=  36.6s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.669 total time= 1.3min\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.738 total time= 1.4min\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.890 total time=  19.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.885 total time=  21.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.884 total time=  21.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.884 total time=  10.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.886 total time=  12.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.884 total time=  20.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.878 total time=  10.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.878 total time=  10.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.875 total time=  15.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.877 total time=   9.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.881 total time=  38.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.894 total time=  48.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.884 total time=  22.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.885 total time=  19.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.877 total time=  11.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.882 total time=  11.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.884 total time=  19.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.877 total time=   9.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.869 total time=  39.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.881 total time=  34.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.050 total time=   2.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.054 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.054 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.063 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.059 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.063 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.052 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.063 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.054 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.069 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.105 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.058 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.054 total time=   5.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.378 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.391 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.322 total time=   8.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.271 total time=   4.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.366 total time=   9.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.394 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.373 total time=   4.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.367 total time=   4.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.272 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.320 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.386 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.313 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.331 total time=   8.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.315 total time=   9.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.893 total time= 1.4min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.894 total time= 1.4min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.890 total time=  17.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.891 total time=  30.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.877 total time=  15.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.878 total time= 1.0min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.883 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.886 total time=  18.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.894 total time=  19.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.892 total time=  35.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.895 total time=  32.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.887 total time=  17.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.887 total time=  31.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.886 total time=  30.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.879 total time=  26.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.879 total time=  14.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.877 total time= 1.1min\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.050 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.052 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.061 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.065 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.048 total time=   2.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.058 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.058 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.058 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.061 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.078 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.061 total time=   7.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.054 total time=   7.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.048 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.056 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.058 total time=   3.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.054 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.056 total time=   7.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.054 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.054 total time=   8.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.316 total time=   7.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.256 total time=   7.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.323 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.336 total time=  14.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.315 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.422 total time=  14.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.376 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.366 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.347 total time=  14.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.397 total time=   7.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.165 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.332 total time=  14.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.250 total time=   6.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.275 total time=   7.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.314 total time=   7.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.298 total time=   7.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.302 total time=   4.1s\n",
      "[02:58:01] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:59:05] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:01:37] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:02:57] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:05:30] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:06:50] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:09:22] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:10:46] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.402 total time=  22.5s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.595 total time=  36.8s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.622 total time=  37.2s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.678 total time= 1.9min\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.669 total time= 1.3min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.601 total time= 1.4min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.601 total time=  36.9s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.684 total time= 3.4min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.396 total time=  26.3s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.623 total time= 1.0min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.420 total time=  16.1s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.386 total time=  26.2s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.738 total time= 2.6min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.890 total time=   8.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.894 total time=  21.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.882 total time=  11.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.883 total time=  21.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.882 total time=  20.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.883 total time=  11.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.877 total time=  11.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.887 total time=  44.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.874 total time=  17.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.875 total time=  16.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.886 total time=  10.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.887 total time=  12.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.889 total time=  20.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.881 total time=  12.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.885 total time=  49.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.880 total time=  45.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.880 total time=  39.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.869 total time=  15.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.050 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.052 total time=   6.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.058 total time=   3.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.063 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.058 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.069 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.050 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.050 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.061 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.056 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.058 total time=   2.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.054 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.054 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.056 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.059 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.061 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.054 total time=   5.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.054 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.369 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.336 total time=   4.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.392 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.336 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.178 total time=   4.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.606 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.226 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.336 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.340 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.339 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.316 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.145 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.303 total time=   9.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.318 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.292 total time=   9.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.372 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.339 total time=   4.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.886 total time=  17.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.895 total time=  32.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.890 total time=  18.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.891 total time=  34.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.893 total time=  30.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.884 total time=  17.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.880 total time=  32.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.893 total time= 1.3min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.879 total time=  27.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.885 total time=  27.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.891 total time=  17.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.896 total time=  18.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.892 total time= 1.4min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.894 total time= 1.2min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.889 total time=  30.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.887 total time=  25.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.874 total time=  15.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.877 total time=  27.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.878 total time=  26.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.058 total time=   5.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.058 total time=   9.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.065 total time=   8.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.056 total time=   7.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.058 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.052 total time=   7.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.089 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.058 total time=   7.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.048 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.058 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.061 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.059 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.059 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.058 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.067 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.059 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.060 total time=   3.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.378 total time=  14.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.329 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.390 total time=  14.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.347 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.344 total time=  14.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.356 total time=   7.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.353 total time=  14.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.230 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.505 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.342 total time=  14.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.407 total time=   7.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.349 total time=   7.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.373 total time=   7.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.340 total time=  14.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.355 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.283 total time=  11.4s\n",
      "[02:58:13] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:59:40] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:03:20] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:05:14] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:07:08] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:10:48] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.588 total time=  52.3s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.619 total time=  37.3s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.402 total time=  23.4s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.658 total time= 1.2min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.728 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.623 total time= 1.4min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.399 total time=  15.9s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.623 total time=  37.2s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.713 total time= 3.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.623 total time= 1.0min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.623 total time=  37.1s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.418 total time=  26.1s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.399 total time=  16.0s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.697 total time= 1.3min\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.385 total time=  15.8s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.669 total time= 1.2min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.894 total time=  48.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.890 total time=  48.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.884 total time=  19.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.878 total time=  20.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.873 total time=   8.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.876 total time=  39.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.877 total time=  38.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.889 total time=  10.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.887 total time=  50.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.884 total time=  46.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.887 total time=  46.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.875 total time=  16.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.876 total time=  16.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.063 total time=   3.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.056 total time=   2.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.060 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.058 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.087 total time=   2.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.072 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.056 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.054 total time=   5.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.058 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.054 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.050 total time=   2.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.054 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.054 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.050 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.078 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.059 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.350 total time=   4.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.334 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.378 total time=   4.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.350 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.422 total time=   4.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.270 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.308 total time=   9.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.219 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.319 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.293 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.328 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.338 total time=   9.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.392 total time=   4.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.387 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.285 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.296 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.382 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.342 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.352 total time=  10.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.889 total time=  18.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.894 total time=  33.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.894 total time=  34.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.888 total time=  16.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.890 total time= 1.2min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.885 total time=  31.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.878 total time=  26.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.873 total time=  14.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.880 total time=  15.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.883 total time=  27.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.889 total time=  17.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.890 total time= 1.4min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.893 total time= 1.4min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.886 total time= 1.2min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.878 total time=  14.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.882 total time=  25.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.877 total time=  14.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.880 total time=  55.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.052 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.058 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.056 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.242 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.050 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.059 total time=   7.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.065 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.058 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.059 total time=   7.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.078 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.060 total time=   3.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.050 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.059 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.440 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.199 total time=  14.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.295 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.313 total time=  14.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.313 total time=   7.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.330 total time=   7.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.351 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.333 total time=  14.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.415 total time=   7.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.616 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.413 total time=  14.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.307 total time=   7.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.306 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.341 total time=  14.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.295 total time=   4.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.290 total time=  14.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.340 total time=   7.0s\n",
      "[02:58:07] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:00:04] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:01:03] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:02:03] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:04:36] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:05:39] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:07:00] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:08:54] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:10:49] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.588 total time=  52.4s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.398 total time=  16.3s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.622 total time=  37.3s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.392 total time=  16.1s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.686 total time= 1.2min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.398 total time=  16.2s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.687 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.396 total time=  16.1s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.601 total time=  36.5s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.422 total time=  16.1s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.380 total time=  34.8s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.387 total time=  15.9s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.725 total time= 1.3min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.714 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.386 total time=  25.9s\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.596 total time= 1.0min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.386 total time=  16.0s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.622 total time=  36.8s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.697 total time= 2.3min\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.739 total time= 1.3min\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.889 total time=  19.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.887 total time=  49.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.886 total time=  46.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.880 total time=  19.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.878 total time=  16.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.873 total time=   9.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.868 total time=  10.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.876 total time=  16.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.883 total time=  11.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.890 total time=  50.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.885 total time=  50.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.886 total time=  45.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.873 total time=  17.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.874 total time=  16.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.870 total time=   9.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.873 total time=  33.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.063 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.054 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.050 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.056 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.071 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.059 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.050 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.054 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.052 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.056 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.050 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.076 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.046 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.052 total time=   5.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.354 total time=   9.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.193 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.347 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.332 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.297 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.295 total time=   9.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.325 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.158 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.282 total time=   9.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.310 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.352 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.385 total time=   4.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.306 total time=   4.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.309 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.198 total time=   4.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.900 total time=  32.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.890 total time=  34.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.889 total time=  35.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.888 total time=  16.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.888 total time=  17.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.892 total time=  31.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.893 total time=  17.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.886 total time= 1.3min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.879 total time= 1.1min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.892 total time= 1.4min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.897 total time= 1.4min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.893 total time= 1.2min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.884 total time= 1.0min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.876 total time=  27.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.050 total time=  10.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.058 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.072 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.056 total time=   4.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.056 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.059 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.058 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.054 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.061 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.050 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.060 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.058 total time=   3.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.056 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.048 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.054 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.065 total time=   7.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.054 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.332 total time=   6.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.410 total time=   7.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.343 total time=  14.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.339 total time=   7.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.375 total time=   7.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.335 total time=   7.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.291 total time=   6.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.373 total time=   7.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.362 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.376 total time=  14.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.375 total time=  14.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.313 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.341 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.410 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.322 total time=  14.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.210 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.304 total time=  12.2s\n",
      "[02:58:05] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:00:00] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:03:38] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:07:20] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:08:18] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:09:18] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:10:41] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_evaluate = XGBClassifier()\n",
    "xgb_evaluate_gs = GridSearchCV(xgb_evaluate, params_xgb, scoring=\"f1\", n_jobs=-1, cv=3)\n",
    "xgb_evaluate_gs.fit(train_evaluate_x, train_evaluate_y)\n",
    "pred_evaluate_y_xgb = xgb_evaluate_gs.predict(test_evaluate_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "31273bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_evaluate_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d4d1cdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9642188961646398\n",
      "Kappa Score ->  0.8780814698474202\n",
      "ROC AUC Score ->  0.9240165032289787\n",
      "F1 Score ->  0.899803536345776\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3477\n",
      "           1       0.94      0.86      0.90       799\n",
      "\n",
      "    accuracy                           0.96      4276\n",
      "   macro avg       0.96      0.92      0.94      4276\n",
      "weighted avg       0.96      0.96      0.96      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_evaluate_y, pred_evaluate_y_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7de288e",
   "metadata": {},
   "source": [
    "### Create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe0629",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "86d38b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_x, create_y = split_train_x.to_numpy(), split_train_y['Create'].astype('long').to_numpy()#rus(split_train_x, split_train_y['Create'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a7186a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17104, 94)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c195a",
   "metadata": {},
   "source": [
    "#### BERT Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "811c2a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_x_bert = create_x[:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8670d486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /Users/ylii0447/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /Users/ylii0447/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/ylii0447/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /Users/ylii0447/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "using `logging_steps` to initialize `eval_steps` to 10\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 13683\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training model for column create\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='540' max='642' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [540/642 1:06:26 < 12:35, 0.13 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.527800</td>\n",
       "      <td>0.469140</td>\n",
       "      <td>0.449292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.416900</td>\n",
       "      <td>0.325915</td>\n",
       "      <td>0.772425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.311200</td>\n",
       "      <td>0.276034</td>\n",
       "      <td>0.815756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.276600</td>\n",
       "      <td>0.243401</td>\n",
       "      <td>0.853102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.229300</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.865772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.216700</td>\n",
       "      <td>0.180800</td>\n",
       "      <td>0.887674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.231300</td>\n",
       "      <td>0.150544</td>\n",
       "      <td>0.897398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>0.152131</td>\n",
       "      <td>0.913262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.167900</td>\n",
       "      <td>0.124396</td>\n",
       "      <td>0.926182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.170100</td>\n",
       "      <td>0.123569</td>\n",
       "      <td>0.931397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>0.119209</td>\n",
       "      <td>0.933421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.166300</td>\n",
       "      <td>0.153052</td>\n",
       "      <td>0.897378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.117494</td>\n",
       "      <td>0.926703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.115554</td>\n",
       "      <td>0.937555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.104100</td>\n",
       "      <td>0.112217</td>\n",
       "      <td>0.936905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.133900</td>\n",
       "      <td>0.107202</td>\n",
       "      <td>0.934829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.098402</td>\n",
       "      <td>0.939537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.095776</td>\n",
       "      <td>0.940818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.103369</td>\n",
       "      <td>0.939218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.120300</td>\n",
       "      <td>0.092132</td>\n",
       "      <td>0.946014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.134200</td>\n",
       "      <td>0.097245</td>\n",
       "      <td>0.942715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.099700</td>\n",
       "      <td>0.097834</td>\n",
       "      <td>0.946014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.103566</td>\n",
       "      <td>0.942307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>0.100112</td>\n",
       "      <td>0.937960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.103392</td>\n",
       "      <td>0.938659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.115537</td>\n",
       "      <td>0.941802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.095300</td>\n",
       "      <td>0.100916</td>\n",
       "      <td>0.947730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.108400</td>\n",
       "      <td>0.098574</td>\n",
       "      <td>0.938659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>0.092698</td>\n",
       "      <td>0.943961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>0.100204</td>\n",
       "      <td>0.943752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.101344</td>\n",
       "      <td>0.936038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.100236</td>\n",
       "      <td>0.938025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.103883</td>\n",
       "      <td>0.936826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.105400</td>\n",
       "      <td>0.110296</td>\n",
       "      <td>0.930081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.099900</td>\n",
       "      <td>0.092110</td>\n",
       "      <td>0.944345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.089500</td>\n",
       "      <td>0.100442</td>\n",
       "      <td>0.947400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.100069</td>\n",
       "      <td>0.950690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.092344</td>\n",
       "      <td>0.950477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>0.086435</td>\n",
       "      <td>0.950783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.106021</td>\n",
       "      <td>0.948125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.092114</td>\n",
       "      <td>0.949662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.090810</td>\n",
       "      <td>0.951539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.050500</td>\n",
       "      <td>0.110057</td>\n",
       "      <td>0.940608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>0.091930</td>\n",
       "      <td>0.955710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>0.102275</td>\n",
       "      <td>0.950503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.060200</td>\n",
       "      <td>0.106131</td>\n",
       "      <td>0.944314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.094833</td>\n",
       "      <td>0.953590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.107539</td>\n",
       "      <td>0.949640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.105544</td>\n",
       "      <td>0.952732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.109268</td>\n",
       "      <td>0.949913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.108526</td>\n",
       "      <td>0.949721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.093925</td>\n",
       "      <td>0.953249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.091707</td>\n",
       "      <td>0.953707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>0.099421</td>\n",
       "      <td>0.948394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-10\n",
      "Configuration saved in create/checkpoint-10/config.json\n",
      "Model weights saved in create/checkpoint-10/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-20\n",
      "Configuration saved in create/checkpoint-20/config.json\n",
      "Model weights saved in create/checkpoint-20/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-30\n",
      "Configuration saved in create/checkpoint-30/config.json\n",
      "Model weights saved in create/checkpoint-30/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-40\n",
      "Configuration saved in create/checkpoint-40/config.json\n",
      "Model weights saved in create/checkpoint-40/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-50\n",
      "Configuration saved in create/checkpoint-50/config.json\n",
      "Model weights saved in create/checkpoint-50/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-60\n",
      "Configuration saved in create/checkpoint-60/config.json\n",
      "Model weights saved in create/checkpoint-60/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-70\n",
      "Configuration saved in create/checkpoint-70/config.json\n",
      "Model weights saved in create/checkpoint-70/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-80\n",
      "Configuration saved in create/checkpoint-80/config.json\n",
      "Model weights saved in create/checkpoint-80/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-90\n",
      "Configuration saved in create/checkpoint-90/config.json\n",
      "Model weights saved in create/checkpoint-90/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-100\n",
      "Configuration saved in create/checkpoint-100/config.json\n",
      "Model weights saved in create/checkpoint-100/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-110\n",
      "Configuration saved in create/checkpoint-110/config.json\n",
      "Model weights saved in create/checkpoint-110/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-120\n",
      "Configuration saved in create/checkpoint-120/config.json\n",
      "Model weights saved in create/checkpoint-120/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-130\n",
      "Configuration saved in create/checkpoint-130/config.json\n",
      "Model weights saved in create/checkpoint-130/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-140\n",
      "Configuration saved in create/checkpoint-140/config.json\n",
      "Model weights saved in create/checkpoint-140/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-150\n",
      "Configuration saved in create/checkpoint-150/config.json\n",
      "Model weights saved in create/checkpoint-150/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-160\n",
      "Configuration saved in create/checkpoint-160/config.json\n",
      "Model weights saved in create/checkpoint-160/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-170\n",
      "Configuration saved in create/checkpoint-170/config.json\n",
      "Model weights saved in create/checkpoint-170/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-180\n",
      "Configuration saved in create/checkpoint-180/config.json\n",
      "Model weights saved in create/checkpoint-180/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-190\n",
      "Configuration saved in create/checkpoint-190/config.json\n",
      "Model weights saved in create/checkpoint-190/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-200\n",
      "Configuration saved in create/checkpoint-200/config.json\n",
      "Model weights saved in create/checkpoint-200/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-210\n",
      "Configuration saved in create/checkpoint-210/config.json\n",
      "Model weights saved in create/checkpoint-210/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-220\n",
      "Configuration saved in create/checkpoint-220/config.json\n",
      "Model weights saved in create/checkpoint-220/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-230\n",
      "Configuration saved in create/checkpoint-230/config.json\n",
      "Model weights saved in create/checkpoint-230/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-240\n",
      "Configuration saved in create/checkpoint-240/config.json\n",
      "Model weights saved in create/checkpoint-240/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-250\n",
      "Configuration saved in create/checkpoint-250/config.json\n",
      "Model weights saved in create/checkpoint-250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-260\n",
      "Configuration saved in create/checkpoint-260/config.json\n",
      "Model weights saved in create/checkpoint-260/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-270\n",
      "Configuration saved in create/checkpoint-270/config.json\n",
      "Model weights saved in create/checkpoint-270/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-280\n",
      "Configuration saved in create/checkpoint-280/config.json\n",
      "Model weights saved in create/checkpoint-280/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-290\n",
      "Configuration saved in create/checkpoint-290/config.json\n",
      "Model weights saved in create/checkpoint-290/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-300\n",
      "Configuration saved in create/checkpoint-300/config.json\n",
      "Model weights saved in create/checkpoint-300/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-310\n",
      "Configuration saved in create/checkpoint-310/config.json\n",
      "Model weights saved in create/checkpoint-310/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-320\n",
      "Configuration saved in create/checkpoint-320/config.json\n",
      "Model weights saved in create/checkpoint-320/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-330\n",
      "Configuration saved in create/checkpoint-330/config.json\n",
      "Model weights saved in create/checkpoint-330/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-340\n",
      "Configuration saved in create/checkpoint-340/config.json\n",
      "Model weights saved in create/checkpoint-340/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to create/checkpoint-350\n",
      "Configuration saved in create/checkpoint-350/config.json\n",
      "Model weights saved in create/checkpoint-350/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-360\n",
      "Configuration saved in create/checkpoint-360/config.json\n",
      "Model weights saved in create/checkpoint-360/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-370\n",
      "Configuration saved in create/checkpoint-370/config.json\n",
      "Model weights saved in create/checkpoint-370/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-380\n",
      "Configuration saved in create/checkpoint-380/config.json\n",
      "Model weights saved in create/checkpoint-380/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-390\n",
      "Configuration saved in create/checkpoint-390/config.json\n",
      "Model weights saved in create/checkpoint-390/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-400\n",
      "Configuration saved in create/checkpoint-400/config.json\n",
      "Model weights saved in create/checkpoint-400/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-410\n",
      "Configuration saved in create/checkpoint-410/config.json\n",
      "Model weights saved in create/checkpoint-410/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-420\n",
      "Configuration saved in create/checkpoint-420/config.json\n",
      "Model weights saved in create/checkpoint-420/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-430\n",
      "Configuration saved in create/checkpoint-430/config.json\n",
      "Model weights saved in create/checkpoint-430/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-440\n",
      "Configuration saved in create/checkpoint-440/config.json\n",
      "Model weights saved in create/checkpoint-440/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-450\n",
      "Configuration saved in create/checkpoint-450/config.json\n",
      "Model weights saved in create/checkpoint-450/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-460\n",
      "Configuration saved in create/checkpoint-460/config.json\n",
      "Model weights saved in create/checkpoint-460/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-470\n",
      "Configuration saved in create/checkpoint-470/config.json\n",
      "Model weights saved in create/checkpoint-470/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-480\n",
      "Configuration saved in create/checkpoint-480/config.json\n",
      "Model weights saved in create/checkpoint-480/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-490\n",
      "Configuration saved in create/checkpoint-490/config.json\n",
      "Model weights saved in create/checkpoint-490/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-500\n",
      "Configuration saved in create/checkpoint-500/config.json\n",
      "Model weights saved in create/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-510\n",
      "Configuration saved in create/checkpoint-510/config.json\n",
      "Model weights saved in create/checkpoint-510/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-520\n",
      "Configuration saved in create/checkpoint-520/config.json\n",
      "Model weights saved in create/checkpoint-520/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-530\n",
      "Configuration saved in create/checkpoint-530/config.json\n",
      "Model weights saved in create/checkpoint-530/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to create/checkpoint-540\n",
      "Configuration saved in create/checkpoint-540/config.json\n",
      "Model weights saved in create/checkpoint-540/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from create/checkpoint-440 (score: 0.9557104662301037).\n",
      "Saving model checkpoint to create\n",
      "Configuration saved in create/config.json\n",
      "Model weights saved in create/pytorch_model.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 4276\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed. Started testing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:52]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9623479887745556\n",
      "Kappa Score ->  0.8655021212980828\n",
      "ROC AUC Score ->  0.9237178744094423\n",
      "F1 Score ->  0.8881167477414871\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      3537\n",
      "           1       0.91      0.86      0.89       739\n",
      "\n",
      "    accuracy                           0.96      4276\n",
      "   macro avg       0.94      0.92      0.93      4276\n",
      "weighted avg       0.96      0.96      0.96      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if RUN_DL:\n",
    "    create_bert = createBERT('create', create_x_bert, create_y, split_test_x['Learning_outcome'].tolist(), split_test_y['Create'].astype('long').to_numpy(), 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d4da0b",
   "metadata": {},
   "source": [
    "#### Traditional ML Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "15ece630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Unigram...\n",
      "Getting Bigram...\n",
      "Getting Tfidf...\n",
      "Getting ARI...\n",
      "Combining...\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.367 total time=  22.3s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.393 total time=  15.7s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.596 total time=  37.2s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.366 total time=  23.3s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.710 total time= 2.1min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.382 total time=  34.0s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.415 total time=  34.7s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.599 total time= 1.4min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.397 total time=  35.4s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.419 total time=  16.2s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.687 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.397 total time=  15.7s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.669 total time= 1.3min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.596 total time= 1.0min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.596 total time=  37.1s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.399 total time=  26.2s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.386 total time=  16.0s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.725 total time= 1.3min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.714 total time= 1.4min\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.888 total time=  49.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.883 total time=  49.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.886 total time=  46.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.873 total time=  17.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.866 total time=  17.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.869 total time=   8.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.873 total time=  39.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.889 total time=  50.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.890 total time=  46.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.883 total time=  18.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.868 total time=   9.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.876 total time=  10.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.877 total time=  16.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.874 total time=   9.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.058 total time=   3.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.072 total time=   3.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.054 total time=   3.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.054 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.056 total time=   2.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.058 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.058 total time=   2.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.059 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.067 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.050 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.058 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.050 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.059 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.052 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.058 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.060 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.061 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.050 total time=   2.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.059 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.387 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.329 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.311 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.314 total time=   8.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.328 total time=   9.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.380 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.363 total time=   3.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.353 total time=   4.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.387 total time=   4.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.344 total time=   4.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.332 total time=   8.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.383 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.318 total time=   9.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.344 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.363 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.339 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.898 total time=  15.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.890 total time=  19.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.898 total time= 1.4min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.889 total time=  32.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.887 total time=  31.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.889 total time=  15.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.883 total time=  16.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.873 total time=  14.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.884 total time=  27.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.882 total time=  26.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.864 total time=  14.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.893 total time=  19.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.895 total time=  34.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.892 total time=  16.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.889 total time= 1.3min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.890 total time= 1.2min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.889 total time= 1.2min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.886 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.052 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.050 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.054 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.059 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.054 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.054 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.058 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.058 total time=   7.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.061 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.050 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.063 total time=   3.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.063 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.048 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.058 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.058 total time=   7.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.050 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.063 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.050 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.291 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.337 total time=  14.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.300 total time=   7.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.408 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.338 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.333 total time=  14.6s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.329 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.337 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.356 total time=  14.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.323 total time=   7.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.341 total time=   7.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.346 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.422 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.354 total time=  14.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.138 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.329 total time=  14.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.247 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.334 total time=  13.9s\n",
      "[02:58:03] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:59:13] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:01:08] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:03:17] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:05:10] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:07:06] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:10:44] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated feature shape is (17104, 3094)\n",
      "Generated test feature is (4276, 3094)\n"
     ]
    }
   ],
   "source": [
    "combined_create_x, column_names_create, test_create_x = generateX(create_x, split_test_x.to_numpy(), 0, 1, 94)\n",
    "train_create_x = combined_create_x\n",
    "train_create_y = create_y\n",
    "test_create_y = split_test_y['Create'].astype('long').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ab0303a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_create += data.columns[8:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a48dfa",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b0324562",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_create = GaussianNB()\n",
    "gnb_create_gs = GridSearchCV(gnb_create, params_nb, scoring=\"f1\", n_jobs=-1, cv=3)\n",
    "gnb_create_gs.fit(train_create_x, train_create_y)\n",
    "pred_create_y_gnb = gnb_create_gs.predict(test_create_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "15349cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 1e-08}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_create_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d9e43bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.6760991580916744\n",
      "Kappa Score ->  0.29991762985827797\n",
      "ROC AUC Score ->  0.7426614758422752\n",
      "F1 Score ->  0.47398404861374865\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.64      0.77      3537\n",
      "           1       0.33      0.84      0.47       739\n",
      "\n",
      "    accuracy                           0.68      4276\n",
      "   macro avg       0.64      0.74      0.62      4276\n",
      "weighted avg       0.84      0.68      0.72      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_create_y, pred_create_y_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f9324",
   "metadata": {},
   "source": [
    "##### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f52048ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.375 total time=  22.0s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.418 total time=  16.0s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.595 total time=  37.1s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.375 total time=  22.9s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.687 total time= 2.1min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.397 total time=  34.5s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.595 total time= 1.4min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.622 total time=  37.3s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.417 total time=  35.0s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.669 total time= 1.3min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.738 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.739 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.596 total time=  36.9s\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.596 total time=  36.8s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.715 total time= 2.6min\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.888 total time=  51.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.887 total time=  11.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.886 total time=  20.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.884 total time=  11.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.881 total time=  44.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.872 total time=  38.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.879 total time=  38.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.889 total time=  21.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.887 total time=  12.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.882 total time=  11.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.881 total time=  11.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.882 total time=  11.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.885 total time=  20.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.885 total time=   9.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.880 total time=  46.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.868 total time=  37.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.054 total time=   6.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.058 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.065 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.052 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.050 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.135 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.059 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.058 total time=   2.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.054 total time=   5.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.048 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.059 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.058 total time=   5.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.054 total time=   5.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.058 total time=   5.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.050 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.061 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.265 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.368 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.332 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.309 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.375 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.325 total time=   9.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.350 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.341 total time=   9.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.346 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.390 total time=   9.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.335 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.178 total time=   3.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.299 total time=   8.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.356 total time=   4.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.326 total time=   4.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.311 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.371 total time=   4.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.268 total time=   4.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.897 total time= 1.4min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.892 total time= 1.4min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.888 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.882 total time=  17.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.884 total time=  26.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.884 total time=  14.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.878 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.893 total time=  34.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.897 total time=  34.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.888 total time=  16.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.892 total time= 1.2min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.894 total time= 1.2min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.882 total time= 1.1min\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.072 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.056 total time=   4.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.054 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.054 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.052 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.059 total time=   7.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.050 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.054 total time=   7.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.061 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.065 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.052 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.058 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.059 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.309 total time=   4.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.322 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.332 total time=  14.4s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.292 total time=   6.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.352 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.340 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.306 total time=  14.5s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.326 total time=   7.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.344 total time=   7.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.309 total time=  15.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.388 total time=   6.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.357 total time=   7.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.345 total time=   7.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.320 total time=   7.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.341 total time=   7.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.371 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.342 total time=   6.6s\n",
      "[02:58:02] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:59:07] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:01:40] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:03:02] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:05:37] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:06:58] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:08:52] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:10:53] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.592 total time=  53.1s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.596 total time=  37.1s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.697 total time= 1.8min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.417 total time=  16.2s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.739 total time= 1.5min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.416 total time=  16.1s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.596 total time=  36.9s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.596 total time=  37.0s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.717 total time= 3.0min\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.687 total time= 1.5min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.422 total time=  16.2s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.398 total time=  15.9s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.601 total time=  36.9s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.687 total time= 2.6min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.714 total time= 1.2min\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.887 total time=   8.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.884 total time=  12.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.887 total time=  12.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.883 total time=  11.7s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.884 total time=  48.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.884 total time=  45.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.881 total time=  40.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.875 total time=  17.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.888 total time=  49.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.890 total time=  49.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.883 total time=  20.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.885 total time=  19.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.880 total time=  17.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.867 total time=   9.7s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.872 total time=   9.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.877 total time=  33.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.054 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.063 total time=   2.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.054 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.059 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.054 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.050 total time=   2.9s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.052 total time=   5.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.063 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.058 total time=   5.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.054 total time=   5.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.058 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.063 total time=   2.4s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.054 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.060 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.389 total time=   4.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.357 total time=   9.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.359 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.292 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.342 total time=   9.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.405 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.369 total time=   4.9s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.405 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.336 total time=   4.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.353 total time=   3.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.368 total time=   9.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.380 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.347 total time=   9.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.373 total time=   3.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.267 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.297 total time=   8.9s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.302 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.895 total time=  34.3s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.894 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.891 total time= 1.2min\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.892 total time=  32.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.881 total time=  26.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.874 total time=  15.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.884 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.894 total time=  34.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.897 total time= 1.4min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.890 total time=  30.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.886 total time=  31.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.886 total time=  16.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.877 total time=  15.4s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.876 total time=  15.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.878 total time= 1.1min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.885 total time=  56.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.058 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.060 total time=   3.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.058 total time=   3.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.058 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.063 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.059 total time=   7.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.058 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.052 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.054 total time=   7.7s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.058 total time=   7.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.054 total time=   7.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.059 total time=   7.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.300 total time=   4.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.330 total time=  14.1s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.365 total time=   6.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.546 total time=   7.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.408 total time=   7.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.309 total time=  14.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.356 total time=  14.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.308 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.315 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.315 total time=  14.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.322 total time=  14.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.377 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.486 total time=   4.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.373 total time=  14.2s\n",
      "[02:58:04] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:00:04] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:03:43] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:04:45] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:05:47] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:08:20] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:09:25] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:10:51] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.592 total time=  52.7s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.386 total time=  16.2s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.596 total time=  37.1s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.382 total time=  15.9s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.710 total time= 1.2min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.708 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.595 total time= 1.4min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.596 total time=  37.2s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.737 total time= 3.5min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.422 total time=  26.1s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.601 total time= 1.0min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.596 total time=  36.7s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.726 total time= 2.3min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.698 total time= 1.2min\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.898 total time=  19.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.887 total time=  21.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.892 total time=  22.3s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.879 total time=  10.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=250;, score=0.880 total time=  47.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.884 total time=  44.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.875 total time=  39.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.892 total time=  20.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.885 total time=  10.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.885 total time=  12.8s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.886 total time=  22.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.886 total time=  19.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.884 total time=  11.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.884 total time=  47.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.878 total time=  39.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.872 total time=  16.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.061 total time=   3.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.054 total time=   2.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.061 total time=   5.8s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.056 total time=   2.5s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.054 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.058 total time=   3.1s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.058 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.054 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=250;, score=0.052 total time=   5.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.050 total time=   5.3s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.058 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.201 total time=   2.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.054 total time=   5.4s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.059 total time=   2.4s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.061 total time=   3.0s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.056 total time=   2.3s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.054 total time=   5.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.050 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.067 total time=   3.0s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.504 total time=   3.1s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.341 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.336 total time=   4.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.367 total time=   4.6s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.339 total time=   4.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.330 total time=   4.6s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.275 total time=   4.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.312 total time=   4.7s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.342 total time=   9.1s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.320 total time=   3.2s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.343 total time=   4.5s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.281 total time=   4.8s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.299 total time=   4.5s\n",
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250;, score=0.318 total time=   9.2s\n",
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.339 total time=   4.6s\n",
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.272 total time=   3.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.893 total time=  32.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.896 total time=  18.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.892 total time=  17.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.898 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.892 total time= 1.3min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.885 total time= 1.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.878 total time=  28.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.892 total time=  35.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.896 total time=  33.1s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.889 total time=  18.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.890 total time= 1.4min\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.891 total time=  16.7s\n",
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.892 total time=  30.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.872 total time=  15.5s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.873 total time=  26.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.886 total time=  26.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.874 total time=  14.3s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.067 total time=   4.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.058 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.058 total time=   5.6s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250;, score=0.059 total time=   9.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250;, score=0.050 total time=   9.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.061 total time=   7.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.060 total time=   2.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.050 total time=   3.9s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.048 total time=   4.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.056 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.056 total time=   3.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.050 total time=   4.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.065 total time=   2.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.061 total time=   2.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=250;, score=0.060 total time=   7.6s\n",
      "[CV 1/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.050 total time=   3.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.060 total time=   3.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.069 total time=   3.8s\n",
      "[CV 3/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.050 total time=   2.8s\n",
      "[CV 2/3] END bootstrap=False, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.058 total time=   3.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.401 total time=   6.4s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.425 total time=   7.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.207 total time=   6.9s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.323 total time=   6.8s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.301 total time=  14.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.410 total time=   4.2s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=250;, score=0.344 total time=  14.5s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.161 total time=   4.0s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250;, score=0.327 total time=  14.7s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.368 total time=   7.0s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.257 total time=   6.9s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.404 total time=   4.2s\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.329 total time=   4.2s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250;, score=0.305 total time=  14.3s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.367 total time=   7.1s\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.324 total time=   7.0s\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.367 total time=   6.8s\n",
      "[02:58:10] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:59:38] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:01:30] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:03:26] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:07:11] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:10:52] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "svm_create = SVC()\n",
    "svm_create_gs = GridSearchCV(svm_create, params_svm, scoring=\"f1\", n_jobs=-1, cv=3)\n",
    "svm_create_gs.fit(train_create_x, train_create_y)\n",
    "pred_create_y_svm = svm_create_gs.predict(test_create_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6c0c1970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_create_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "11130ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9424695977549111\n",
      "Kappa Score ->  0.7907186897535529\n",
      "ROC AUC Score ->  0.8801236340514713\n",
      "F1 Score ->  0.825035561877667\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      3537\n",
      "           1       0.87      0.78      0.83       739\n",
      "\n",
      "    accuracy                           0.94      4276\n",
      "   macro avg       0.91      0.88      0.90      4276\n",
      "weighted avg       0.94      0.94      0.94      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_create_y, pred_create_y_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a215222",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "43944ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr_create = LogisticRegression()\n",
    "lr_create_gs = GridSearchCV(lr_create, params_lr, scoring=\"f1\", n_jobs=-1, cv=3, verbose=3)\n",
    "lr_create_gs.fit(train_create_x, train_create_y)\n",
    "pred_create_y_lr = lr_create_gs.predict(test_create_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "40a67215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_create_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5e3e92c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9022450888681011\n",
      "Kappa Score ->  0.6047910599899615\n",
      "ROC AUC Score ->  0.7616092473801983\n",
      "F1 Score ->  0.6590538336052203\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      3537\n",
      "           1       0.83      0.55      0.66       739\n",
      "\n",
      "    accuracy                           0.90      4276\n",
      "   macro avg       0.87      0.76      0.80      4276\n",
      "weighted avg       0.90      0.90      0.89      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_create_y, pred_create_y_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae0d2c",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "13e09fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_create = RandomForestClassifier()\n",
    "rf_create_gs = GridSearchCV(rf_create, params_rf, scoring=\"f1\", n_jobs=-1, cv=3)\n",
    "rf_create_gs.fit(train_create_x, train_create_y)\n",
    "pred_create_y_rf = rf_create_gs.predict(test_create_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5b72a239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 250}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_create_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b3a4fb56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9434050514499532\n",
      "Kappa Score ->  0.7920378080920989\n",
      "ROC AUC Score ->  0.8769424942508025\n",
      "F1 Score ->  0.8256484149855909\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      3537\n",
      "           1       0.88      0.78      0.83       739\n",
      "\n",
      "    accuracy                           0.94      4276\n",
      "   macro avg       0.92      0.88      0.90      4276\n",
      "weighted avg       0.94      0.94      0.94      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_create_y, pred_create_y_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea953f3",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e6c5b681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:19:22] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_create = XGBClassifier()\n",
    "xgb_create_gs = GridSearchCV(xgb_create, params_xgb, scoring=\"f1\", n_jobs=-1, cv=3)\n",
    "xgb_create_gs.fit(train_create_x, train_create_y)\n",
    "pred_create_y_xgb = xgb_create_gs.predict(test_create_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "466258dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.5, 'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 50}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_create_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9c7872b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.9441066417212348\n",
      "Kappa Score ->  0.7961063316999984\n",
      "ROC AUC Score ->  0.881648400458635\n",
      "F1 Score ->  0.8294075660242684\n",
      "Classification report -> \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      3537\n",
      "           1       0.88      0.79      0.83       739\n",
      "\n",
      "    accuracy                           0.94      4276\n",
      "   macro avg       0.92      0.88      0.90      4276\n",
      "weighted avg       0.94      0.94      0.94      4276\n",
      "\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.360 total time=  16.6s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.496 total time=  36.9s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.539 total time=  37.1s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.592 total time= 2.2min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.656 total time= 1.5min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.498 total time= 1.4min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.390 total time=  37.5s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.629 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.655 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.631 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.411 total time=  17.2s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.540 total time=  37.5s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.393 total time=  27.4s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.631 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.656 total time= 1.4min\n",
      "[05:03:58] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:36] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:07:36] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:08:56] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:10:47] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:12:43] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:14:37] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.338 total time=  24.7s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.408 total time=  16.6s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.498 total time=  37.1s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.338 total time=  25.6s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.617 total time= 2.2min\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.631 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.410 total time=  16.9s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  36.6s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.392 total time=  17.1s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.540 total time=  36.9s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.632 total time= 3.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.503 total time= 1.0min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.393 total time=  17.1s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  37.5s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.631 total time= 2.5min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.392 total time=  17.2s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.631 total time= 1.3min\n",
      "[05:03:47] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:05:46] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:46] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:08:41] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:11:13] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:12:33] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:15:06] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.362 total time=  24.7s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.388 total time=  16.8s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.496 total time=  36.8s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.367 total time=  25.8s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.592 total time= 2.2min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.657 total time= 1.5min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.392 total time=  17.0s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.503 total time=  36.5s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.504 total time=  36.6s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.657 total time= 3.5min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.656 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.504 total time=  37.2s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.538 total time=  37.2s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.411 total time=  16.7s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.641 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.364 total time=  16.9s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.631 total time= 1.3min\n",
      "[05:03:55] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:05:22] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:03] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:12:45] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:16:23] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.347 total time=  25.4s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.535 total time=  36.9s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.499 total time=  36.9s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.590 total time= 2.2min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.641 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.364 total time=  17.0s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.538 total time=  36.5s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.411 total time=  16.9s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.503 total time=  36.5s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.657 total time= 3.5min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.393 total time=  27.8s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.538 total time= 1.0min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.392 total time=  17.2s\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.504 total time=  37.1s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.364 total time=  16.8s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.656 total time= 1.5min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.641 total time= 1.4min\n",
      "[05:03:42] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:04:48] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:07:23] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:08:43] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:10:40] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:12:40] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:14:33] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:16:26] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.460 total time=  54.6s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.534 total time=  36.8s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.347 total time=  26.0s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.619 total time= 1.5min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.651 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.533 total time= 1.4min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.364 total time=  17.1s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.499 total time=  36.6s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.631 total time= 3.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.409 total time=  27.2s\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.503 total time= 1.0min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.410 total time=  17.0s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.499 total time=  37.1s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.631 total time= 2.5min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.641 total time= 1.2min\n",
      "[05:03:51] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:05:15] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:07:07] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:01] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:10:53] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:12:48] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:16:28] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.499 total time=  55.4s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.393 total time=  17.2s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.499 total time=  37.5s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.388 total time=  16.9s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.619 total time= 1.5min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.391 total time=  17.5s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.406 total time=  35.6s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.494 total time= 1.4min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.538 total time=  37.2s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.406 total time=  36.4s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.392 total time=  17.1s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.629 total time= 1.5min\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.410 total time=  16.6s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.631 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.538 total time= 1.0min\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.538 total time=  37.4s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.499 total time=  37.0s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.391 total time=  17.0s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.631 total time= 1.5min\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.410 total time=  16.9s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.656 total time= 1.3min\n",
      "[05:03:46] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:05:46] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:25] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:10:24] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:11:25] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:13:55] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:14:56] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:16:18] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.462 total time=  55.4s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.504 total time=  36.6s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.617 total time= 2.2min\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.631 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.493 total time= 1.4min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.499 total time=  36.8s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.364 total time=  16.9s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.655 total time= 1.5min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.639 total time= 1.5min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.641 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.503 total time=  37.7s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.409 total time=  27.3s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.641 total time= 2.5min\n",
      "[05:03:43] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:04:44] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:07:18] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:08:38] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:11:10] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:12:27] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:15:01] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:16:21] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.460 total time=  55.2s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.410 total time=  17.0s\n",
      "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.539 total time=  36.9s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.408 total time=  16.7s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.632 total time= 1.5min\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.364 total time=  17.7s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.641 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.504 total time=  36.5s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  37.1s\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.631 total time= 3.5min\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.641 total time= 1.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.01;, score=0.363 total time=  17.2s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  37.3s\n",
      "[CV 1/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.366 total time=  28.1s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.0001;, score=0.656 total time= 2.5min\n",
      "[05:03:45] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:05:42] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:22] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:13:02] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:14:02] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:15:04] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:16:30] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time=  55.3s\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=saga, tol=0.0001;, score=0.497 total time=  36.9s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.590 total time= 2.2min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.409 total time=  17.2s\n",
      "[CV 1/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.359 total time=  36.3s\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.391 total time=  36.7s\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.533 total time= 1.4min\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.01;, score=0.359 total time=  37.0s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.410 total time=  16.7s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.639 total time= 1.5min\n",
      "[CV 1/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.364 total time=  16.9s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.01;, score=0.392 total time=  16.8s\n",
      "[CV 2/3] END C=1, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.656 total time= 1.5min\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.0001;, score=0.498 total time= 1.0min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.503 total time=  36.9s\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.656 total time= 2.5min\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.001;, score=0.640 total time= 1.3min\n",
      "[05:03:44] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:04:51] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:06:44] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:07:47] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:10:16] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:11:18] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:12:38] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:14:29] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:16:31] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/3] END C=0.1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.461 total time=  55.1s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.364 total time=  17.3s\n",
      "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=saga, tol=0.0001;, score=0.504 total time=  37.0s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.01;, score=0.361 total time=  16.9s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.001;, score=0.651 total time= 1.5min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=saga, tol=0.0001;, score=0.631 total time= 1.5min\n",
      "[CV 3/3] END C=1, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.498 total time= 1.4min\n",
      "[CV 2/3] END C=1, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.539 total time=  36.6s\n",
      "[CV 3/3] END C=1, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.632 total time= 3.5min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.01;, score=0.364 total time=  27.5s\n",
      "[CV 3/3] END C=10, max_iter=200, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time= 1.0min\n",
      "[CV 1/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.01;, score=0.364 total time=  17.0s\n",
      "[CV 2/3] END C=10, max_iter=200, penalty=none, solver=saga, tol=0.001;, score=0.539 total time=  37.0s\n",
      "[CV 3/3] END C=10, max_iter=500, penalty=l1, solver=saga, tol=0.001;, score=0.641 total time= 2.5min\n",
      "[CV 2/3] END C=10, max_iter=500, penalty=none, solver=saga, tol=0.0001;, score=0.656 total time= 1.3min\n",
      "[05:03:51] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:05:20] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:07:14] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:09:06] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:12:51] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:16:33] WARNING: /private/var/folders/3k/2jqk91gd5bq3qwryjtcyt0z0f8_6y9/T/pip-install-gi89lwv1/xgboost_fc3285fae86f44df8a22d54d5f322c53/build/temp.macosx-11.0-arm64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "performancePrinter(test_create_y, pred_create_y_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228381b7",
   "metadata": {},
   "source": [
    "### Plot Visualised Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "73d62a5c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "\n",
    "axs[0, 0].set_title('Feature Importance: Remember')\n",
    "axs[0, 0].barh(range(20), svm_importance_remember[list(reversed(svm_sorted_indices_remember[:20]))], align='center')\n",
    "axs[0, 0].set_yticks(range(20), df_svm_remember.columns[list(reversed(svm_sorted_indices_remember[:20]))], fontsize=13)\n",
    "axs[0, 0].set_xlabel('Coefficient')\n",
    "\n",
    "axs[0, 1].set_title('Feature Importance: Understand')\n",
    "axs[0, 1].barh(range(20), rf_importance_understand[list(reversed(rf_sorted_indices_understand[:20]))], align='center')\n",
    "axs[0, 1].set_yticks(range(20), df_rf_understand.columns[list(reversed(rf_sorted_indices_understand[:20]))], fontsize=13)\n",
    "axs[0, 1].set_xlabel('Gini Impurity')\n",
    "\n",
    "axs[0, 2].set_title('Feature Importance: Apply')\n",
    "axs[0, 2].barh(range(20), rf_importance_apply[list(reversed(rf_sorted_indices_apply[:20]))], align='center')\n",
    "axs[0, 2].set_yticks(range(20), df_rf_apply.columns[list(reversed(rf_sorted_indices_apply[:20]))], fontsize=13)\n",
    "axs[0, 2].set_xlabel('Gini Impurity')\n",
    "\n",
    "axs[1, 0].set_title('Feature Importance: Analyze')\n",
    "axs[1, 0].barh(range(20), svm_importance_analyze[list(reversed(svm_sorted_indices_analyze[:20]))], align='center')\n",
    "axs[1, 0].set_yticks(range(20), df_svm_analyze.columns[list(reversed(svm_sorted_indices_analyze[:20]))], fontsize=13)\n",
    "axs[1, 0].set_xlabel('Coefficient')\n",
    "\n",
    "axs[1, 1].set_title('Feature Importance: Evaluate')\n",
    "axs[1, 1].barh(range(20), xgb_importance_evaluate[list(reversed(xgb_sorted_indices_evaluate[:20]))], align='center')\n",
    "axs[1, 1].set_yticks(range(20), df_xgb_evaluate.columns[list(reversed(xgb_sorted_indices_evaluate[:20]))], fontsize=13)\n",
    "axs[1, 1].set_xlabel('Gini Impurity')\n",
    "\n",
    "axs[1, 2].set_title('Feature Importance: Create')\n",
    "axs[1, 2].barh(range(20), xgb_importance_create[list(reversed(xgb_sorted_indices_create[:20]))], align='center')\n",
    "axs[1, 2].set_yticks(range(20), df_xgb_create.columns[list(reversed(xgb_sorted_indices_create[:20]))], fontsize=13)\n",
    "axs[1, 2].set_xlabel('Gini Impurity')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('feature_importance.eps', format='eps', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5245e356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "\n",
    "axs[0, 0].set_title('XGB Feature Importance: Remember')\n",
    "axs[0, 0].barh(range(20), xgb_importance_remember[list(reversed(xgb_sorted_indices_remember[:20]))], align='center')\n",
    "axs[0, 0].set_yticks(range(20), df_xgb_remember.columns[list(reversed(xgb_sorted_indices_remember[:20]))], fontsize=13)\n",
    "axs[0, 0].set_xlabel('Gini Impurity')\n",
    "\n",
    "axs[0, 1].set_title('XGB Feature Importance: Understand')\n",
    "axs[0, 1].barh(range(20), xgb_importance_understand[list(reversed(xgb_sorted_indices_understand[:20]))], align='center')\n",
    "axs[0, 1].set_yticks(range(20), df_xgb_understand.columns[list(reversed(xgb_sorted_indices_understand[:20]))], fontsize=13)\n",
    "axs[0, 1].set_xlabel('Gini Impurity')\n",
    "\n",
    "axs[0, 2].set_title('XGB Feature Importance: Apply')\n",
    "axs[0, 2].barh(range(20), xgb_importance_apply[list(reversed(xgb_sorted_indices_apply[:20]))], align='center')\n",
    "axs[0, 2].set_yticks(range(20), df_xgb_apply.columns[list(reversed(xgb_sorted_indices_apply[:20]))], fontsize=13)\n",
    "axs[0, 2].set_xlabel('Gini Impurity')\n",
    "\n",
    "axs[1, 0].set_title('XGB Feature Importance: Analyze')\n",
    "axs[1, 0].barh(range(20), xgb_importance_analyze[list(reversed(xgb_sorted_indices_analyze[:20]))], align='center')\n",
    "axs[1, 0].set_yticks(range(20), df_xgb_analyze.columns[list(reversed(xgb_sorted_indices_analyze[:20]))], fontsize=13)\n",
    "axs[1, 0].set_xlabel('Gini Impurity')\n",
    "\n",
    "axs[1, 1].set_title('XGB Feature Importance: Evaluate')\n",
    "axs[1, 1].barh(range(20), xgb_importance_evaluate[list(reversed(xgb_sorted_indices_evaluate[:20]))], align='center')\n",
    "axs[1, 1].set_yticks(range(20), df_xgb_evaluate.columns[list(reversed(xgb_sorted_indices_evaluate[:20]))], fontsize=13)\n",
    "axs[1, 1].set_xlabel('Gini Impurity')\n",
    "\n",
    "axs[1, 2].set_title('XGB Feature Importance: Create')\n",
    "axs[1, 2].barh(range(20), xgb_importance_create[list(reversed(xgb_sorted_indices_create[:20]))], align='center')\n",
    "axs[1, 2].set_yticks(range(20), df_xgb_create.columns[list(reversed(xgb_sorted_indices_create[:20]))], fontsize=13)\n",
    "axs[1, 2].set_xlabel('Gini Impurity')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('xgb_combined.eps', format='eps', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7c899523",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_rf_remember.columns[list(reversed(rf_sorted_indices_remember[:20]))]\n",
    "b = df_rf_understand.columns[list(reversed(rf_sorted_indices_understand[:20]))]\n",
    "c = df_rf_apply.columns[list(reversed(rf_sorted_indices_apply[:20]))]\n",
    "d = df_rf_analyze.columns[list(reversed(rf_sorted_indices_analyze[:20]))]\n",
    "e = df_rf_evaluate.columns[list(reversed(rf_sorted_indices_evaluate[:20]))]\n",
    "f = df_rf_create.columns[list(reversed(rf_sorted_indices_create[:20]))]\n",
    "total = list(a) + list(b) + list(c) + list(d) + list(e) + list(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "04379e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sixltr', 'uni_evaluate', 'ari', 'Dic', 'tfidf_evaluate',\n",
       "       'uni_understand', 'work', 'uni_apply', 'tfidf_apply', 'Authentic',\n",
       "       'tfidf_analyse', 'uni_demonstrate', 'tfidf_demonstrate', 'uni_analyse',\n",
       "       'cogproc', 'insight', 'tfidf_recognise', 'uni_recognise',\n",
       "       'tfidf_identify', 'uni_identify'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "47cce54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8d6af62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('insight', 6),\n",
       " ('work', 5),\n",
       " ('tfidf_apply', 5),\n",
       " ('uni_demonstrate', 5),\n",
       " ('tfidf_demonstrate', 5),\n",
       " ('uni_apply', 4),\n",
       " ('Authentic', 4),\n",
       " ('cogproc', 4),\n",
       " ('ari', 3),\n",
       " ('Dic', 3)]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FreqDist(total).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f5b8964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_xgb_remember.columns[list(reversed(xgb_sorted_indices_remember[:20]))]\n",
    "b = df_xgb_understand.columns[list(reversed(xgb_sorted_indices_understand[:20]))]\n",
    "c = df_xgb_apply.columns[list(reversed(xgb_sorted_indices_apply[:20]))]\n",
    "d = df_xgb_analyze.columns[list(reversed(xgb_sorted_indices_analyze[:20]))]\n",
    "e = df_xgb_evaluate.columns[list(reversed(xgb_sorted_indices_evaluate[:20]))]\n",
    "f = df_xgb_create.columns[list(reversed(xgb_sorted_indices_create[:20]))]\n",
    "total = list(a) + list(b) + list(c) + list(d) + list(e) + list(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8660851a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('uni_apply', 4),\n",
       " ('uni_demonstrate', 4),\n",
       " ('tfidf_demonstrate', 4),\n",
       " ('uni_analyse', 3),\n",
       " ('tfidf_apply', 3),\n",
       " ('tfidf_evaluate', 2),\n",
       " ('uni_communicate', 2),\n",
       " ('tfidf_analyse', 2),\n",
       " ('tfidf_identify', 2),\n",
       " ('uni_evaluate', 2)]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FreqDist(total).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ab76ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ab208e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
