{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3fe3735",
   "metadata": {},
   "source": [
    "Required packages:\\\n",
    "pandas==1.4.0\\\n",
    "numpy==1.21.5\\\n",
    "scikit-learn==1.0.2\\\n",
    "tensorflow==2.7.0\\\n",
    "torch==1.10.2\\\n",
    "transformers==4.17.0.dev0\\\n",
    "datasets==1.18.3\\\n",
    "textstat==0.7.2 (if running the ML part)\\\n",
    "xgboost==1.5.2 (if running the ML part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7611427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "883b3b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/sample_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f93d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna({'Remember': 0, 'Understand': 0, 'Apply': 0, 'Analyze': 0, 'Evaluate': 0, 'Create':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "558e721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC_data = pd.read_csv(\"data/LIWC2015 Results (Learning_outcome.csv).csv\")\n",
    "data = data.join(LIWC_data).drop(['A'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3bbe570",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning_outcome</th>\n",
       "      <th>Remember</th>\n",
       "      <th>Understand</th>\n",
       "      <th>Apply</th>\n",
       "      <th>Analyze</th>\n",
       "      <th>Evaluate</th>\n",
       "      <th>Create</th>\n",
       "      <th>WC</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>Clout</th>\n",
       "      <th>...</th>\n",
       "      <th>Comma</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyze the health economic implications of e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>99.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apply research skills to operate effectively ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>99.00</td>\n",
       "      <td>92.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assess and synthesise diverse information abo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>43.96</td>\n",
       "      <td>77.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe the general characteristics of the m...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>99.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evaluate the different models of perioperativ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>98.58</td>\n",
       "      <td>15.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Learning_outcome  Remember  Understand  \\\n",
       "0   Analyze the health economic implications of e...       0.0         0.0   \n",
       "1   Apply research skills to operate effectively ...       0.0         0.0   \n",
       "2   Assess and synthesise diverse information abo...       0.0         0.0   \n",
       "3   Describe the general characteristics of the m...       0.0         1.0   \n",
       "4   Evaluate the different models of perioperativ...       0.0         0.0   \n",
       "\n",
       "   Apply  Analyze  Evaluate  Create  WC  Analytic  Clout  ...  Comma  Colon  \\\n",
       "0    0.0      1.0       0.0     0.0   9     99.00  50.00  ...    0.0    0.0   \n",
       "1    1.0      0.0       0.0     0.0  14     99.00  92.33  ...    0.0    0.0   \n",
       "2    0.0      0.0       1.0     1.0  26     43.96  77.92  ...    0.0    0.0   \n",
       "3    0.0      0.0       0.0     0.0  23     99.00  50.00  ...    8.7    0.0   \n",
       "4    0.0      0.0       1.0     0.0  10     98.58  15.86  ...    0.0    0.0   \n",
       "\n",
       "   SemiC  QMark  Exclam  Dash  Quote  Apostro  Parenth  OtherP  \n",
       "0    0.0    0.0     0.0  0.00    0.0      0.0      0.0     0.0  \n",
       "1    0.0    0.0     0.0  0.00    0.0      0.0      0.0     0.0  \n",
       "2    0.0    0.0     0.0  0.00    0.0      0.0      0.0     0.0  \n",
       "3    0.0    0.0     0.0  4.35    0.0      0.0      0.0     0.0  \n",
       "4    0.0    0.0     0.0  0.00    0.0      0.0      0.0     0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "738e8d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[data.columns[1:7]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "206bd2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Remember', 'Understand', 'Apply', 'Analyze', 'Evaluate', 'Create'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "506c390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9b29a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, cohen_kappa_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d5be46",
   "metadata": {},
   "source": [
    "## ML Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f1ad0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96309d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateX(data_x, test_x, textual_column_index, start_index_LIWC, end_index_LIWC):\n",
    "    column_names = []\n",
    "    print(\"Getting Unigram...\")\n",
    "    uni_cv = CountVectorizer(stop_words='english', ngram_range=(1, 1), max_features=1000)\n",
    "    unigram = uni_cv.fit_transform(data_x[:, textual_column_index])\n",
    "    unigram = unigram.toarray()\n",
    "    unigram_test = uni_cv.transform(test_x[:,textual_column_index]).toarray()\n",
    "    temp = uni_cv.get_feature_names_out().tolist()\n",
    "    column_names += [\"uni_\"+name for name in temp]\n",
    "    print(\"Getting Bigram...\")\n",
    "    bi_cv = CountVectorizer(stop_words='english', ngram_range=(2, 2), max_features=1000)\n",
    "    bigram = bi_cv.fit_transform(data_x[:, textual_column_index])\n",
    "    bigram = bigram.toarray()\n",
    "    bigram_test = bi_cv.transform(test_x[:, textual_column_index]).toarray()\n",
    "    temp = bi_cv.get_feature_names_out().tolist()\n",
    "    column_names += [\"bi_\"+name for name in temp]\n",
    "    print(\"Getting Tfidf...\")\n",
    "    tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1, 1), max_features=1000)\n",
    "    t = tfidf.fit_transform(data_x[:, textual_column_index])\n",
    "    t = t.toarray()\n",
    "    t_test = tfidf.transform(test_x[:, textual_column_index]).toarray()\n",
    "    temp = tfidf.get_feature_names_out().tolist()\n",
    "    column_names += [\"tfidf_\"+name for name in temp]\n",
    "    print(\"Getting ARI...\")\n",
    "    ari = [textstat.automated_readability_index(text) for text in data_x[:, textual_column_index]]\n",
    "    ari_test = [textstat.automated_readability_index(text) for text in test_x[:, textual_column_index]]\n",
    "    column_names.append(\"ari\")\n",
    "    combined_data_x = []\n",
    "    combined_test_x = []\n",
    "    print(\"Combining...\")\n",
    "    for i in range(len(data_x)):\n",
    "        combined_data_x.append(unigram[i].tolist()\n",
    "                              + bigram[i].tolist()\n",
    "                              + t[i].tolist()\n",
    "                              + [ari[i]]\n",
    "                              + data_x[i, start_index_LIWC:end_index_LIWC].tolist())\n",
    "    for i in range(len(test_x)):\n",
    "        combined_test_x.append(unigram_test[i].tolist()\n",
    "                              + bigram_test[i].tolist()\n",
    "                              + t_test[i].tolist()\n",
    "                              + [ari_test[i]]\n",
    "                              + test_x[i, start_index_LIWC:end_index_LIWC].tolist())\n",
    "    print(\"Generated feature shape is\", np.array(combined_data_x).shape)\n",
    "    print(\"Generated test feature is\", np.array(combined_test_x).shape)\n",
    "    return combined_data_x, column_names, combined_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d575655a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Analyze the health economic implications of e...\n",
       "1         Apply research skills to operate effectively ...\n",
       "2         Assess and synthesise diverse information abo...\n",
       "3         Describe the general characteristics of the m...\n",
       "4         Evaluate the different models of perioperativ...\n",
       "                               ...                        \n",
       "21375    Write/type simple sentences using hiragana, ka...\n",
       "21376    Writing of assessment reports and giving feedb...\n",
       "21377    You will develop the ability to work in a team...\n",
       "21378    You will develop their oral presentation skill...\n",
       "21379    You will gain an ability to use geoscientific ...\n",
       "Name: Learning_outcome, Length: 21380, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=list(data.columns[1:7])).iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "592e391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data.drop(columns=list(data.columns[1:8])), data[data.columns[1:7]], test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e72037dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([16156,   948])),\n",
       " (array([0., 1.]), array([4039,  237])))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Remember'].tolist(), return_counts=True), np.unique(test_y['Remember'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7a8e740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([12479,  4625])),\n",
       " (array([0., 1.]), array([3076, 1200])))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Understand'].tolist(), return_counts=True), np.unique(test_y['Understand'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a0155c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([12239,  4865])),\n",
       " (array([0., 1.]), array([3060, 1216])))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Apply'].tolist(), return_counts=True), np.unique(test_y['Apply'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fde5b0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([14346,  2758])),\n",
       " (array([0., 1.]), array([3575,  701])))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Analyze'].tolist(), return_counts=True), np.unique(test_y['Analyze'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "819bd6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([14069,  3035])),\n",
       " (array([0., 1.]), array([3477,  799])))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Evaluate'].tolist(), return_counts=True), np.unique(test_y['Evaluate'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57bb7c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([13956,  3148])),\n",
       " (array([0., 1.]), array([3537,  739])))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Create'].tolist(), return_counts=True), np.unique(test_y['Create'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8315a801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4]), array([18773,  2325,   280,     2]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = []\n",
    "for d in data[data.columns[1:7]].values:\n",
    "    one_hot.append(np.array2string(d).count(\"1\"))\n",
    "np.unique(one_hot, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6008a326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Unigram...\n",
      "Getting Bigram...\n",
      "Getting Tfidf...\n",
      "Getting ARI...\n",
      "Combining...\n",
      "Generated feature shape is (17104, 3093)\n",
      "Generated test feature is (4276, 3093)\n"
     ]
    }
   ],
   "source": [
    "ml_train_x, column_names, ml_test_x = generateX(train_x.to_numpy(), test_x.to_numpy(), 0, 1, 94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4393f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names += data.columns[7:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35d7e85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(ml_train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "722b4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = rf.predict(ml_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddeb617c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Remember      0.938     0.705     0.805       237\n",
      "  Understand      0.929     0.783     0.850      1200\n",
      "       Apply      0.945     0.771     0.849      1216\n",
      "     Analyze      0.964     0.733     0.833       701\n",
      "    Evaluate      0.962     0.760     0.849       799\n",
      "      Create      0.923     0.645     0.760       739\n",
      "\n",
      "   micro avg      0.943     0.744     0.832      4892\n",
      "   macro avg      0.943     0.733     0.824      4892\n",
      "weighted avg      0.943     0.744     0.831      4892\n",
      " samples avg      0.779     0.755     0.763      4892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_y, output_dict=False, target_names=list(data.columns[1:7]), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2796b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_score_y = rf.predict_proba(ml_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "491b5a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4276, 93)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf029020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 4276, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pred_score_y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91fa2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_score_y = np.transpose([score[:, 1] for score in rf.predict_proba(ml_test_x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac9ad3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9848633 , 0.97075301, 0.97065273, 0.97663957, 0.97929357,\n",
       "       0.96531295])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_y, pred_score_y, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "110ab923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8319817247287263"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_y, pred_y, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e579641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7252104770813844"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96a1d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_result_df = pd.DataFrame(data=pred_y, columns=data.columns[1:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2ad2b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Remember</th>\n",
       "      <th>Understand</th>\n",
       "      <th>Apply</th>\n",
       "      <th>Analyze</th>\n",
       "      <th>Evaluate</th>\n",
       "      <th>Create</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4276 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Remember  Understand  Apply  Analyze  Evaluate  Create\n",
       "0          0.0         1.0    0.0      0.0       0.0     0.0\n",
       "1          0.0         1.0    0.0      0.0       0.0     0.0\n",
       "2          0.0         1.0    0.0      0.0       0.0     0.0\n",
       "3          0.0         0.0    1.0      0.0       0.0     0.0\n",
       "4          0.0         0.0    0.0      0.0       0.0     0.0\n",
       "...        ...         ...    ...      ...       ...     ...\n",
       "4271       0.0         0.0    0.0      0.0       1.0     0.0\n",
       "4272       1.0         0.0    0.0      0.0       0.0     0.0\n",
       "4273       0.0         0.0    1.0      0.0       0.0     0.0\n",
       "4274       0.0         0.0    0.0      0.0       0.0     0.0\n",
       "4275       0.0         0.0    0.0      0.0       1.0     0.0\n",
       "\n",
       "[4276 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fba1ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_golden_df = pd.DataFrame(data=test_y, columns=data.columns[1:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "203d209c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9810570626753976\n",
      "0.9223573433115061\n",
      "0.921889616463985\n",
      "0.9518241347053321\n",
      "0.9494855004677268\n",
      "0.9293732460243218\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(ml_golden_df['Remember'].tolist(), ml_result_df['Remember'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Understand'].tolist(), ml_result_df['Understand'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Apply'].tolist(), ml_result_df['Apply'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Analyze'].tolist(), ml_result_df['Analyze'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Evaluate'].tolist(), ml_result_df['Evaluate'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Create'].tolist(), ml_result_df['Create'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d286e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7950759924457214\n",
      "0.7980526086986209\n",
      "0.7968115473567279\n",
      "0.8055212727390746\n",
      "0.8191237484680814\n",
      "0.719669252126872\n"
     ]
    }
   ],
   "source": [
    "print(cohen_kappa_score(ml_golden_df['Remember'].tolist(), ml_result_df['Remember'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Understand'].tolist(), ml_result_df['Understand'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Apply'].tolist(), ml_result_df['Apply'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Analyze'].tolist(), ml_result_df['Analyze'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Evaluate'].tolist(), ml_result_df['Evaluate'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Create'].tolist(), ml_result_df['Create'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940215e9",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8f11046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/.pyenv/versions/3.9.18/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, AutoModel, TrainingArguments, Trainer, AutoModelForSequenceClassification, EarlyStoppingCallback\n",
    "from transformers import TFBertPreTrainedModel, TFBertMainLayer, InputFeatures\n",
    "from datasets import load_metric, list_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0af84439",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "740bae00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', problem_type=\"multi_label_classification\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', problem_type=\"multi_label_classification\", num_labels=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4808e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data['Learning_outcome'].tolist(), labels, test_size=0.2, random_state=666)\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "107a3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded = tokenizer(train_x, truncation=True, padding=True, max_length=100)\n",
    "val_encoded = tokenizer(val_x, truncation=True, padding=True, max_length=100)\n",
    "test_encoded = tokenizer(test_x, truncation=True, padding=True, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0dfe437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = EncodeDataset(train_encoded, train_y), EncodeDataset(val_encoded, val_y), EncodeDataset(test_encoded, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af89acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "        output_dir='multilabel',          # output directory\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=3,              # total number of training epochs\n",
    "        per_device_train_batch_size=64,  # batch size per device during training\n",
    "        per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "        warmup_steps=5,                # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.05,               # strength of weight decay\n",
    "        logging_dir='./logs',            # directory for storing logs\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=10,\n",
    "        load_best_model_at_end=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64f828cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassResult(predicted):\n",
    "    results = []\n",
    "    for probs in predicted.numpy():\n",
    "        result = []\n",
    "        for prob in probs:\n",
    "            if prob < 0.5:\n",
    "                result.append(0)\n",
    "            else:\n",
    "                result.append(1)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "metric = load_metric(\"f1\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = tf.keras.activations.sigmoid(logits)\n",
    "    predicted = getClassResult(predictions)\n",
    "    return metric.compute(predictions=predicted, references=labels, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ebca9668",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, args=training_args, train_dataset=train_set, eval_dataset=val_set, callbacks=[EarlyStoppingCallback(early_stopping_patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cbae7c3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/.pyenv/versions/3.9.18/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 13683\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 642\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='642' max='642' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [642/642 07:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.604300</td>\n",
       "      <td>0.498867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.458200</td>\n",
       "      <td>0.437737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.428000</td>\n",
       "      <td>0.398313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.381200</td>\n",
       "      <td>0.345268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.340300</td>\n",
       "      <td>0.298848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.279900</td>\n",
       "      <td>0.263143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.249600</td>\n",
       "      <td>0.229983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.211680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.207300</td>\n",
       "      <td>0.190417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.185200</td>\n",
       "      <td>0.181433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.187600</td>\n",
       "      <td>0.177525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.157973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.153200</td>\n",
       "      <td>0.153410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.135300</td>\n",
       "      <td>0.148238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>0.147335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.142994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.148587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.134547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.141600</td>\n",
       "      <td>0.132276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.126300</td>\n",
       "      <td>0.129123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.139200</td>\n",
       "      <td>0.128438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.112800</td>\n",
       "      <td>0.130820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.124535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.118600</td>\n",
       "      <td>0.125932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.118951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.118792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.102700</td>\n",
       "      <td>0.116778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.117692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>0.120196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>0.125927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.088700</td>\n",
       "      <td>0.117792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.096300</td>\n",
       "      <td>0.110245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>0.112678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>0.108730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.091600</td>\n",
       "      <td>0.107565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.106600</td>\n",
       "      <td>0.110020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.107532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.104060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.101770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.101767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>0.102785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>0.104169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>0.099778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.073300</td>\n",
       "      <td>0.103162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.100185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.098180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.098216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.097814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.097933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.097806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.099205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.097302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.096394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.096244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.095801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.095411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.095618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.094842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.095348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.053900</td>\n",
       "      <td>0.095523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.058900</td>\n",
       "      <td>0.094417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.094209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.093924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.093753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-10\n",
      "Configuration saved in multilabel/checkpoint-10/config.json\n",
      "Model weights saved in multilabel/checkpoint-10/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-20\n",
      "Configuration saved in multilabel/checkpoint-20/config.json\n",
      "Model weights saved in multilabel/checkpoint-20/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-30\n",
      "Configuration saved in multilabel/checkpoint-30/config.json\n",
      "Model weights saved in multilabel/checkpoint-30/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-40\n",
      "Configuration saved in multilabel/checkpoint-40/config.json\n",
      "Model weights saved in multilabel/checkpoint-40/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-50\n",
      "Configuration saved in multilabel/checkpoint-50/config.json\n",
      "Model weights saved in multilabel/checkpoint-50/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-60\n",
      "Configuration saved in multilabel/checkpoint-60/config.json\n",
      "Model weights saved in multilabel/checkpoint-60/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-70\n",
      "Configuration saved in multilabel/checkpoint-70/config.json\n",
      "Model weights saved in multilabel/checkpoint-70/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-80\n",
      "Configuration saved in multilabel/checkpoint-80/config.json\n",
      "Model weights saved in multilabel/checkpoint-80/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-90\n",
      "Configuration saved in multilabel/checkpoint-90/config.json\n",
      "Model weights saved in multilabel/checkpoint-90/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-100\n",
      "Configuration saved in multilabel/checkpoint-100/config.json\n",
      "Model weights saved in multilabel/checkpoint-100/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-110\n",
      "Configuration saved in multilabel/checkpoint-110/config.json\n",
      "Model weights saved in multilabel/checkpoint-110/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-120\n",
      "Configuration saved in multilabel/checkpoint-120/config.json\n",
      "Model weights saved in multilabel/checkpoint-120/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-130\n",
      "Configuration saved in multilabel/checkpoint-130/config.json\n",
      "Model weights saved in multilabel/checkpoint-130/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-140\n",
      "Configuration saved in multilabel/checkpoint-140/config.json\n",
      "Model weights saved in multilabel/checkpoint-140/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-150\n",
      "Configuration saved in multilabel/checkpoint-150/config.json\n",
      "Model weights saved in multilabel/checkpoint-150/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-160\n",
      "Configuration saved in multilabel/checkpoint-160/config.json\n",
      "Model weights saved in multilabel/checkpoint-160/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-170\n",
      "Configuration saved in multilabel/checkpoint-170/config.json\n",
      "Model weights saved in multilabel/checkpoint-170/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-180\n",
      "Configuration saved in multilabel/checkpoint-180/config.json\n",
      "Model weights saved in multilabel/checkpoint-180/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-190\n",
      "Configuration saved in multilabel/checkpoint-190/config.json\n",
      "Model weights saved in multilabel/checkpoint-190/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-200\n",
      "Configuration saved in multilabel/checkpoint-200/config.json\n",
      "Model weights saved in multilabel/checkpoint-200/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-210\n",
      "Configuration saved in multilabel/checkpoint-210/config.json\n",
      "Model weights saved in multilabel/checkpoint-210/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-220\n",
      "Configuration saved in multilabel/checkpoint-220/config.json\n",
      "Model weights saved in multilabel/checkpoint-220/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-230\n",
      "Configuration saved in multilabel/checkpoint-230/config.json\n",
      "Model weights saved in multilabel/checkpoint-230/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-240\n",
      "Configuration saved in multilabel/checkpoint-240/config.json\n",
      "Model weights saved in multilabel/checkpoint-240/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-250\n",
      "Configuration saved in multilabel/checkpoint-250/config.json\n",
      "Model weights saved in multilabel/checkpoint-250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-260\n",
      "Configuration saved in multilabel/checkpoint-260/config.json\n",
      "Model weights saved in multilabel/checkpoint-260/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-270\n",
      "Configuration saved in multilabel/checkpoint-270/config.json\n",
      "Model weights saved in multilabel/checkpoint-270/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-280\n",
      "Configuration saved in multilabel/checkpoint-280/config.json\n",
      "Model weights saved in multilabel/checkpoint-280/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-290\n",
      "Configuration saved in multilabel/checkpoint-290/config.json\n",
      "Model weights saved in multilabel/checkpoint-290/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-300\n",
      "Configuration saved in multilabel/checkpoint-300/config.json\n",
      "Model weights saved in multilabel/checkpoint-300/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-310\n",
      "Configuration saved in multilabel/checkpoint-310/config.json\n",
      "Model weights saved in multilabel/checkpoint-310/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-320\n",
      "Configuration saved in multilabel/checkpoint-320/config.json\n",
      "Model weights saved in multilabel/checkpoint-320/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-330\n",
      "Configuration saved in multilabel/checkpoint-330/config.json\n",
      "Model weights saved in multilabel/checkpoint-330/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-340\n",
      "Configuration saved in multilabel/checkpoint-340/config.json\n",
      "Model weights saved in multilabel/checkpoint-340/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-350\n",
      "Configuration saved in multilabel/checkpoint-350/config.json\n",
      "Model weights saved in multilabel/checkpoint-350/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-360\n",
      "Configuration saved in multilabel/checkpoint-360/config.json\n",
      "Model weights saved in multilabel/checkpoint-360/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-370\n",
      "Configuration saved in multilabel/checkpoint-370/config.json\n",
      "Model weights saved in multilabel/checkpoint-370/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-380\n",
      "Configuration saved in multilabel/checkpoint-380/config.json\n",
      "Model weights saved in multilabel/checkpoint-380/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-390\n",
      "Configuration saved in multilabel/checkpoint-390/config.json\n",
      "Model weights saved in multilabel/checkpoint-390/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-400\n",
      "Configuration saved in multilabel/checkpoint-400/config.json\n",
      "Model weights saved in multilabel/checkpoint-400/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-410\n",
      "Configuration saved in multilabel/checkpoint-410/config.json\n",
      "Model weights saved in multilabel/checkpoint-410/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-420\n",
      "Configuration saved in multilabel/checkpoint-420/config.json\n",
      "Model weights saved in multilabel/checkpoint-420/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-430\n",
      "Configuration saved in multilabel/checkpoint-430/config.json\n",
      "Model weights saved in multilabel/checkpoint-430/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-440\n",
      "Configuration saved in multilabel/checkpoint-440/config.json\n",
      "Model weights saved in multilabel/checkpoint-440/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-450\n",
      "Configuration saved in multilabel/checkpoint-450/config.json\n",
      "Model weights saved in multilabel/checkpoint-450/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-460\n",
      "Configuration saved in multilabel/checkpoint-460/config.json\n",
      "Model weights saved in multilabel/checkpoint-460/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-470\n",
      "Configuration saved in multilabel/checkpoint-470/config.json\n",
      "Model weights saved in multilabel/checkpoint-470/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-480\n",
      "Configuration saved in multilabel/checkpoint-480/config.json\n",
      "Model weights saved in multilabel/checkpoint-480/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-490\n",
      "Configuration saved in multilabel/checkpoint-490/config.json\n",
      "Model weights saved in multilabel/checkpoint-490/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-500\n",
      "Configuration saved in multilabel/checkpoint-500/config.json\n",
      "Model weights saved in multilabel/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-510\n",
      "Configuration saved in multilabel/checkpoint-510/config.json\n",
      "Model weights saved in multilabel/checkpoint-510/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-520\n",
      "Configuration saved in multilabel/checkpoint-520/config.json\n",
      "Model weights saved in multilabel/checkpoint-520/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-530\n",
      "Configuration saved in multilabel/checkpoint-530/config.json\n",
      "Model weights saved in multilabel/checkpoint-530/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-540\n",
      "Configuration saved in multilabel/checkpoint-540/config.json\n",
      "Model weights saved in multilabel/checkpoint-540/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-550\n",
      "Configuration saved in multilabel/checkpoint-550/config.json\n",
      "Model weights saved in multilabel/checkpoint-550/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-560\n",
      "Configuration saved in multilabel/checkpoint-560/config.json\n",
      "Model weights saved in multilabel/checkpoint-560/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-570\n",
      "Configuration saved in multilabel/checkpoint-570/config.json\n",
      "Model weights saved in multilabel/checkpoint-570/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-580\n",
      "Configuration saved in multilabel/checkpoint-580/config.json\n",
      "Model weights saved in multilabel/checkpoint-580/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-590\n",
      "Configuration saved in multilabel/checkpoint-590/config.json\n",
      "Model weights saved in multilabel/checkpoint-590/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-600\n",
      "Configuration saved in multilabel/checkpoint-600/config.json\n",
      "Model weights saved in multilabel/checkpoint-600/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-610\n",
      "Configuration saved in multilabel/checkpoint-610/config.json\n",
      "Model weights saved in multilabel/checkpoint-610/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-620\n",
      "Configuration saved in multilabel/checkpoint-620/config.json\n",
      "Model weights saved in multilabel/checkpoint-620/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-630\n",
      "Configuration saved in multilabel/checkpoint-630/config.json\n",
      "Model weights saved in multilabel/checkpoint-630/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-640\n",
      "Configuration saved in multilabel/checkpoint-640/config.json\n",
      "Model weights saved in multilabel/checkpoint-640/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from multilabel/checkpoint-640 (score: 0.09375252574682236).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=642, training_loss=0.13524437687617968, metrics={'train_runtime': 464.4953, 'train_samples_per_second': 88.373, 'train_steps_per_second': 1.382, 'total_flos': 2109537813056400.0, 'train_loss': 0.13524437687617968, 'epoch': 3.0})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f14bc5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 4276\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logits = trainer.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0750e38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4276, 6)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5b7a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 13:17:11.501703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 13:17:11.546480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 13:17:11.546781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 13:17:11.548737: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-05 13:17:11.554727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 13:17:11.555052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 13:17:11.555215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 13:17:11.556747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 13:17:11.556946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 13:17:11.557117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-05 13:17:11.557535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12490 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "predicted = tf.keras.activations.sigmoid(logits.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f33fc8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00969101, 0.98481834, 0.0107606 , 0.00975786, 0.00886829,\n",
       "        0.01091874],\n",
       "       [0.00915964, 0.98466325, 0.01052529, 0.00910978, 0.00913619,\n",
       "        0.01224123],\n",
       "       [0.05010709, 0.89347756, 0.00486106, 0.05864727, 0.06428542,\n",
       "        0.00304807],\n",
       "       ...,\n",
       "       [0.00506825, 0.01770407, 0.97926235, 0.00668835, 0.00808989,\n",
       "        0.01428074],\n",
       "       [0.9081824 , 0.08788445, 0.03324952, 0.0135317 , 0.8482272 ,\n",
       "        0.02497723],\n",
       "       [0.01558924, 0.02727734, 0.79540026, 0.03905605, 0.9863284 ,\n",
       "        0.02791703]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "acea92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = getClassResult(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d53a3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for pred in predicted_label:\n",
    "    if pred.count(1) > 1:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0899422a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Remember      0.906     0.937     0.921       237\n",
      "  Understand      0.957     0.935     0.946      1200\n",
      "       Apply      0.925     0.931     0.928      1216\n",
      "     Analyze      0.921     0.914     0.918       701\n",
      "    Evaluate      0.936     0.927     0.931       799\n",
      "      Create      0.931     0.857     0.892       739\n",
      "\n",
      "   micro avg      0.934     0.918     0.926      4892\n",
      "   macro avg      0.929     0.917     0.923      4892\n",
      "weighted avg      0.934     0.918     0.926      4892\n",
      " samples avg      0.935     0.930     0.927      4892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, predicted_label, output_dict=False, target_names=list(data.columns[1:7]), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e52f7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99093125, 0.98838345, 0.98106201, 0.9831701 , 0.98881367,\n",
       "       0.97583137])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_y, predicted.numpy(), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c01e8dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8849391955098223"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.array(test_y), predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4bcd035",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_result_df = pd.DataFrame(data=predicted_label, columns=data.columns[1:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a4d4dc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9911131898971001\n",
      "0.9700654817586529\n",
      "0.9588400374181478\n",
      "0.9731057062675398\n",
      "0.974508886810103\n",
      "0.9642188961646398\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(ml_golden_df['Remember'].tolist(), dl_result_df['Remember'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Understand'].tolist(), dl_result_df['Understand'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Apply'].tolist(), dl_result_df['Apply'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Analyze'].tolist(), dl_result_df['Analyze'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Evaluate'].tolist(), dl_result_df['Evaluate'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Create'].tolist(), dl_result_df['Create'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d9b0db2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9164544023297831\n",
      "0.9253291189805224\n",
      "0.8990734740645693\n",
      "0.9016083140914566\n",
      "0.9158313318284425\n",
      "0.8707724325268182\n"
     ]
    }
   ],
   "source": [
    "print(cohen_kappa_score(ml_golden_df['Remember'].tolist(), dl_result_df['Remember'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Understand'].tolist(), dl_result_df['Understand'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Apply'].tolist(), dl_result_df['Apply'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Analyze'].tolist(), dl_result_df['Analyze'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Evaluate'].tolist(), dl_result_df['Evaluate'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Create'].tolist(), dl_result_df['Create'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee3d07d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
