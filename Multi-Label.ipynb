{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3fe3735",
   "metadata": {},
   "source": [
    "Required packages:\\\n",
    "pandas==1.4.0\\\n",
    "numpy==1.21.5\\\n",
    "scikit-learn==1.0.2\\\n",
    "tensorflow==2.7.0\\\n",
    "torch==1.10.2\\\n",
    "transformers==4.17.0.dev0\\\n",
    "datasets==1.18.3\\\n",
    "textstat==0.7.2 (if running the ML part)\\\n",
    "xgboost==1.5.2 (if running the ML part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7611427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "883b3b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/sample_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f93d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna({'Remember': 0, 'Understand': 0, 'Apply': 0, 'Analyze': 0, 'Evaluate': 0, 'Create':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "558e721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC_data = pd.read_csv(\"data/LIWC2015 Results (Learning_outcome.csv).csv\")\n",
    "data = data.join(LIWC_data).drop(['A'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3bbe570",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning_outcome</th>\n",
       "      <th>Remember</th>\n",
       "      <th>Understand</th>\n",
       "      <th>Apply</th>\n",
       "      <th>Analyze</th>\n",
       "      <th>Evaluate</th>\n",
       "      <th>Create</th>\n",
       "      <th>WC</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>Clout</th>\n",
       "      <th>...</th>\n",
       "      <th>Comma</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyze the health economic implications of e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>99.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apply research skills to operate effectively ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>99.00</td>\n",
       "      <td>92.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assess and synthesise diverse information abo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>43.96</td>\n",
       "      <td>77.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe the general characteristics of the m...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>99.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evaluate the different models of perioperativ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>98.58</td>\n",
       "      <td>15.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Learning_outcome  Remember  Understand  \\\n",
       "0   Analyze the health economic implications of e...       0.0         0.0   \n",
       "1   Apply research skills to operate effectively ...       0.0         0.0   \n",
       "2   Assess and synthesise diverse information abo...       0.0         0.0   \n",
       "3   Describe the general characteristics of the m...       0.0         1.0   \n",
       "4   Evaluate the different models of perioperativ...       0.0         0.0   \n",
       "\n",
       "   Apply  Analyze  Evaluate  Create  WC  Analytic  Clout  ...  Comma  Colon  \\\n",
       "0    0.0      1.0       0.0     0.0   9     99.00  50.00  ...    0.0    0.0   \n",
       "1    1.0      0.0       0.0     0.0  14     99.00  92.33  ...    0.0    0.0   \n",
       "2    0.0      0.0       1.0     1.0  26     43.96  77.92  ...    0.0    0.0   \n",
       "3    0.0      0.0       0.0     0.0  23     99.00  50.00  ...    8.7    0.0   \n",
       "4    0.0      0.0       1.0     0.0  10     98.58  15.86  ...    0.0    0.0   \n",
       "\n",
       "   SemiC  QMark  Exclam  Dash  Quote  Apostro  Parenth  OtherP  \n",
       "0    0.0    0.0     0.0  0.00    0.0      0.0      0.0     0.0  \n",
       "1    0.0    0.0     0.0  0.00    0.0      0.0      0.0     0.0  \n",
       "2    0.0    0.0     0.0  0.00    0.0      0.0      0.0     0.0  \n",
       "3    0.0    0.0     0.0  4.35    0.0      0.0      0.0     0.0  \n",
       "4    0.0    0.0     0.0  0.00    0.0      0.0      0.0     0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "738e8d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[data.columns[1:7]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "206bd2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Remember', 'Understand', 'Apply', 'Analyze', 'Evaluate', 'Create'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "506c390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9b29a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, cohen_kappa_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d5be46",
   "metadata": {},
   "source": [
    "## ML Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f1ad0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96309d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateX(data_x, test_x, textual_column_index, start_index_LIWC, end_index_LIWC):\n",
    "    column_names = []\n",
    "    print(\"Getting Unigram...\")\n",
    "    uni_cv = CountVectorizer(stop_words='english', ngram_range=(1, 1), max_features=1000)\n",
    "    unigram = uni_cv.fit_transform(data_x[:, textual_column_index])\n",
    "    unigram = unigram.toarray()\n",
    "    unigram_test = uni_cv.transform(test_x[:,textual_column_index]).toarray()\n",
    "    temp = uni_cv.get_feature_names_out().tolist()\n",
    "    column_names += [\"uni_\"+name for name in temp]\n",
    "    print(\"Getting Bigram...\")\n",
    "    bi_cv = CountVectorizer(stop_words='english', ngram_range=(2, 2), max_features=1000)\n",
    "    bigram = bi_cv.fit_transform(data_x[:, textual_column_index])\n",
    "    bigram = bigram.toarray()\n",
    "    bigram_test = bi_cv.transform(test_x[:, textual_column_index]).toarray()\n",
    "    temp = bi_cv.get_feature_names_out().tolist()\n",
    "    column_names += [\"bi_\"+name for name in temp]\n",
    "    print(\"Getting Tfidf...\")\n",
    "    tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1, 1), max_features=1000)\n",
    "    t = tfidf.fit_transform(data_x[:, textual_column_index])\n",
    "    t = t.toarray()\n",
    "    t_test = tfidf.transform(test_x[:, textual_column_index]).toarray()\n",
    "    temp = tfidf.get_feature_names_out().tolist()\n",
    "    column_names += [\"tfidf_\"+name for name in temp]\n",
    "    print(\"Getting ARI...\")\n",
    "    ari = [textstat.automated_readability_index(text) for text in data_x[:, textual_column_index]]\n",
    "    ari_test = [textstat.automated_readability_index(text) for text in test_x[:, textual_column_index]]\n",
    "    column_names.append(\"ari\")\n",
    "    combined_data_x = []\n",
    "    combined_test_x = []\n",
    "    print(\"Combining...\")\n",
    "    for i in range(len(data_x)):\n",
    "        combined_data_x.append(unigram[i].tolist()\n",
    "                              + bigram[i].tolist()\n",
    "                              + t[i].tolist()\n",
    "                              + [ari[i]]\n",
    "                              + data_x[i, start_index_LIWC:end_index_LIWC].tolist())\n",
    "    for i in range(len(test_x)):\n",
    "        combined_test_x.append(unigram_test[i].tolist()\n",
    "                              + bigram_test[i].tolist()\n",
    "                              + t_test[i].tolist()\n",
    "                              + [ari_test[i]]\n",
    "                              + test_x[i, start_index_LIWC:end_index_LIWC].tolist())\n",
    "    print(\"Generated feature shape is\", np.array(combined_data_x).shape)\n",
    "    print(\"Generated test feature is\", np.array(combined_test_x).shape)\n",
    "    return combined_data_x, column_names, combined_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d575655a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Analyze the health economic implications of e...\n",
       "1         Apply research skills to operate effectively ...\n",
       "2         Assess and synthesise diverse information abo...\n",
       "3         Describe the general characteristics of the m...\n",
       "4         Evaluate the different models of perioperativ...\n",
       "                               ...                        \n",
       "21375    Write/type simple sentences using hiragana, ka...\n",
       "21376    Writing of assessment reports and giving feedb...\n",
       "21377    You will develop the ability to work in a team...\n",
       "21378    You will develop their oral presentation skill...\n",
       "21379    You will gain an ability to use geoscientific ...\n",
       "Name: Learning_outcome, Length: 21380, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=list(data.columns[1:7])).iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "592e391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data.drop(columns=list(data.columns[1:8])), data[data.columns[1:7]], test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e72037dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([16156,   948])),\n",
       " (array([0., 1.]), array([4039,  237])))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Remember'].tolist(), return_counts=True), np.unique(test_y['Remember'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7a8e740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([12479,  4625])),\n",
       " (array([0., 1.]), array([3076, 1200])))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Understand'].tolist(), return_counts=True), np.unique(test_y['Understand'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a0155c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([12239,  4865])),\n",
       " (array([0., 1.]), array([3060, 1216])))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Apply'].tolist(), return_counts=True), np.unique(test_y['Apply'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fde5b0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([14346,  2758])),\n",
       " (array([0., 1.]), array([3575,  701])))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Analyze'].tolist(), return_counts=True), np.unique(test_y['Analyze'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "819bd6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([14069,  3035])),\n",
       " (array([0., 1.]), array([3477,  799])))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Evaluate'].tolist(), return_counts=True), np.unique(test_y['Evaluate'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57bb7c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0., 1.]), array([13956,  3148])),\n",
       " (array([0., 1.]), array([3537,  739])))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y['Create'].tolist(), return_counts=True), np.unique(test_y['Create'].tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8315a801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4]), array([18773,  2325,   280,     2]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = []\n",
    "for d in data[data.columns[1:7]].values:\n",
    "    one_hot.append(np.array2string(d).count(\"1\"))\n",
    "np.unique(one_hot, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6008a326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Unigram...\n",
      "Getting Bigram...\n",
      "Getting Tfidf...\n",
      "Getting ARI...\n",
      "Combining...\n",
      "Generated feature shape is (17104, 3093)\n",
      "Generated test feature is (4276, 3093)\n"
     ]
    }
   ],
   "source": [
    "ml_train_x, column_names, ml_test_x = generateX(train_x.to_numpy(), test_x.to_numpy(), 0, 1, 94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4393f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names += data.columns[7:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35d7e85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(ml_train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "722b4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = rf.predict(ml_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddeb617c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Remember      0.930     0.730     0.818       237\n",
      "  Understand      0.931     0.799     0.860      1200\n",
      "       Apply      0.943     0.769     0.847      1216\n",
      "     Analyze      0.966     0.729     0.831       701\n",
      "    Evaluate      0.965     0.762     0.852       799\n",
      "      Create      0.924     0.639     0.755       739\n",
      "\n",
      "   micro avg      0.943     0.748     0.834      4892\n",
      "   macro avg      0.943     0.738     0.827      4892\n",
      "weighted avg      0.943     0.748     0.833      4892\n",
      " samples avg      0.781     0.758     0.765      4892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_y, output_dict=False, target_names=list(data.columns[1:7]), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2796b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_score_y = rf.predict_proba(ml_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "491b5a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4276, 93)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf029020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 4276, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pred_score_y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91fa2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_score_y = np.transpose([score[:, 1] for score in rf.predict_proba(ml_test_x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac9ad3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98932821, 0.96999865, 0.97035698, 0.97208663, 0.98145618,\n",
       "       0.96424479])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_y, pred_score_y, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "110ab923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8343404400866492"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_y, pred_y, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e579641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7296538821328344"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96a1d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_result_df = pd.DataFrame(data=pred_y, columns=data.columns[1:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2ad2b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Remember</th>\n",
       "      <th>Understand</th>\n",
       "      <th>Apply</th>\n",
       "      <th>Analyze</th>\n",
       "      <th>Evaluate</th>\n",
       "      <th>Create</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4276 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Remember  Understand  Apply  Analyze  Evaluate  Create\n",
       "0          0.0         1.0    0.0      0.0       0.0     0.0\n",
       "1          0.0         1.0    0.0      0.0       0.0     0.0\n",
       "2          0.0         1.0    0.0      0.0       0.0     0.0\n",
       "3          0.0         0.0    1.0      0.0       0.0     0.0\n",
       "4          0.0         0.0    0.0      0.0       0.0     0.0\n",
       "...        ...         ...    ...      ...       ...     ...\n",
       "4271       0.0         0.0    0.0      0.0       1.0     0.0\n",
       "4272       1.0         0.0    0.0      0.0       0.0     0.0\n",
       "4273       0.0         0.0    1.0      0.0       0.0     0.0\n",
       "4274       0.0         0.0    0.0      0.0       0.0     0.0\n",
       "4275       0.0         0.0    0.0      0.0       1.0     0.0\n",
       "\n",
       "[4276 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fba1ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_golden_df = pd.DataFrame(data=test_y, columns=data.columns[1:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "203d209c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9819925163704397\n",
      "0.9270346117867165\n",
      "0.9209541627689429\n",
      "0.9513564078578111\n",
      "0.950420954162769\n",
      "0.9284377923292797\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(ml_golden_df['Remember'].tolist(), ml_result_df['Remember'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Understand'].tolist(), ml_result_df['Understand'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Apply'].tolist(), ml_result_df['Apply'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Analyze'].tolist(), ml_result_df['Analyze'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Evaluate'].tolist(), ml_result_df['Evaluate'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Create'].tolist(), ml_result_df['Create'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d286e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8086393922063672\n",
      "0.8111253942815723\n",
      "0.7943781527142935\n",
      "0.80313345678515\n",
      "0.8224733086816355\n",
      "0.7149173090775037\n"
     ]
    }
   ],
   "source": [
    "print(cohen_kappa_score(ml_golden_df['Remember'].tolist(), ml_result_df['Remember'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Understand'].tolist(), ml_result_df['Understand'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Apply'].tolist(), ml_result_df['Apply'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Analyze'].tolist(), ml_result_df['Analyze'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Evaluate'].tolist(), ml_result_df['Evaluate'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Create'].tolist(), ml_result_df['Create'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940215e9",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8f11046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, AutoModel, TrainingArguments, Trainer, AutoModelForSequenceClassification, EarlyStoppingCallback\n",
    "from transformers import TFBertPreTrainedModel, TFBertMainLayer, InputFeatures\n",
    "from datasets import load_metric, list_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0af84439",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "740bae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', problem_type=\"multi_label_classification\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained('multilabel/checkpoint-250', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4808e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data['Learning_outcome'].tolist(), labels, test_size=0.2, random_state=666)\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "107a3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded = tokenizer(train_x, truncation=True, padding=True, max_length=100)\n",
    "val_encoded = tokenizer(val_x, truncation=True, padding=True, max_length=100)\n",
    "test_encoded = tokenizer(test_x, truncation=True, padding=True, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0dfe437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = EncodeDataset(train_encoded, train_y), EncodeDataset(val_encoded, val_y), EncodeDataset(test_encoded, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af89acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "        output_dir='multilabel',          # output directory\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=3,              # total number of training epochs\n",
    "        per_device_train_batch_size=64,  # batch size per device during training\n",
    "        per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "        warmup_steps=5,                # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.05,               # strength of weight decay\n",
    "        logging_dir='./logs',            # directory for storing logs\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=10,\n",
    "        load_best_model_at_end=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64f828cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassResult(predicted):\n",
    "    results = []\n",
    "    for probs in predicted.numpy():\n",
    "        result = []\n",
    "        for prob in probs:\n",
    "            if prob < 0.5:\n",
    "                result.append(0)\n",
    "            else:\n",
    "                result.append(1)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "metric = load_metric(\"f1\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = tf.keras.activations.sigmoid(logits)\n",
    "    predicted = getClassResult(predictions)\n",
    "    return metric.compute(predictions=predicted, references=labels, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebca9668",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, args=training_args, train_dataset=train_set, eval_dataset=val_set, callbacks=[EarlyStoppingCallback(early_stopping_patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbae7c3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 13683\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 642\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='642' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/642 1:11:45 < 1:22:20, 0.07 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.328700</td>\n",
       "      <td>0.320655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.301600</td>\n",
       "      <td>0.272382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.277200</td>\n",
       "      <td>0.240769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.229900</td>\n",
       "      <td>0.216400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.194180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.182231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.169153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.163196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.160195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.160300</td>\n",
       "      <td>0.149396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.159200</td>\n",
       "      <td>0.154515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>0.140491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.137786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.119600</td>\n",
       "      <td>0.132561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.140900</td>\n",
       "      <td>0.130889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.139800</td>\n",
       "      <td>0.128218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.135500</td>\n",
       "      <td>0.139436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>0.124558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.125121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.117800</td>\n",
       "      <td>0.119454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.117832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.109700</td>\n",
       "      <td>0.118813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.119164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.113883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.099900</td>\n",
       "      <td>0.111960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.105500</td>\n",
       "      <td>0.114039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.115314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.114011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.114620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.116487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-10\n",
      "Configuration saved in multilabel/checkpoint-10/config.json\n",
      "Model weights saved in multilabel/checkpoint-10/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-20\n",
      "Configuration saved in multilabel/checkpoint-20/config.json\n",
      "Model weights saved in multilabel/checkpoint-20/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-30\n",
      "Configuration saved in multilabel/checkpoint-30/config.json\n",
      "Model weights saved in multilabel/checkpoint-30/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-40\n",
      "Configuration saved in multilabel/checkpoint-40/config.json\n",
      "Model weights saved in multilabel/checkpoint-40/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-50\n",
      "Configuration saved in multilabel/checkpoint-50/config.json\n",
      "Model weights saved in multilabel/checkpoint-50/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-60\n",
      "Configuration saved in multilabel/checkpoint-60/config.json\n",
      "Model weights saved in multilabel/checkpoint-60/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-70\n",
      "Configuration saved in multilabel/checkpoint-70/config.json\n",
      "Model weights saved in multilabel/checkpoint-70/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-80\n",
      "Configuration saved in multilabel/checkpoint-80/config.json\n",
      "Model weights saved in multilabel/checkpoint-80/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-90\n",
      "Configuration saved in multilabel/checkpoint-90/config.json\n",
      "Model weights saved in multilabel/checkpoint-90/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-100\n",
      "Configuration saved in multilabel/checkpoint-100/config.json\n",
      "Model weights saved in multilabel/checkpoint-100/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-110\n",
      "Configuration saved in multilabel/checkpoint-110/config.json\n",
      "Model weights saved in multilabel/checkpoint-110/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-120\n",
      "Configuration saved in multilabel/checkpoint-120/config.json\n",
      "Model weights saved in multilabel/checkpoint-120/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-130\n",
      "Configuration saved in multilabel/checkpoint-130/config.json\n",
      "Model weights saved in multilabel/checkpoint-130/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-140\n",
      "Configuration saved in multilabel/checkpoint-140/config.json\n",
      "Model weights saved in multilabel/checkpoint-140/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-150\n",
      "Configuration saved in multilabel/checkpoint-150/config.json\n",
      "Model weights saved in multilabel/checkpoint-150/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-160\n",
      "Configuration saved in multilabel/checkpoint-160/config.json\n",
      "Model weights saved in multilabel/checkpoint-160/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-170\n",
      "Configuration saved in multilabel/checkpoint-170/config.json\n",
      "Model weights saved in multilabel/checkpoint-170/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-180\n",
      "Configuration saved in multilabel/checkpoint-180/config.json\n",
      "Model weights saved in multilabel/checkpoint-180/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-190\n",
      "Configuration saved in multilabel/checkpoint-190/config.json\n",
      "Model weights saved in multilabel/checkpoint-190/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-200\n",
      "Configuration saved in multilabel/checkpoint-200/config.json\n",
      "Model weights saved in multilabel/checkpoint-200/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-210\n",
      "Configuration saved in multilabel/checkpoint-210/config.json\n",
      "Model weights saved in multilabel/checkpoint-210/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-220\n",
      "Configuration saved in multilabel/checkpoint-220/config.json\n",
      "Model weights saved in multilabel/checkpoint-220/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-230\n",
      "Configuration saved in multilabel/checkpoint-230/config.json\n",
      "Model weights saved in multilabel/checkpoint-230/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-240\n",
      "Configuration saved in multilabel/checkpoint-240/config.json\n",
      "Model weights saved in multilabel/checkpoint-240/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-250\n",
      "Configuration saved in multilabel/checkpoint-250/config.json\n",
      "Model weights saved in multilabel/checkpoint-250/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-260\n",
      "Configuration saved in multilabel/checkpoint-260/config.json\n",
      "Model weights saved in multilabel/checkpoint-260/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-270\n",
      "Configuration saved in multilabel/checkpoint-270/config.json\n",
      "Model weights saved in multilabel/checkpoint-270/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-280\n",
      "Configuration saved in multilabel/checkpoint-280/config.json\n",
      "Model weights saved in multilabel/checkpoint-280/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-290\n",
      "Configuration saved in multilabel/checkpoint-290/config.json\n",
      "Model weights saved in multilabel/checkpoint-290/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3421\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to multilabel/checkpoint-300\n",
      "Configuration saved in multilabel/checkpoint-300/config.json\n",
      "Model weights saved in multilabel/checkpoint-300/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from multilabel/checkpoint-250 (score: 0.1119597777724266).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=0.15403384764989217, metrics={'train_runtime': 4311.8885, 'train_samples_per_second': 9.52, 'train_steps_per_second': 0.149, 'total_flos': 986033813713200.0, 'train_loss': 0.15403384764989217, 'epoch': 1.4})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f14bc5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 4276\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 01:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logits = trainer.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0750e38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4276, 6)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5b7a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 00:49:38.848119: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-10 00:49:38.848561: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "predicted = tf.keras.activations.sigmoid(logits.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f33fc8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01409502, 0.9816279 , 0.01466793, 0.0106061 , 0.01333568,\n",
       "        0.01498337],\n",
       "       [0.01131314, 0.97574437, 0.01378885, 0.00961971, 0.01381588,\n",
       "        0.01985262],\n",
       "       [0.01220088, 0.25224018, 0.02930349, 0.01424369, 0.41727734,\n",
       "        0.00650762],\n",
       "       ...,\n",
       "       [0.00437115, 0.01897231, 0.95080817, 0.00888529, 0.01537037,\n",
       "        0.03060839],\n",
       "       [0.60755473, 0.33469725, 0.02623363, 0.0142573 , 0.8560901 ,\n",
       "        0.01503711],\n",
       "       [0.00936071, 0.02604666, 0.5798291 , 0.02834429, 0.9835946 ,\n",
       "        0.05021281]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "acea92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = getClassResult(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d53a3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for pred in predicted_label:\n",
    "    if pred.count(1) > 1:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0899422a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Remember      0.860     0.852     0.856       237\n",
      "  Understand      0.921     0.918     0.920      1200\n",
      "       Apply      0.929     0.895     0.912      1216\n",
      "     Analyze      0.939     0.877     0.907       701\n",
      "    Evaluate      0.947     0.914     0.930       799\n",
      "      Create      0.915     0.832     0.872       739\n",
      "\n",
      "   micro avg      0.926     0.890     0.907      4892\n",
      "   macro avg      0.919     0.881     0.899      4892\n",
      "weighted avg      0.926     0.890     0.907      4892\n",
      " samples avg      0.919     0.907     0.907      4892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ylii0447/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, predicted_label, output_dict=False, target_names=list(data.columns[1:7]), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e52f7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98839375, 0.98205773, 0.97611275, 0.98406073, 0.98888998,\n",
       "       0.97096306])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_y, predicted.numpy(), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c01e8dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8528999064546305"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.array(test_y), predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4bcd035",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_result_df = pd.DataFrame(data=predicted_label, columns=data.columns[1:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4d4dc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9840972871842844\n",
      "0.9550982226379794\n",
      "0.9506548175865295\n",
      "0.970533208606174\n",
      "0.9742750233863424\n",
      "0.9576707202993452\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(ml_golden_df['Remember'].tolist(), dl_result_df['Remember'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Understand'].tolist(), dl_result_df['Understand'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Apply'].tolist(), dl_result_df['Apply'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Analyze'].tolist(), dl_result_df['Analyze'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Evaluate'].tolist(), dl_result_df['Evaluate'].tolist()))\n",
    "print(accuracy_score(ml_golden_df['Create'].tolist(), dl_result_df['Create'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9b0db2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8475165217354823\n",
      "0.8886774810112577\n",
      "0.8773959293050357\n",
      "0.8895938602599291\n",
      "0.9141876451080061\n",
      "0.8464440044283781\n"
     ]
    }
   ],
   "source": [
    "print(cohen_kappa_score(ml_golden_df['Remember'].tolist(), dl_result_df['Remember'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Understand'].tolist(), dl_result_df['Understand'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Apply'].tolist(), dl_result_df['Apply'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Analyze'].tolist(), dl_result_df['Analyze'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Evaluate'].tolist(), dl_result_df['Evaluate'].tolist()))\n",
    "print(cohen_kappa_score(ml_golden_df['Create'].tolist(), dl_result_df['Create'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee3d07d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
